{"/about/":{"data":{"":" Hello, I’m Vinay a FOSS enthusiast and a undergraduate, currently Hack’ing at Deeproot GNU/Linux.\nI’m a Debian Maintainer,maintaining \u0026 working on packages of GitLab and its components on Debian.\nPlease feel free to hit me up if you want to get in contact or want to know about me. I go by the handle vinay-keshava across the web.\nEmail/XMPP: vinaykeshava [AT] disroot.org\n[Domain Sponsored by Deeproot GNU Linux]"},"title":"About"},"/blog/":{"data":{"":" Debian Maintainer Now!! Contributing to Debian !! Software Freedom Camp 2021 git.fosscommunity.in Server Update "},"title":"Blog Post's"},"/blog/automating-debian-installer/":{"data":{"":"The Debian Graphical Installer,when i was introduced to Kali Linux(a Debian based distro),during my initial days of bachelor’s, the installer was so tricky to install GNU / Linux,thereby losing my data (:\nEven though nowadays, Live systems have Calamares based installer,i feel the Graphical Installer is a bit annoying,so i wanted to automate the debian installer using a preseed configuration file,giving answers to debian installer in a config file making it easier and faster.\nThis is the wiki link for Debian Installer Preseeding https://wiki.debian.org/DebianInstaller/Preseed . Preseeding is like a set of answers to debian-installer(d-i) questions.Preseeding can be done in 3 ways\n1.Adding the preseed file to installer’s initrd.gz\n2.Over webserver via DHCP\n3.Loading the preseed file from a webserver over the boot options.\nThis blog post explains automating the debian installer by loading the preseed file from a webserver over the boot.\nWhen Graphical Installer boot menu appears after booting through the Debian iso,select the Help entry from the menu. After selecting the Help entry from boot menu,a boot: prompt is displayed below, enter you webserver url of the preseed file, in my case the preseed file was on my server with ip http://144.24.135.168/preseed.cfg/, and give boot: auto url=http://144.24.135.168/preseed.cfg and the auto command launchs the automated debian installer. The default preseed file for new release will be updated here https://wiki.debian.org/DebianInstaller/Preseed#Default_preseed_files Answers like setting username and password for Account setup,Network Configuration,Mirror Settings,Partitioning disks,setting normal user as root user Locales,Keyboard layout,Package Selection and many more\nAll the features in the Debian installer can be answered with the preseed file. My Preseed filed-i mirror/http/hostname string http.us.debian.org d-i mirror/http/directory string /debian d-i mirror/http/proxy string d-i passwd/root-login boolean false d-i passwd/user-fullname string Vinay Keshava d-i passwd/username string vinay d-i passwd/user-password password vinay d-i passwd/user-password-again password vinay d-i clock-setup/ntp boolean true d-i partman-auto/init_automatically_partition select biggest_free In the above preseed file i’ve set the debian mirrors [ line 1-3 ]with http.us.debian.org and the directory for the mirror is /debian,Account setup with password[ line 4-8 ], [ line 9 ] for ntp server to sync time with and [ line 10 ] for automatically partitioning the disk with biggest free space disk partition.\nThis is sample preseed file with few options and it can be customized accordingly.\n:wq "},"title":" Automating the Debian Installer"},"/blog/contributing-to-debian/":{"data":{"debian#Debian":"DebianDebian is a GNU/Linux distribution completely inclinded towards Free Software philosophy, maintained by the community.\nBefore talking about how i started contributing to debian, i would like to talk about the camp organized by FSCI It is an online free mentorship programme organized by Free Software Community of India ,introducing people to Free Software.Ravish introduced me to 2021 FSCI’s camp, and there i got introduced to Debian Packaging through Debian Developers and Debian Maintainers.\nDuring the project phase of the camp, i choosed to work on Debian Packaging and System Administration(here is my Project Proposal)","debian-packages-and-my-story-#Debian Packages and my Story !!":"Debian has roughly over 51,000 packages, these packages are installable through apt, just like “sudo apt install nano”. I always wanted to know how “sudo apt install nano” works !.\nDuring the project phase of the camp Praveen my mentor of the project,a Debian Developer himself suggested to get started by packaging node packages(dependencies of Gitlab). A big Thanks to praveen for teaching packaging from scratch, also answering my useless questions and also sponsoring my packages to debian. Initially i found it very difficult to understand it,but the community was so welcoming, they were helping and assisting me by clearing all my doubts through matrix.\nI took a lot of time to learn,tried to spend more time in learning during hectic schedule of college and also i gave up hope many times and restarted it. So initial task was to setup the Debian Unstable environment and rebuilding the existing simple node-pretty-ms package, and then tried a simple package update and then went to continue packaging few node modules.\nI currently maintain around two node modules as of today, looking forward to maintain more packages in debian. All the communication happens mainly through mailing list or irc of respective teams.","further-development#Further Development":"Looking forward to contribute and hangout with the awesome debian community and learn more.\n:wq "},"title":"Contributing to Debian"},"/blog/debconf23/":{"data":{"":"Its almost been more than a month since DebConf23 happened,and this post was in draft for very long time because i just wanted to write the best post of all my post, and finally writing about the experience of attending a FOSS conference/conference for the first time.I had graduated in early May'23, so was not sure whether i could attend DebConf.I had joined Deeproot GNU/Linux,just before DebConf as an Intern. I was excited for this because i meeting my Debian and Free Software Community of India friends for the first time in 2 years,i hadn’t met anyone physically,was conversing with them online.\nI became a Debian Maintainer in early'2023 March ,special thanks to Praveen my GURU,for advocating my Debian Maintainer process,who taught me Debian Packaging from scratch,answering my stupid questions and Nilesh for signing my keys. I have written a separate blog post about my experience of becoming a DM.\nAhh so this is Ravish [Left] and me. Ravish is my college super senior,we were part of FOSS club called Edwin’s Lab in our college,he’s the one who introduced me to GNU/Linux. Forever indebted to ravish its because of him i’m working at DeeprootLinux,Thanks man.\nIt was my first time flying,I,Abhas - Founder of Deeproot Linux,Ravish boarded a cab to the Bangalore Airport, and we reached around 8:00pm,the architecture of KIAL was just amazing,i was astonished, we had huge baggage to carry for the Mostly Harmless Stall at the airport,so we had rigourous security checks at the airport. We boarded the flight on 9th September, DebConf was about to start from 10th September [ I missed DebCamp ]\nIt was a surreal experience of flying for the first time,it was amazing feel.We also had our dinner (Veg Roll) on the flight. Had the best view of city during the night time,watching’em from higher altitude was just so satisfying for eyes. We reached Kochi Airport around 11:15pm and boarded a cab to Four Points Sheraton Hotel. We reached Infopark Kochi around 12:30am and checked in to our hotels.I had applied for Accomodation and Food Bursary and it was approved :) So my room was at Four Points Sheraton Kochi,6th floor, also i was wondering who my roomate was,the earlier day i had receieved a mail that Kurian Benoy was my roommate, i was curious to meet him.\nThe next morning was DebConf Opening Ceremony,so had to sleep because it was already 3:00am i was exploring my hotel room.\nWoke up around 8:00 am and freshened up and headed to FrontDesk for Registration,we got our name with GPG key printed on our ID’s,also got the SwagBag,with some cool stickers and swags by Debian. After the registration i met kurian benoy, my roommate for a week.\nStickers part of Debian Swag I and ravish were waiting at the HackLab for the opening ceremony,in mean time we met urbec,part of Video Team,had some good conversation too.\nDEBCONF-23 starts with opening ceremony at Anamudi(These were the hall names,other hall names were Kuthiran,Ponmudi) the DebConf organizing team were on the stage giving a Welcome Note, and then after welcoming ceremony i went to attend talks which we interesting. The talk schedule was not very tight, because we used to gather more at the eating place to meet new people from diverse countries,having some really good conversations.\nI met praveen,shruti,anupa,ravi,sahil,abhijith,nilesh,bilal,suman,kelvin,pushkar,utkarsh,joostvb,Israel Galadima… and lot more people whom i wanted to meet.\nI also met Pushkar from canonical, who used to stay at Bengaluru in the same locality and that was coincidence,meeting him was great too. First day ended good.\nA picture with Pirate Praveen and Ravi. Abhas's talk on Home automation with his amazing LED pant :) Cheese and wine party, the party is simple to bring good stuff from other countries like cheese and wine, People from all over the world bought different stuff to the cheese and wine party,we got the chance to taste from Korean wafers and red wine.\nOn 13th Sep there’s a Day trip,but i hadn’t registered early, only for Bird Sanctuary the registration was open,just the day before day trip edited the wiki and added my name. A Day trip to Thattekad Bird Sanctuary On the way to Thattekad i met /su/bin/ siby, on the bus. Thattekad Bird Sanctuary is around 50km from the kochi,so we left around 7:00 am\nWe reached around 9:00 and had snacks and started walking towards the bird sanctuary. It started with a walk around the bird sanctuary spotting for birds around,during the trek i was with Praveen,Bady,Kannan and Kelvin. Spotting birds was difficult because it wasn’t the actual season for migrating birds,so we could spot only few. Kelvin was explaining how he started to contribute to Open Street Map.\nOn our way back to the bus it started raining heavily and we were drenched completely, The cool debian umbrella with Debian symbol on it,helped us to get back to the bus.After a hot tea and snacks we started back to kochi.\nDebian and Clouds :)\nThe place were i stayed the most Mostly Harmless Stall (But not Harmless) with Abhas,Akshay explaining people about Liberated Hardware,and why it is important in life to use Liberated Hardware.Enjoyed Sahil’s touch typing and testing keyboards,i couldn’t take a picture with Sahil,he also volunteers at FSCI managing instances,he taught me git.fosscommunity.in update generating keys etc he’s also a Debian Developer,part of DebConf organizing committe too, also met saswata from Unmukti Tech.\nIt was an Amazing conference,it was my first Conference/FOSS conference enjoyed it,got to meet new people,the ecosystem of the Hacklab to hack around,seeing the community bonding even ravish wanted to contribute by packaging so taught him packaging at hacklab during free time,Also i learnt about OpenStreetMap,and now i map in and around Bangalore in my free time,a good hobby that i’m interested.Enjoyed ravi’s humourous jokes :) throughout DebConf\nThe only disappointing thing at DebConf was the demise of Abraham Raji during a Day Trip,Debian project mourns the death of abraham, i hadn’t personally met him,but conversed online about fsci camp,an inspiring soul\nAbraham Lives Onnn!"},"title":"DebConf 23,Kochi India"},"/blog/debian-maintainer/":{"data":{"":"I am excited to share with you all that I have recently become a Debian maintainer!! Thanks to amazing debian community.\nIt all started with Software Freedom Camp, ravish my college super senior (we were a part of college linux club) introduced me to software freedom camp organized by FSCI, since then i was a noob hopping between various distro’s from kali linux to other debian based distros to arch ! I had previously written my experience of attending software freedom camp here.\nI started with packaging node modules initially without any knowledge of javascript/nodejs, before packaging new module i tried to upgrade few node packages to new upstream,it was difficult at first understanding the packaging process. node-prosemirror-view was the first node module i packaged, cut to 20'23, i maintain few ruby and golang packages most of them which are gitlab dependencies, here is the list of packages i maintain.Special thanks to praveen for his mentoring, who is my package sponsorer.\nOver the past six months, I have been packaging Ruby gems and GitLab dependencies. For this gitlab update, I took on the challenge of building GitLab 15.8.4 and its major components, including Gitlay and GitLab-shell.\nThanks to Praveen and Bilal for their help and support during gitlab package upgrade to 15.8.4.\nThe first package as DM uploaded was ruby-et-orbi.\nWe are also preparing GitLab for bookworm, the next release of Debian."},"title":"Debian Maintainer Now !!!!"},"/blog/dont-grow-up-old/":{"data":{"":"Don’t grow up old, everyone wants to become an adult soon, enjoy life ,stay independent,take more responsibilites etc etc.\nBut in this process, you miss out a lot of things,the excitement to grow old faster kills you, and you will only realize this when you look behind and regret saying, i should have done this at that point of time in my life, but you cannot do it now,and now do nothing but,regretting.\nDon’t let the kid inside you miss out the fun,enjoy every moment in life to the fullest,enjoy by living the present moment. Do what you’re supposed to do at that point of time in your life. What ever is supposed to happen,happens at the right time,irrespective of what and how many times you think about it."},"title":"Dont Grow Up Old!"},"/blog/foss-activities-dec-2023/":{"data":{"":"","debian-activities#Debian Activities":" javamorph\nAdded compilation support for JDK 21 with the help of Vladimir Petko. #Bug 1052620 Link to MR, MR accepted and bug closed. Thanks to package maintainer tony mancill for sponsoring package. ruby-validates-hostname\nNew Upstream 1.0.13-1 Routine Update Required for gitlab 16.4 ruby-gpgme\nNew Upstream 2.0.23-1 Routine Update Required for gitlab 16.4 ruby-lockbox\nNew Upstream 1.3.0-1 Routine Update Required for gitlab 16.4 ruby-gitlab-experiment\nruby-gitlab-experiment to experimental New Upstream version 0.8.0-1 Required for gitlab 16.4 ruby-tanuki-emoji\nNew Upstream version 0.7.0-1 Required for gitlab 16.4 epm\nUpdated d/watch patch for epm,epm upstream maintainer has been changed to github.com/jimjag/epm Bug #1051502 ruby-loofah\nNew upstream version 2.21.4 Required for GitLab 16.6.x ruby-apollo-upload-server\nNew upstream version 2.1.5 Required for Gitlab 16.6.x ruby-po-to-json\nNew upstream version 2.0.0 Required for Gitlab 16.6.x Refreshed Patches. "},"title":"Foss activities - Dec 2023"},"/blog/foss-activities-nov-2023/":{"data":{"":"","debian-activities#Debian Activities":" javamorph\nAdded compilation support for JDK 21 with the help of Vladimir Petko. Link to MR ruby-pry-byebug\nMy first QA upload to Debian Closing the bug #1054747 Link to MR New Upstream release 3.10.1 Abhijith pointed out this bug to me, to prevent ruby-octokit from being removed from the archive. Thanks to Miguel Landaeta for sponsoring this package upload."},"title":"Foss activities - Nov 2023"},"/blog/foss-activities-oct-2023/":{"data":{"":"Post DebConf Month","debian-activities#Debian Activities":" ruby-aws-sdk-core\nNew upstream release 3.178.0 rofi\nMy first NMU( Non Maintainer Upload) to debian\nSponsorer: Abhijith PA,also thanks to karthik for mentioning to update rofi,because it was no longer maintained also fixed the bug https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1043483 for d/watch\nNew Upstream version 1.7.5\nd/watch update closes bug\nRefreshing Patch to fix man pages\nFixing Build Depends on obsolute package\nruby-aws-sigv4\nNew Upstream release 1.6.1 ruby-aws-sdk-s3\nNew Upstream release 1.130.0 ","open-street-map#Open Street Map":"My edits on open street Map for October in and around Bangalore and Pavagada. https://www.openstreetmap.org/user/vinay-keshava/history\n:wq "},"title":"Foss activities - Oct 2023"},"/blog/git-fosscommunity-in-update/":{"data":{"":"Ahh, my first blog post. Good Beginnings (:\nExcited!!\nThis blog post is dedicated to sharing my experience with updating the FSCI’s GitLab instance git.fosscommunity.in update.\nFSCI runs a free instance of GitLab Community Edition at git.fosscommunity.in for collaborative software development.\nFSCI also hosts and maintains a lot of services for the community, you can check out the services here, these services are managed by volunteers.\nAfter joining Software Freedom Camp 2021 Diversity Edition( Online mentorship programme organized by Free Software Community of India(FSCI) ) as a learner and I met a bunch of people who discuss about Free/Libre/Open Source Software and educate people about why it is important to use free software in our life maintaining freedom and privacy in this era of technology. Along with Ravish and Sahilister we all updated it from GitLab v14.4.2 to Gitlab v14.4.4 it was a Security update, it took a lot of my time to update and upgrade the instance.\nAll thanks to Ravish and Sahilister for helping and teaching me."},"title":"git.fosscommunity.in Server Update"},"/blog/i-should-write-more/":{"data":{"":"2023 is about to end in another few months,I feel ,i should write more now!. I just love writing now,I feel i should write more to express my thoughts,ideas,its been since few months i started to write more docs,and i just simply love it.\nI feel like it helps me document stuff,check how my learning evolved over time and its progress.\nAt first when i started to create my portfolio i was reluctant to write much,barely one or two articles per year,i was not confident about my grammer too,now i really dont care about it,i just write my raw thoughts.There’s some level of satisfaction of writing,i encourage others also to write more.\nPeople who read my blog might provide feedback too,correct if any mistakes. I also encourage other people to write, if they are too shy they can try anonymous blog.\n:wq "},"title":"I Should Write more!"},"/blog/software-freedom-camp-2021/":{"data":{"experience-of-running-snikket-server#Experience of Running Snikket Server":"Back to writing after a 2-month long Semester End Exam !!!!.\nEveryone uses messaging platforms like WhatsApp, Facebook, Signal, Telegram, and various other applications to communicate with people, in this blog post I would like to introduce to XMPP Protocol( Extensible Messaging and Presence Protocol), XMPP is an open, decentralized universal messaging standard for instant messaging, voice/video calls. Many Applications or Clients are built using the XMPP protocol due to its open nature. Platforms like WhatsApp, Telegram, Signal impose vendor lock-in wherein the user using the product or service cannot transit to the competitor’s product/service. To overcome vendor lock-in issues and privacy issues one of the minimal, simple best solutions is to set up a Snikket server of your own, where you can own your data.\nWhat is SnikketSnikket is a simple, customized messaging platform that is different from other messaging apps like Whatsapp, Telegram. Snikket is a decentralized messaging platform which means anyone can host their snikket server on their cloud, it allows everyone to host their server. Snikket is free software, a privacy-friendly messaging platform based on XMPP protocol, it can be self-hosted by anyone. Snikket provides an android application client to connect to any XMPP servers and using a snikket account you choose any XMPP clients if you want to connect using android applications like monocles chat, blabber, Snikket app other desktop clients recommended are dino-im and gajim.\nExperience of Running Snikket ServerSnikket is my first self-hosted service, before talking about the experience of running the snikket server I would like to talk about Software Freedom camp 2021 ,the camp is organized by the Free Software Community of India. As a part of the camp initially, learners were made to understand the philosophy and intention behind free software. Later during the project phase, learners were allowed to choose certain available topics proposed by the mentor. After joining the sfcamp as a learner, I choose to learn system administration and Debian packaging, under system administration one of the deliverables was to set up a Snikket server of my own.\nTo run any snikket server basic requirements are a domain name and a VPS (Virtual Private Server )to run your snikket server. I had signed up for the Github Student Developer pack through the pack got the free domain from name.com and I choose Amazon Web Services Free Tier as my VPS.\nSnikket is all about the DNS Docker Daemons Snikket also has an option of creating circles, limiting users to that circle only, although any user can talk to any individual by providing an XMPP or Snikket username. Snikket uses an invite-based procedure for account creation on the server. Only the admin can have the authority to create an invite link. Snikket also supports audio and video calls of great speed, these are some of the features of the snikket application. I have been using Snikket and invited most of my friends to my Snikket server. Initially, it took time to make them understand how it is completely different from other messaging platforms. Later educated them about how decentralization, vendor lock-in works and then introduced them to Snikket and other XMPP-based clients.\nThe learning while setting up the snikket server was got introduced to Docker Container, Domain Name System( DNS ), how server logs are checked, and debugging the errors.","guide-to-setup-snikket-server#Guide to Setup Snikket Server":"Here is the quickstart guide to setup the snikket server , this is the official guide by Snikket to setup the snikket server . The detailed documentation is here. Snikket requires few ports to be open for communication refer this which clearly mentions the firewall rules and ports required. Snikket Source code here.\nThanks to Ravish and Sahil for helping to set up the Snikket server.\nNext Goals - Reverse Proxy by Nginx . Bye for now .\n:wq ","what-is-snikket#What is Snikket":""},"title":"Software Freedom Camp 2021 Snikket"},"/captures/":{"data":{"":"Coming Soon."},"title":"My Captures"},"/docs/":{"data":{"":"I try to hack around a lot of stuff,but lazy to document, but trying to document ’em all"},"title":"Documentation"},"/docs/debian/":{"data":{"":"Tutorials,configs and hacks related to Debian Packaging."},"title":"Debian Packaging"},"/docs/epm/":{"data":{"":"","#":"EPM is a ESP Package Manager used to package software easily,either by creating debs or rpms or tar.gz which makes easy to distribute software. Software distribution is the most difficult task in today’s world, and packaging software for each distribution makes it tedious,every distribution has their own set of rules and development tools to package software.\nEPM makes it easy to ship and package software for every distribtion.\nTo get started with EPM here is the documentation link.\nYou can install epm on Debian by just\n$ sudo apt install epm Or can build from source too.\nPackaging using EPM An example demo to package prometheus to generate a deb and tar.gz using EPM.\nStep 1: Download the tarball prometheus-2.48.0.linux-amd64.tar.gz\nStep2: Extract to the new folder\nStep 3: Create a new file in the extracted folder called prometheus.list with the following contents and here is the FHS to package\nls -l prometheus-2.48.0.linux-amd64$ ls -l prometheus-2.48.0.linux-amd64 total 171576 -rw-r--r-- 1 debian debian 11357 Nov 16 05:01 LICENSE -rw-r--r-- 1 debian debian 3773 Nov 16 05:01 NOTICE drwxr-xr-x 2 debian debian 4096 Nov 16 05:01 console_libraries drwxr-xr-x 2 debian debian 4096 Nov 16 05:01 consoles drwxr-xr-x 2 root root 4096 Nov 28 06:30 linux-6.1-x86_64 -rwxr-xr-x 1 debian debian 90226488 Nov 28 06:29 prometheus -rw-r--r-- 1 debian debian 424 Nov 27 10:19 prometheus-systemd-service -rw-r--r-- 1 debian debian 734 Nov 28 06:28 prometheus.list -rw-r--r-- 1 debian debian 934 Nov 16 05:01 prometheus.yml -rwxr-xr-x 1 debian debian 85422008 Nov 28 06:29 promtool prometheus.list%product Prometheus %copyright Promethues[Expat], All Rights Reserved. %vendor %license LICENSE %description Prometheus %version 2.48.0 %literal(control) \u003c\u003cEOF Section: misc Priority: important EOF f 755 root sys /usr/local/bin/prometheus prometheus f 755 root sys /usr/local/bin/promtool promtool d 755 root sys /etc/prometheus/consoles consoles d 755 root sys /etc/prometheus/console_libraries console_libraries f 644 root sys /etc/prometheus/prometheus.yml prometheus.yml f 644 root sys /lib/systemd/system/prometheus.service prometheus-systemd-service %postinstall sudo systemctl daemon-reload %postinstall sudo systemctl enable prometheus %postinstall echo Installation completed prometheus running on port 9090 Terminologies %product describes the name of the package.\n%copyright describes the license of the package.\n%vendor describes the organization name.\n%license attaches the file called LICENSE of the prometheus package.\n%description description about the package.\n%literal literal data, debian packages have control file to provide metadata about each package,similarly this token can be used to produce similar metadata.\n%postinstall \u0026 %preinstall to execute any scripts after and before installing the package respectively.\nHere,comes the actual part files,directories and symlinks\nTo put files/directories in FHS follow the below example syntax\ntype mode owner group destination source options f 755 root sys /usr/local/bin/prometheus prometheus Here\n-\u003e type describes whether its a file(f), or directory(d) or symbolic link (l) or configuration file(c)\n-\u003e mode describes about the file permission in unix style also mentioning the user and the group level access\n-\u003e destination \u0026 source specifies which file or directory to be put,here /usr/local/bin/prometheus is the destination and the binary prometheus in the current directory is the source\nBelow is the prometheus systemd service file example to enable systemd for prometheus and hence we use %postinstall to reload the systemd daemon and setup the systemd service.\nprometheus systemd service file $ cat prometheus-systemd-service [Unit] Description=Prometheus Time Series Collection and Processing Server Wants=network-online.target After=network-online.target [Service] ExecStart=/usr/local/bin/prometheus --config.file /etc/prometheus/prometheus.yml --storage.tsdb.path /var/lib/prometheus/ \\ --web.console.templates=/etc/prometheus/consoles \\ --web.console.libraries=/etc/prometheus/console_libraries [Install] WantedBy=multi-user.target Building the package $ sudo epm -f deb prometheus Will look for prometheus.list we had configured above and tries to build the package.\nThe -f option is to specify the distribution format here, giving it as deb to build a deb.\nIf the command runs successfully it creates and directory within the current directory called linux-6.1-x86_64 the built package deb is present within this directory.\nRunning without the -f option builds a tarball as show below.\nwithin the extraced directory$ sudo epm prometheus $ ls linux-6.1-x86_64/ prometheus-2.48.0-linux-6.1-x86_64.tar.gz $ sudo epm -f deb prometheus $ ls linux-6.1-x86_64/ prometheus-2.48.0-linux-6.1-x86_64.deb prometheus-2.48.0-linux-6.1-x86_64.tar.gz Drawbacks EPM does not support alphanumeric characters and special characters like underscore for the package name making it difficult and reducing reading enhancibility. "},"title":"EPM (ESP Package Manager)"},"/docs/golang/":{"data":{"":"Golang Learning."},"title":"Golang Learning"},"/docs/golang/introduction/":{"data":{"":"","basics#Basics":"Packages Programs start running with package main package main import \"fmt\" func main(){ fmt.Println(\"Hello World\") } Multiple package import paths. package main import ( \"fmt\" \"math/rand\" ) func main(){ fmt.Println(\"Fav number:\", rand.Intn(10)) } Exported Names Exported names start with capital letter,just like Pi in math package. package main import ( \"fmt\" \"math\" ) func main(){ fmt.Println(math.Pi) } Functions Functions can take zero or more arguments, variable type comes after variable name. package main import \"fmt\" func multiply(x int,y int) int { return x*y } func main(){ fmt.Println(multiply(4,2)) } Shortening function parameters,for better readability. func multiply(x,y int) int { return x*y } Return multiple results in a function definition func addsub(x,y int) (int,int){ return x+y,x-y) } func main(){ fmt.Println(addsub(20,20)) } Named return values. func addsub(x,y int) (add,sub int) { add = x+y sub = x-y return } Multiple Returns func swap(x,y string) (string,string){ return y,x } func addsub(x,y int) (int,int){ return x+y,x-y } func main(){ fmt.Println(swap(\"hello\",\"world\") fmt.Pritln(addsub(10,20)) } Variables package main import \"fmt\" var hello bool var i int=0 func main(){ var b,c int= 20,30 fmt.Println(i,hello,b,c) } Short variable description k:=3\nTypes Basic Types Integers - Signed (int,int8,int16,int32,int64) Unsigned (uint,uint8,uint16,uint32,uint64) Floats - float32,float64 Complex Numbers - float32,float64 Byte Rune String Rune Boolean Composite Types Collections/Aggregation - Arrays,Structs Reference Types - slices, maps,channels, pointers,functionos Interface package main import ( \"fmt\" \"math/cmplx\" ) var ( hello bool = false name string = \"vinay\" age int = 22 z complex128 = cmplx.Sqrt(-5+2i) ) func main(){ fmt.Printf(\"Type: %T Value: %v\\n\",hello,hello) fmt.Printf(\"Type: %T Value: %v\",name,name) fmt.Printf(\"Type: %T Value: %v\",age,age) fmt.Printf(\"Type: %T Values: %v\",z,z) } //observe the printf not the usual Println Type conversion and type inference package main import \"fmt\" import \"math\" // The expression T(v) converts the value v to the type T. func main(){ // Type conversion var x,y int =3,5 var f float64 = math.Sqrt(float64(x*x + y*y)) var z uint = uint(f) fmt.Println(x,y,z) fmt.Printf(\"Type: %T Value: %v\\n\",x,x) fmt.Printf(\"Type: %T Value: %v\\n\",z,z) fmt.Printf(\"Type: %T Value: %v\\n\",f,f) // Type Inference - the variable's type is inferred without from the value // on the right side i:=22 fmt.Printf(\"Type: %T Values: %v\",i,i) } Constants package main import \"fmt\" func main(){ const Pi = 3.14 // never use short description for constants i.e := fmt.Println(Pi) } "},"title":"Introduction to Golang"},"/docs/hacks/":{"data":{"":"If things are uncategorized,it goes to Hacks :)"},"title":"Hacks"},"/docs/hacks/customize-qcow2-disk-image/":{"data":{"":"Tired of Debian Installer ):\nOn Proxmox VE i had to go through the Debian Installer if i want to spin up a new VM,taking a lot of time and effort.\nDownload the .qcow2 image from cloud.debian.org https://cloud.debian.org/images/cloud/bookworm/20230910-1499/debian-12-genericcloud-amd64-20230910-1499.qcow2 ,this is a generic cloud image which can be easily imported onto proxmox.\nReset the root password on the disk image $ virt-customize -a debian-10-genericcloud-amd64.qcow2 --root-password password:debian\nBy default the .qcow2 doesn’t have any root password,so the disk image has be customized using virt-customize to add root password.\nIncrease size of .qcow2 disk image. By default the size of Debian Generic Cloud is 2GB, using qemu-img we can resize the disk image. qemu-img resize image.qcow2 +SIZE Import the disk image on Proxmox VE. Copy the image to /var/lib/vz/template/qemu/. Create a VM on Proxmox VE without any media (do not attach any physical media) and delete any existing disk on proxmox.\nqm importdisk 114 /var/lib/vz/template/qemu/debian-12-genericcloud-amd64-20230910-1499.qcow2 amogha -format qcow2 Execute the above qm importdisk on the proxmox server where 114is the VM id where in your case will be different. Refreshing the Proxmox GUI on the browser,attach the unused Hard Disk under Hardware, also add a cloudInit drive and set IP address to dhcp to automatically assign IP address for both IPv4 and IPv6.\nUnder Options update the boot order and check whether the hard disk which was added to be checklisted and prioritize it to first.\nAnother alternative way is to use Preseed file at boot which automates debian installer,haven’t tried that yet.\nCreating a new VM Creating a vm using command line on proxmox without using using the WEB-UI\n#!/bin/bash function newqemu_vm { qm create $vmid --name $name --memory $ram --net0 virtio,bridge=vmbr0 qm importdisk $vmid /var/lib/vz/template/qemu/debian-12-genericcloud-amd64-20230910-1499.qcow2 amogha -format qcow2 sleep 5 qm set $vmid --scsihw virtio-scsi-pci --scsi0 amogha:vm-$vmid-disk-0 qm set $vmid --ide2 amogha:cloudinit --boot c --bootdisk scsi0 --serial0 socket --vga serial0 qm set $vmid --ipconfig0 ip=dhcp qm resize $vmid scsi0 +\"$size\"G qm set $vmid --sshkey ~/.ssh/id_rsa.pub qm start $vmid } echo \"HostName of the VM:\" read name echo \"Enter new VMID:\" read vmid echo \"Enter number of CPU cores:\" read cpucores echo \"Ram:\" read ram echo \"Enter Total Storage of the VM: [Example: +11G ]\" read size newqemu_vm :wq #for now"},"title":"Customize .qcow2 image"},"/docs/hacks/mapping-of-physical-usb-ports-to-device-names/":{"data":{"":"","how-to-map-physical-usb-ports-to-device-names-on-gnulinux#How to Map Physical USB ports to Device Names on GNU/Linux":"lsusb command$ lsusb Bus 002 Device 004: ID 04b3:3025 IBM Corp. NetVista Full Width Keyboard Bus 002 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub Bus 003 Device 123: ID 0951:1666 Kingston Technology DataTraveler 100 G3/G4/SE9 G2/50 Bus 003 Device 002: ID 2109:0815 VIA Labs, Inc. USB3.0 Hub $ lsusb -t /: Bus 06.Port 1: Dev 1, Class=root_hub, Driver=xhci_hcd/2p, 10000M |__ Port 2: Dev 2, If 0, Class=Hub, Driver=hub/7p, 5000M /: Bus 05.Port 1: Dev 1, Class=root_hub, Driver=ehci-pci/3p, 480M |__ Port 1: Dev 2, If 0, Class=Hub, Driver=hub/8p, 480M /: Bus 04.Port 1: Dev 1, Class=root_hub, Driver=xhci_hcd/2p, 480M /: Bus 03.Port 1: Dev 1, Class=root_hub, Driver=xhci_hcd/4p, 5000M |__ Port 4: Dev 2, If 0, Class=Hub, Driver=hub/4p, 5000M |__ Port 2: Dev 123, If 0, Class=Mass Storage, Driver=usb-storage, 5000M /: Bus 02.Port 1: Dev 1, Class=root_hub, Driver=ehci-pci/3p, 480M |__ Port 1: Dev 2, If 0, Class=Hub, Driver=hub/6p, 480M |__ Port 3: Dev 4, If 0, Class=Human Interface Device, Driver=usbhid, 1.5M /: Bus 01.Port 1: Dev 1, Class=root_hub, Driver=xhci_hcd/4p, 480M |__ Port 4: Dev 2, If 0, Class=Hub, Driver=hub/4p, 480M “lsusb” is a utility of “usbutils” in GNU/Linux to display information about the USB Buses and the USB’s attached to the buses.The output of the command displays the VendorID:ProductID and to which bus it is attached,the “Kingston Technology DataTraveler” bearing the VendorID:ProductID (0951:1666) attached to bus 003, the lsusb command with option “-t” provides a tree like output in a hierarchial structure.\n“lsblk” is a tree-like structure to identify devices and their partitions,and also displays device name (/dev/sd* if its a hard disk,/dev/nvme0n1 in case of SSD),size of the drive/partition, whether it is a disk/partition and the device’s mountpoints,here the /dev/sda* is the hard disk and sda1/2/5 are the partitions of the hard disk and /dev/sdb is the Kingston USB drive connected.\n$ lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTS sda 8:0 0 119.2G 0 disk ├─sda1 8:1 0 118.3G 0 part / ├─sda2 8:2 0 1K 0 part └─sda5 8:5 0 976M 0 part [SWAP] sdb 8:16 1 28.9G 0 disk sr0 11:0 1 1024M 0 rom Suppose if there are multiple USB sticks attached to mutiple physical USB ports how to know which device names is mapped to which USB port ?\nIf there are multiple USB’s attached how do we get to know USB drive’s device file and to which port that USB is connected ?\nThe answer is by /dev/disk/* Everything in GNU/Linux is either a file or a directory,so even the disk are represented as files in GNU/Linux.\n$ ls -ltrh /dev/disk/ total 0 drwxr-xr-x 2 root root 100 Aug 28 12:28 by-partuuid drwxr-xr-x 2 root root 100 Aug 29 09:49 by-uuid drwxr-xr-x 2 root root 260 Aug 29 09:49 by-path drwxr-xr-x 2 root root 60 Aug 29 09:49 by-label drwxr-xr-x 2 root root 160 Aug 29 09:49 by-id drwxr-xr-x 2 root root 260 Aug 29 09:49 by-diskseq The USB disks can be identified by the Partition UUID, UUID of the disk, by path, by label of the disk and also by disk sequence.\nBy UUID(Universally Unique Identifier) by uuid$ cat /etc/fstab UUID=3341b336-0c26-4079-b3aa-faca8e2dd8b6 / ext4 errors=remount-ro 0 1 UUID=53b53d97-b5e4-43fe-b560-2a01f119b6cf none swap sw 0 0 /dev/sr0 /media/cdrom0 udf,iso9660 user,noauto 0 0 $ ls -ltrh /dev/disk/by-uuid/ total 0 lrwxrwxrwx 1 root root 10 Aug 22 10:40 3341b336-0c26-4079-b3aa-faca8e2dd8b6 -\u003e ../../sda1 lrwxrwxrwx 1 root root 10 Aug 22 10:40 53b53d97-b5e4-43fe-b560-2a01f119b6cf -\u003e ../../sda5 lrwxrwxrwx 1 root root 9 Aug 29 09:49 2010-10-06-11-43-04-00 -\u003e ../../sdb The device /dev/disk/by-uuid/3341b336-0c26-4079-b3aa-faca8e2dd8b6 is simply a symbolic link to actual an device,the reason being this is device name may change depending whether disk is attached or not,whereas these links will point to the same drive,so henceforth safer to use.\nBy-Label by-label$ ls -ltrh /dev/disk/by-label/ total 0 lrwxrwxrwx 1 root root 9 Aug 29 09:49 VINAY-USB -\u003e ../../sdb Labels are easy, it avoids confusion in identifying disk, instead of remembering /dev/sda device file names.\nBy-Path by-path$ ls -ltrh /dev/disk/by-path/ total 0 lrwxrwxrwx 1 root root 9 Aug 22 10:40 pci-0000:00:1f.2-ata-2.0 -\u003e ../../sda lrwxrwxrwx 1 root root 9 Aug 22 10:40 pci-0000:00:1f.2-ata-2 -\u003e ../../sda lrwxrwxrwx 1 root root 10 Aug 22 10:40 pci-0000:00:1f.2-ata-2-part2 -\u003e ../../sda2 lrwxrwxrwx 1 root root 10 Aug 22 10:40 pci-0000:00:1f.2-ata-2.0-part2 -\u003e ../../sda2 lrwxrwxrwx 1 root root 10 Aug 22 10:40 pci-0000:00:1f.2-ata-2-part1 -\u003e ../../sda1 lrwxrwxrwx 1 root root 10 Aug 22 10:40 pci-0000:00:1f.2-ata-2.0-part1 -\u003e ../../sda1 lrwxrwxrwx 1 root root 10 Aug 22 10:40 pci-0000:00:1f.2-ata-2-part5 -\u003e ../../sda5 lrwxrwxrwx 1 root root 10 Aug 22 10:40 pci-0000:00:1f.2-ata-2.0-part5 -\u003e ../../sda5 lrwxrwxrwx 1 root root 9 Aug 22 10:40 pci-0000:00:1f.2-ata-3.0 -\u003e ../../sr0 lrwxrwxrwx 1 root root 9 Aug 22 10:40 pci-0000:00:1f.2-ata-3 -\u003e ../../sr0 lrwxrwxrwx 1 root root 9 Aug 29 09:49 pci-0000:00:14.0-usb-0:4.2:1.0-scsi-0:0:0:0 -\u003e ../../sdb Here /dev/sdb is the USB device attached and “pci-0000:00:14.0-usb-0:4.2:1.0-scsi-0:0:0:0” file which represents the USB device describes that the USB device is connected from PCI bus to SCSI adapter.“by-path” is the pci path of the disk device. this device file name is created depending on the shortest physical path to the device. “/dev/sda” the first SCSI drive on the first SCSI bus,/dev/sdb is the second SCSI drive and /dev/sdc is the third SCSI drive and so on.\n:wq "},"title":"Mapping of Physical USB ports to Device Name on GNU/Linux"},"/docs/interception-vimproved/":{"data":{"":"","#":"Setting up Interception Vimproved on Debian Bookworm I started learning vim few months ago and wanted to try vim key bindings like shortcuts on my laptop after trying a mechanical hackable keyboard.\nInterception Vimproved is a plugin for interception-tools which combines both caps2esc and space on hold work as special fn key. This blog post shows how to setup interception-vimproved using interception-tools on Debian Bookworm.\nStep 1: Dependencies Installing Dependencies to build interception-vimproved on Debian Bookworm GNU/Linux\nsudo apt install interception-tools meson libyaml-cpp-dev cmake interception-tools is a small set of tools for input events of devices,that can be used to customize the behaviour of input keyboard mappings.\nThe advantage of interception-tools operates at lower level compared to xmodmap by using libevdev and libudev.\nStep 2: Clone \u0026 Build Clone interception-vimproved repository and build\n$ git clone \"https://github.com/maricn/interception-vimproved\" $ cd interception-vimproved $ sudo make install Clone the git repository and change the directory, and then launch a make install command to build.\nStep 3: Configuration Create a new file called udevmon.yaml in /etc/interception and paste the following contents into the file /etc/interception/udevmon.yaml\n- JOB: \"interception -g $DEVNODE | interception-vimproved /etc/interception-vimproved/config.yaml | uinput -d $DEVNODE\" DEVICE: NAME: \".*((k|K)(eyboard|EYBOARD)).*\" udevmon.yaml is like a job specification for udevmon,specifying that it matches with (k|K)(eyboard|EYBOARD)) input device.\nℹ️ I haven’t tested this for an External Keyboard Input device,but works fine for the built-in keyboard of the laptop. Step 4: Reload udevmon Reload udevmon using systemctl\n$ sudo systemctl restart udevmon Hack around the config To change any keybindings or to add new mappings the config file is present in config.yaml located in /etc/interception-vimproved/ when a sudo make install is launched the config file is copied to /etc/interception-vimproved/config.yaml.\nmy config.yaml has the below shortcuts\n/etc/interception-vimproved/config.yaml- intercept: KEY_CAPSLOCK ontap: KEY_ESC onhold: KEY_LEFTCTRL - intercept: KEY_ENTER # not necessary: ontap: KEY_ENTER is inferred if left empty onhold: KEY_RIGHTCTRL # this is a layer. hold space (onhold) contains several remappings - intercept: KEY_SPACE onhold: # special chars - from: KEY_E to: KEY_ESC # alternative syntax - {from: KEY_D, to: KEY_DELETE} - {from: KEY_B, to: KEY_BACKSPACE} # vim home row - {from: KEY_H, to: KEY_LEFT} - {from: KEY_J, to: KEY_DOWN} - {from: KEY_K, to: KEY_UP} - {from: KEY_L, to: KEY_RIGHT} # vim above home row - {from: KEY_Y, to: KEY_HOME} - {from: KEY_U, to: KEY_PAGEDOWN} - {from: KEY_I, to: KEY_PAGEUP} - {from: KEY_O, to: KEY_END} # number row, to F keys - {from: KEY_1, to: KEY_F1} - {from: KEY_2, to: KEY_F2} - {from: KEY_3, to: KEY_F3} - {from: KEY_4, to: KEY_F4} - {from: KEY_5, to: KEY_F5} - {from: KEY_6, to: KEY_F6} - {from: KEY_7, to: KEY_F7} - {from: KEY_8, to: KEY_F8} - {from: KEY_9, to: KEY_F9} - {from: KEY_0, to: KEY_F10} - {from: KEY_MINUS, to: KEY_F11} - {from: KEY_EQUAL, to: KEY_F12} # xf86 audio - {from: KEY_M, to: KEY_MUTE} - {from: KEY_COMMA, to: KEY_VOLUMEDOWN} - {from: KEY_DOT, to: KEY_VOLUMEUP} # mouse navigation - {from: BTN_LEFT, to: BTN_BACK} - {from: BTN_RIGHT, to: BTN_FORWARD} Interception-tools is packaged on debian,interception-vimproved is not, that is the reason we are building the source of interception-vimproved,hopefully i’ll try packaging it !.\nArch has interception-tools already packaged here is the link\n:wq #until next time "},"title":"Interception Vimproved"},"/docs/ldap/":{"data":{"":"Documenting stuff learning about OpenLDAP with two types of configuration, the traditional slapd.conf and slapd.d way of configuring."},"title":"LDAP"},"/docs/ldap/introduction/":{"data":{"":"","#":"Directory Service ℹ️ Difference between a folder and a directory Folder is for grouping items. Directory has index. It is for finding specific item,Directory is a filesystem concept. In simple terms think directory like a telephone directory which is in a hierarchial structure. The term directory service refers to the collection of software, hardware, and processes that store information about an enterprise, subscribers, or both, and make that information available to users. A directory service consists of at least one instance of Directory Server and at least one directory client program. Client programs can access names, phone numbers, addresses, and other data stored in the directory service.\nA directory is similar to database,which is attribute-based data;where data is read more often than write.\nDirectory Server provides Global Directory Services which means it provides information to wide variety of applications,rather than using databases with different applications,which is very hard to administrate.Directory server is a single solution to manage the same information ℹ️ For example, an organization has three different applications running like nextcloud,email and matrix server and all the applications are accessed by same credentials,if separate database schema’s are used for each application it would be hard to manage,if user requesting a password change in one application maybe not be replicated into another application;this problem is solved single,centralized repository of directory information. LDAP provides a common language that client applications and servers use to communicate with one another. LDAP is a “lightweight” version of the Directory Access Protocol (DAP)\nLDAP vs Database How often does your data change? Directory servers are used for reads,if your data changes often and have many write operations directory service is not a ideal choice,RDBMS would be the ideal choice. Type of Data? If data is defined in Key:Value pair or Attribute:Value pair, Directory service would be the best choice,like user profile. Data in Hierarchial tree like structure If data can be modeled into a tree like structure,accessing the parent and child node in the tree,directory service The read:write ratio in LDAP is of 500:1 so more number of read operations are done than the write/update operations.\nOpenLDAP LDAP stands for Lightweight Directory Access Protocol, for accessing directory services.OpenLDAP is the implementation of the LDAP protocol,is a communications protocol that defines the methods in which a directory service can be accessed. The LDAP information model is based on entries, which is a collection of attributes that has a globally unique Distinguished Name(DN) OpenLDAP is the implementation of the LDAP protocol which belong to User Management and Authentication in tech.\nThe LDAP protocol both authenticates and authorize’s users to their resources.The protocol authenticates users with a bind operation that allows users to communicate with LDAP directory then authorizes the authenticated user to resources they need if they have access that are defined in rules.Once a user is successfully authenticated, they need to be authorized to access the resource(s) requested. With OpenLDAP, for example, users belong to groups that can be assigned different permissions. If the authenticating user is assigned the correct permissions to access a certain resource, the LDAP protocol will authorize them to it; if not, the protocol will deny access.\nLDAP Data components Directory: an LDAP server\nDIT: the tree of entries stored within a directory server\nAttributes\nData in LDAP system is stored in elements called attributes,like Key Value pair.Data in the attribute must match to the type defined in the attribute’s initial declaration.\nmail: user@example.com dc:example,dc:com Entries Attributes by themselves are not useful, a group or collection of attributes under a name represents an entry.\ndn: ou=people,dc=example,dc=com objectClass: person sn: Ramesh cn: Varma An example entry displayed in LDIF ( LDAP Data Interchange Format).\n$ cat ldif/user.ldif dn: uid=vinay.m,ou=People,dc=vinay,dc=im objectClass: top objectClass: inetOrgPerson uid: vinay.m cn: vinay sn: m userPassword: test ou: People dn: uid=akshay,ou=People,dc=vinay,dc=im objectClass: top objectClass: inetOrgPerson uid: akshay cn: akshay sn: p userPassword: test ou: People ObjectClass Object class: a collection of required (MUST) and optional (MAY) attributes. Object classes are further subdivided into STRUCTURAL and AUXILIARY classes, and they may inherit from each other.Every entry has a structural Object class which indicates what type of object an entry is and also can have more auxiliary object that have additional characteristics for that entry.\nThe ObjectClass definitions are stored in the schema files.Object class must have an object identifier (OID) Object classes may also list a set of required attribute types (so that any entry with that object class must also include those attributes) and/or a set of optional attribute types (so that any entry with that object class may optionally include those attributes).OID’s are sequence of numbers separated by periods(.), “1.2.840.113556.1.4.473”\nSchema Schema’s define the directory, specifying the configuration of the directories including syntax,object classes,attribute types and matching rules.\nReferences https://access.redhat.com/documentation/en-us/red_hat_directory_server/11/html/deployment_guide/introduction_to_directory_services\nhttps://www.zytrax.com/books/ldap\nhttps://tylersguides.com/guides/openldap-how-to-add-a-user/\nhttps://www.zytrax.com/books/ldap/"},"title":"Introduction"},"/docs/ldap/slapd-conf/":{"data":{"":"","#":"slapd - Standalone LDAP Daemon slapd is a LDAP directory server,which stands for Standalone LDAP daemon.Providing simple auth and security layer.\n$ sudo apt install slapd ldapvi ldap-utils ⚠️ when asked for administration password prompt during installation just press Enter,we reconfigure slapd using dpkg-reconfigure after the installation. $sudo dpkg-reconfigure slapd ℹ️ Reconfiguration:\nOmit initial LDAP server config : No we obviously want to create intial configuration. DNS Domain Name : domain name to build the base DN of LDAP directory in this case we are choosing vinay.im. Organization Name: Type down the organization name( here XYZ Pvt Ltd) Choose an Admin Password of your choice( for tutorial purpose i’ve choosed test) and choose MDB as backend database If asked to purge database when slapd is removed we choose No,will be helpful when we want to switch to a different LDAP server. Choose Yes if you want to backup the current existing database to /var/backups. To have a look at the LDAP database , simple execute slapcat with sudo privileges.\n$ sudo slapcat$ sudo slapcat dn: dc=vinay,dc=im objectClass: top objectClass: dcObject objectClass: organization o: XYZ Pvt Ltd dc: vinay structuralObjectClass: organization entryUUID: 8057316c-ed6e-103d-8b93-b9da23579469 creatorsName: cn=admin,dc=vinay,dc=im createTimestamp: 20230922083350Z modifiersName: cn=admin,dc=vinay,dc=im modifyTimestamp: 20230922083350Z ℹ️ Config files are present in /etc/ldap directory.\nSchemas can be added within the slap.d directory for server customization.\nDatabase is stored in /var/lib/ldap having two files data.mdb and lock.mdb. $ sudo cp /usr/share/doc/slapd/examples/slapd.conf /etc/ldap/ Copy the example config file slapd.conf to /etc/ldap, and replace DNS domain components dc=example to dc=vinay and dc=com to dc=im everywhere in the config, also update /etc/default/slapd from SLAPD_CONF to SLAPD_CONF=/etc/ldap/slapd.conf and update slapd service by sudo systemctl restart slapd\nIn /etc/ldap/slapd.conf under suffix \"dc=vinay,dc=com\" add the following lines\nrootdn \"cn=admin,dc=vinay,dc=com\" rootpw \"test\" Restart the slapd service again.\n$ sudo systemctl restart slapd ldapsearch ldapsearch anonymous query$ldapsearch -x -b \"dc=vinay,dc=im\" # vinay.im dn: dc=vinay,dc=im objectClass: top objectClass: dcObject objectClass: organization o: XYZ Pvt Ltd dc: vinay # search result search: 2 result: 0 Success # numResponses: 2 ldapsearch authenticating with admin user$ ldapsearch -D cn=admin,dc=vinay,dc=im -w test -b dc=vinay,dc=im # extended LDIF # # LDAPv3 # base \u003cdc=vinay,dc=im\u003e with scope subtree # filter: (objectclass=*) # requesting: ALL # # vinay.im dn: dc=vinay,dc=im objectClass: top objectClass: dcObject objectClass: organization o: XYZ Pvt Ltd dc: vinay # search result search: 2 result: 0 Success # numResponses: 2 # numEntries: 1 -D {dn} / --bindDN {dn} — The DN to use to bind to the directory server when performing simple authentication,to use the distinguished binddn name to bind the LDAP directory. -w - this option is used to provide the password on the command line for auth, -W option is used to ask for prompt for typing invisible password without actualling having to type the pass on cli. -b - search base as the starting point for the search instead of default. -x option in ldapsearch is used for simple authentication instead of SASL. The above command search’s through the ldap directory server with admin distinguished name providing password with the -w option and setting the searchbase to start from the rootdn.\n– To list all users on ldap\n$ ldapsearch -D \"cn=admin,dc=vinay,dc=com\" -W -b \"dc=vinay,dc=com\" $ slapcat lists all users from the base dn\nAdding OU (Organization Unit) Organizational units (OUs) are used to organize entries within the directory tree and can be used to delegate administrative responsibilities within your organization. It’s important to keep your directory organized and well-structured from the beginning; otherwise it will quickly become unwieldy and difficult to manage.\nCreate a directory called ldif(LDAP Interchange Format) in /etc/ldap and create a file called people.ldif and paste the following contents.\n$ cat /etc/ldap/ldif/people.ldif dn: ou=People,dc=vinay,dc=com ou: People cn: people sn: people objectClass: top objectClass: inetOrgPerson $ ldapadd -D cn=admin,dc=vinay,dc=im -w test -f /etc/ldap/ldif/people.ldif adding new entry \"ou=People,dc=vinay,dc=im\" now slapcat command shows the OU added within the command output.\nAdd new User Adding new user within the newly created OU(Organizational Unit)\n/etc/ldap/john.ldif# cat john.ldif dn: uid=john,ou=People,dc=vinay,dc=com objectClass: top objectClass: inetOrgPerson uid: john cn: john ou: People sn: abraham mail: john@vinay.com userPassword: john Adding the .ldif file using ldapadd command\n$ sudo ldapadd -D \"cn=admin,dc=vinay,dc=com\" -W -f john.ldif Enter LDAP Password: adding new entry \"uid=john,ou=People,dc=vinay,dc=com\" Read entries within OU as admin Now we have added an OU and a user john to People OU,lets try to ldapsearch the users within the OU as admin\ndisplay users of an OU as admin$ ldapsearch -D \"cn=admin,dc=vinay,dc=com\" -w vinay.com -b \"ou=People,dc=vinay,dc=com\" # extended LDIF # # LDAPv3 # base \u003cou=People,dc=vinay,dc=com\u003e with scope subtree # filter: (objectclass=*) # requesting: ALL # # People, vinay.com dn: ou=People,dc=vinay,dc=com ou: People cn: people sn: people objectClass: top objectClass: inetOrgPerson # john, People, vinay.com dn: uid=john,ou=People,dc=vinay,dc=com objectClass: top objectClass: inetOrgPerson uid: john cn: john ou: People ou: Support sn: abraham mail: john@vinay.com userPassword:: am9obg== Read entries within OU as normal user. $ ldapsearch -D \"uid=john,ou=People,dc=vinay,dc=com\" -w john -b \"ou=People,dc=vinay,dc=com\" # extended LDIF # # LDAPv3 # base \u003cou=People,dc=vinay,dc=com\u003e with scope subtree # filter: (objectclass=*) # requesting: ALL # # People, vinay.com dn: ou=People,dc=vinay,dc=com ou: People cn: people sn: people objectClass: top objectClass: inetOrgPerson # john, People, vinay.com dn: uid=john,ou=People,dc=vinay,dc=com objectClass: top objectClass: inetOrgPerson uid: john cn: john ou: People ou: Support sn: abraham mail: john@vinay.com userPassword:: am9obg== Modifying existing entries Using ldapmodify to update entries. Now to modify an already added record we use ldapmodify and the attributes that are to be modified are put into a separate file,here john-modify.ldif and to demonstrate here an OU Support is added to the existing entry,along with People OU.\njohn-modify.ldif$ cat /etc/ldap/ldif/john-modify.ldif dn: uid=john,ou=People,dc=vinay,dc=com changetype: modify add: ou ou: Support ldapmodify command for john-modify.ldif$ ldapmodify -D \"cn=admin,dc=vinay,dc=com\" -W -f john-modify.ldif Enter LDAP Password: modifying entry \"uid=john,ou=People,dc=vinay,dc=com\" Now running a slapcat command shows the updated OU Support\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 dn: uid=john,ou=People,dc=vinay,dc=com objectClass: top objectClass: inetOrgPerson uid: john cn: john ou: People ou: Support sn: abraham mail: john@vinay.com userPassword:: am9obg== structuralObjectClass: inetOrgPerson entryUUID: 50ea0ea8-f23d-103d-816b-4d9c39504958 creatorsName: cn=admin,dc=vinay,dc=com createTimestamp: 20230928112421Z entryCSN: 20230928120656.291224Z#000000#000#000000 modifiersName: cn=admin,dc=vinay,dc=com modifyTimestamp: 20230928120656Z 2.Using ldapvi to update LDAP entries with a text editor.\nldapvi example$ ldapvi -d --host vinay.im ldapvi is a ldap client using which we can search,modify and delete entries which is easier than ldapmodify instead of adding the updated records in a separate ldif file. ldapvi prompts to open text editor to modify entries,just similar to text editor.\nThe above command will bind anonmously to hostname, here the hostname is vinay.im.After making necessary changes in the entry save from the text editor.\n# ldapvi -d --host nextcloud.vinay.com 3 entries read add: 0, rename: 0, modify: 1, delete: 0 Action? [yYqQvVebB*rsf+?] b --- Login --- Login --- Login Type M-h for help on key bindings. Filter or DN: cn=admin,dc=vinay,dc=im Password: ***** Bound as cn=admin,dc=vinay,dc=im. add: 0, rename: 0, modify: 1, delete: 0 Action? [yYqQvVebB*rsf+?] y Done. after saving and exiting from text editor, an interactive bash prompt [yYqQvVebB*rsf+?]\ny to commit changes.\ne to edit changes.\nv to view changes as LDIF change records.\nb to show login and rebind - we are trying to auth from admin and save the changes to LDAP entries.\n[Reference serverfault] https://serverfault.com/questions/290296/ldapadd-ldapmodify-clarifications-needed-about-these-commands #### Verifying the ```slapd.conf``` Configuration file ```bash $sudo slaptest -v -f /etc/ldap/slapd.conf config file testing succeeded -f : Specifying an alternative configuration file.\n-v : enable verbose mode.\nConventions in OpenLDAP dn - Distinguished Name\nRDN - Relative Distinguished Name\ncn - Common Name\ndc - Domain Component\nmail - Email Address\nou - Organization Unit\nldif - LDAP Data Interchange Format\nldap - Lightweight Directory Access Protocol\nReferences https://access.redhat.com/documentation/en-us/red_hat_directory_server/11/html/deployment_guide/introduction_to_directory_services\nhttps://www.zytrax.com/books/ldap\nhttps://tylersguides.com/guides/openldap-how-to-add-a-user/\nhttps://www.zytrax.com/books/ldap/"},"title":"OpenLDAP (slapd.conf)"},"/docs/ldap/terminology/":{"data":{"":"","#":"Terminology used in LDAP DIT Directory Information Tree root entry {Object}(Also called Objects) objectclass 1 This object class consists of zero or more attributes objectclass 2 This object class consists of zero or more attributes entry {Object} ObjectClass ObjectClass Data is represented as hierarchy of objects,each of which is called entry.The resulting tree structure is called a Directory Information Tree (DIT). The top entry of the tree is called root.\nEach entry in the tree has one parent entry and zero or more child entries.\nEach entry is composed of one or more objectClasses. -\u003e These objectClasses contain zero or more attributes.\nThese attributes have names just like values.\nObjectClasses. Objectclasses is like a container of attributes,where each objectClass has a unique name.There exists a predefined set of ObjectClasses,each of which contains lot of attributes.\nCharacteristics of ObjectClasses:\nobjectClasses defines whether the attribute member should be MUST or MAY be present. objectClass types: STRUCTURAL,AUXILIARY,ABSTRACT, and there should be atleast one STRUCTURAL objectClass with zero or more AUXILIARY objectClasses. objectClass inherits properties and characteristics from its parent objectClass (including its attributes). Attributes. Attributes contains values,which are present within the objectClass,each attribute define the data type. Attributes are mostly defined in key=value pair.\nAttributes can be optional MAY or mandatory MUST defined in that object class.If it is inherited by multiple objectClasses, in one objectClass it can be mandatory in another object class it can be optional, this is defined by the objectClass.\nAttributes can be SINGLE or MUTLI valued.\nsome examples for attributes like cn aliased commonName which is within the objectClass person,organizationalPerson and so on..\nAnother example is dc aliased domainComponent which is present under the objectClass dcObject.\n# Entry Level Hierarchy dn: dc=example,dc=com dc: example description: The best company in the whole world objectClass: dcObject objectClass: organization o: Example, Inc. ## FIRST Level hierarchy - people # this is an ENTRY sequence and is preceded by a BLANK line dn: ou=people, dc=example,dc=com ou: people description: All people in organisation objectClass: organizationalUnit ## SECOND Level hierarchy - people entries # this is an ENTRY sequence and is preceded by a BLANK line dn: cn=Robert Smith,ou=people,dc=example,dc=com objectclass: inetOrgPerson cn: Robert Smith cn: Robert sn: Smith uid: rsmith mail: robert@example.com mail: r.smith@example.com ou: sales DN attribute is the sum of all the RDN (Root Distinguished Name)"},"title":"Terminology"},"/docs/lvm/":{"data":{"":"","#":"LVM is a disk management tool, which is a device mapper for linux kernel,managing storage systems than the traditional partition based one.In LVM instead of creating partitions you create logical volumes, /boot cannot use logical volumes.\nLVM offers features like striping,mirroring,snapshotting.LVM functions by layering abstractions on top of physical storage devices.\nMain components of LVM are\nPhysical Volumes: physical block devices which are set a hard disks,physical volumes are regular storage devices,prefixed with pv.. Volume Groups: LVM combines physical volumes into storage pools known as volume groups,LVM abstracts the function there by making a unified logical devices with one ,prefixed with vg... Logical Volumes: a volume group is sliced into a number of logical volumes.Logical volumes are functionally equivalent to partitions on a physical disks,but with more advanced features. Basic LVM Commands Making Physical Devices as Physical Volumes. lvmdiskscan - returns the number of block devices to which LVM can interact. vinay@kevin ~\u003e sudo lvmdiskscan /dev/sda [ 57.30 GiB] /dev/nvme0n1p1 [ \u003c464.81 GiB] /dev/nvme0n1p5 [ 975.00 MiB] /dev/sdb [ \u003c28.87 GiB] 2 disks 2 partitions 0 LVM physical volume whole disks 0 LVM physical volumes Here we are creating a physical volume for the disks /dev/sda and /dev/sdb.\npvcreate - command that is used to initialize physical disks to physical volumes for LVM, this will write an LVM header to the devices to indicate that they are ready to be added to volume group. vinay@kevin ~\u003e sudo pvcreate /dev/sda /dev/sdb Physical volume \"/dev/sda\" successfully created. Physical volume \"/dev/sdb\" successfully created. pvs - displays information about physical volumes. vinay@kevin ~\u003e sudo pvs PV VG Fmt Attr PSize PFree /dev/sda lvm2 --- 57.30g 57.30g /dev/sdb lvm2 --- \u003c28.87g \u003c28.87g the disks /dev/sda and /dev/sdb is of the size 57G and 28G respectively,hence these can be added to the volume groups.\nAdd Physical Volumes to Volume Group. vgcreate - creates a volume group vinay@kevin ~\u003e sudo vgcreate VolGrpLvm /dev/sda /dev/sdb Volume group \"VolGrpLvm\" successfully created a volume group with the name, VolGrpLvm is created\nvgs - displays information about volume groups vinay@kevin ~\u003e sudo vgs VG #PV #LV #SN Attr VSize VFree VolGrpLvm 2 0 0 wz--n- 86.16g 86.16g Here the two phyical volumes are converted into a pool of storage,making a total of 86G, from this pool of storage,these are sliced to several logical volumes.\nCreating Logical Volumes from the Volume Group Pool. lvcreate - creating a logical volume from the volume group vinay@kevin ~\u003e sudo lvcreate -L 10G -n backup VolGrpLvm Logical volume \"backup\" created. vinay@kevin ~\u003e sudo lvs LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert backup VolGrpLvm -wi-a----- 10.00g lvcreate is used to create a logical volume from the volume group of storage pool, -L option is used to specify the size of the volume and -n option is used to label the logical volume.\nlvs displays information about the logical volume created.\nSimilarly create another logical volume.\nvinay@kevin ~\u003e sudo lvcreate -L 30G -n college-data VolGrpLvm Logical volume \"college-data\" created. vinay@kevin ~\u003e sudo lvs LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert backup VolGrpLvm -wi-a----- 10.00g college-data VolGrpLvm -wi-a----- 30.00g Format and Mount the logical volumes Formatting the logical volumes.\n$ sudo mkfs.ext4 /dev/VolGrpLvm/backup $ sudo mkfs.ext4 /dev/VolGrpLvm/college-data Mounting the logical volume\nvinay@kevin ~\u003e sudo mkdir -p /mnt/{backup,college-data} vinay@kevin ~\u003e sudo mount /dev/VolGrpLvm/backup /mnt/backup/ vinay@kevin ~\u003e sudo mount /dev/VolGrpLvm/college-data /mnt/college-data/ vinay@kevin ~\u003e lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTS sda 8:0 1 57.3G 0 disk ├─VolGrpLvm-backup 254:0 0 10G 0 lvm /mnt/backup └─VolGrpLvm-college--data 254:1 0 30G 0 lvm /mnt/college-data sdb 8:16 1 28.9G 0 disk nvme0n1 259:0 0 465.8G 0 disk ├─nvme0n1p1 259:1 0 464.8G 0 part / ├─nvme0n1p2 259:2 0 1K 0 part └─nvme0n1p5 259:3 0 975M 0 part [SWAP] Creating mount points in /mnt and mount the volumes onto the mountpoints created.\nOther useful scan and display commands. vinay@kevin ~\u003e sudo pvscan PV /dev/sda VG VolGrpLvm lvm2 [57.30 GiB / 17.30 GiB free] PV /dev/sdb VG VolGrpLvm lvm2 [28.86 GiB / 28.86 GiB free] Total: 2 [86.16 GiB] / in use: 2 [86.16 GiB] / in no VG: 0 [0 ] vinay@kevin ~\u003e sudo lvscan ACTIVE '/dev/VolGrpLvm/backup' [10.00 GiB] inherit ACTIVE '/dev/VolGrpLvm/college-data' [30.00 GiB] inherit vinay@kevin ~\u003e sudo vgscan Found volume group \"VolGrpLvm\" using metadata type lvm2 vinay@kevin ~\u003e s^C vinay@kevin ~\u003e vinay@kevin ~\u003e sudo pvscan PV /dev/sda VG VolGrpLvm lvm2 [57.30 GiB / 17.30 GiB free] PV /dev/sdb VG VolGrpLvm lvm2 [28.86 GiB / 28.86 GiB free] Total: 2 [86.16 GiB] / in use: 2 [86.16 GiB] / in no VG: 0 [0 ] vinay@kevin ~\u003e sudo vgscan Found volume group \"VolGrpLvm\" using metadata type lvm2 vinay@kevin ~\u003e sudo lvscan ACTIVE '/dev/VolGrpLvm/backup' [10.00 GiB] inherit ACTIVE '/dev/VolGrpLvm/college-data' [30.00 GiB] inherit vinay@kevin ~\u003e sudo pvdisplay --- Physical volume --- PV Name /dev/sda VG Name VolGrpLvm PV Size 57.30 GiB / not usable 4.00 MiB Allocatable yes PE Size 4.00 MiB Total PE 14669 Free PE 4429 Allocated PE 10240 PV UUID obDX3S-49P0-0Y2o-Vpr1-zFxV-Tgng-Ov9oEz — Physical volume — PV Name /dev/sdb VG Name VolGrpLvm PV Size \u003c28.87 GiB / not usable 4.00 MiB Allocatable yes PE Size 4.00 MiB Total PE 7389 Free PE 7389 Allocated PE 0 PV UUID 7KAaVc-1H9V-FSsK-n98X-P9SM-IIAw-s9Myce\nvinay@kevin ~\u003e sudo vgdisplay — Volume group — VG Name VolGrpLvm System ID Format lvm2 Metadata Areas 2 Metadata Sequence No 3 VG Access read/write VG Status resizable MAX LV 0 Cur LV 2 Open LV 2 Max PV 0 Cur PV 2 Act PV 2 VG Size 86.16 GiB PE Size 4.00 MiB Total PE 22058 Alloc PE / Size 10240 / 40.00 GiB Free PE / Size 11818 / 46.16 GiB VG UUID P1dIv1-Lk34-Oxjo-ZZoE-81ys-3XnL-5WZotd\nvinay@kevin ~\u003e sudo lvdisplay — Logical volume — LV Path /dev/VolGrpLvm/backup LV Name backup VG Name VolGrpLvm LV UUID CjtnRq-evig-hsY4-avOM-6KVM-a7TT-VeAkDR LV Write Access read/write LV Creation host, time kevin, 2024-01-03 10:41:55 +0530 LV Status available\nopen 1LV Size 10.00 GiB Current LE 2560 Segments 1 Allocation inherit Read ahead sectors auto\ncurrently set to 256 Block device 254:0 — Logical volume — LV Path /dev/VolGrpLvm/college-data LV Name college-data VG Name VolGrpLvm LV UUID f2zixQ-ayec-zrXb-AV35-JaU0-9jz5-9ZrFtk LV Write Access read/write LV Creation host, time kevin, 2024-01-03 10:45:39 +0530 LV Status available\nopen 1LV Size 30.00 GiB Current LE 7680 Segments 1 Allocation inherit Read ahead sectors auto\ncurrently set to 256 Block device 254:1 \u003cbutton class=“code-copy-btn group/copybtn transition-all active:opacity-50 bg-primary-700/5 border border-black/5 text-gray-600 hover:text-gray-900 rounded-md p-1.5 dark:bg-primary-300/10 dark:border-white/10 dark:text-gray-400 dark:hover:text-gray-50” title=“Copy code” Rename a LV Renaming a logical volume using lvrename\nvinay@kevin ~\u003e sudo lvrename /dev/VolGrpLvm/college-data /dev/VolGrpLvm/college Renamed \"college-data\" to \"college\" in volume group \"VolGrpLvm\" vinay@kevin ~\u003e ls /dev/VolGrpLvm/ backup@ college@ Extending a LV To increase the size of the logical volume,we use lvextend command.\nvinay@kevin ~\u003e sudo lvs LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert backup VolGrpLvm -wi-ao---- 10.00g college VolGrpLvm -wi-ao---- 30.00g vinay@kevin ~\u003e sudo lvextend -L+5G /dev/VolGrpLvm/backup Size of logical volume VolGrpLvm/backup changed from 10.00 GiB (2560 extents) to 15.00 GiB (3840 extents). Logical volume VolGrpLvm/backup successfully resized. To increase the size of the volume by specified size use the + character to mention the increase in size.\nTo set the size of the volume see the below example.\nvinay@kevin ~\u003e sudo lvextend -L25G /dev/VolGrpLvm/backup Size of logical volume VolGrpLvm/backup changed from 15.00 GiB (3840 extents) to 25.00 GiB (6400 extents). Logical volume VolGrpLvm/backup successfully resized. vinay@kevin ~\u003e sudo lvs LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert backup VolGrpLvm -wi-ao---- 25.00g college VolGrpLvm -wi-ao---- 30.00g Shrink a LV Can reduce the size of the volume using lvreduce command.\nvinay@kevin ~\u003e sudo lvs LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert backup VolGrpLvm -wi-ao---- 25.00g college VolGrpLvm -wi-ao---- 30.00g vinay@kevin ~\u003e sudo lvreduce -L20G /dev/VolGrpLvm/backup WARNING: Reducing active and open logical volume to 20.00 GiB. THIS MAY DESTROY YOUR DATA (filesystem etc.) Do you really want to reduce VolGrpLvm/backup? [y/n]: y Size of logical volume VolGrpLvm/backup changed from 25.00 GiB (6400 extents) to 20.00 GiB (5120 extents). Logical volume VolGrpLvm/backup successfully resized. vinay@kevin ~\u003e sudo lvs LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert backup VolGrpLvm -wi-ao---- 20.00g college VolGrpLvm -wi-ao---- 30.00g Here,the size of the volume is reduced to 20G.\nRemove an LV Before removing an LV,umount it first and then use the lvremove to remove the volume group.\nvinay@kevin ~\u003e sudo lvremove /dev/VolGrpLvm/backup Do you really want to remove active logical volume VolGrpLvm/backup? [y/n]: y Logical volume \"backup\" successfully removed. Increase Pool storage To increase the size of the volume group we use the command vgextend to increase the size of the storage pool.\nInitially the size of the volume storage pool was 86G and now it is increased to 115G /dev/sdc is the new phyical volume.\nvinay@kevin ~\u003e sudo pvcreate /dev/sdc Physical volume \"/dev/sdc\" successfully created. vinay@kevin ~\u003e sudo vgs VG #PV #LV #SN Attr VSize VFree VolGrpLvm 2 1 0 wz--n- 86.16g 56.16g vinay@kevin ~\u003e sudo vgextend VolGrpLvm /dev/sdc Volume group \"VolGrpLvm\" successfully extended vinay@kevin ~\u003e sudo vgs VG #PV #LV #SN Attr VSize VFree VolGrpLvm 3 1 0 wz--n- \u003c115.03g \u003c85.03g Striping RAID 0: Striping RAID 0,also known as striped set or striped volume,requires a minimum of two disks, the disks are merged into one single large volume and data is stored evenly the disks.This process is called disk striping and involves splitting data into blocks and writing it simultaneously/sequentially on multiple disks. It doesn’t support redundancy,fault tolerance and hence data loss.\nData is stored sequentially\nvinay@kevin ~\u003e sudo lvcreate -L 10G -i2 -I64 -n backup1 VolGrpLvm [sudo] password for vinay: WARNING: ext4 signature detected on /dev/VolGrpLvm/backup1 at offset 1080. Wipe it? [y/n]: y Wiping ext4 signature on /dev/VolGrpLvm/backup1. Logical volume \"backup1\" created. Creating a logical volume with the size 10G, the -i argument is used to mention striping and the number next to the option specifies the striping in how many disks, the -I option in the above command is to specify the size of block of 64kB across two physical volumes.\nIf the striping number across the disks is more than the physical volumes,it fails to create a logical volume,with an exeception saying number of stripes exceeds number of physical volumes.\nvinay@kevin ~\u003e sudo lvcreate -L 5G -i4 -I64 -n backup3 VolGrpLvm Number of stripes (4) must not exceed number of physical volumes (3) In this setup only 3 physical volumes are used,which exceeds the stripe number.\nMirroring RAID 1: Disk Mirroring Keeping a copy of the data within the logical volume is called mirroring,for redundancy and to avoid data loss.\nthe -m option with value 1 creates one copy of the data,therefore having a total of two copies of data within the file system,-m2 creates two mirrors,yielding three copies of the file system.\nvinay@kevin ~\u003e sudo lvcreate -L 5G -m1 -n mirrorLV VolGrpLvm Logical volume \"mirrorLV\" created. Thin Volumes Usually LVM normally allocates blocks when you create a volume,thats thick provisioning.LVM thin pools instead allocates blocks when they are written,this is called thin provisioning. Because volumes can be much larger than physically available space.\nTo remove a physical volume from the existing volume group,use vgreduce vinay@kevin ~ [5]\u003e sudo vgreduce VolGrpLvm /dev/sdc Removed \"/dev/sdc\" from volume group \"VolGrpLvm\" Create new physical volumes using physical disks and create a volume group.\nvinay@kevin ~\u003e sudo pvcreate /dev/sdc /dev/sdd Physical volume \"/dev/sdc\" successfully created. Physical volume \"/dev/sdd\" successfully created. vinay@kevin ~\u003e sudo vgcreate vg_thin /dev/sdc /dev/sdd Volume group \"vg_thin\" successfully created Create a thinpool with the size 5G with chunksize 256K where ```vg_thin`` is the volume group name and creating a pool again within the volume group\nvinay@kevin ~\u003e sudo lvcreate --thin --size 5G --chunksize 256K --poolmetadatasize 1G vg_thin/thin_pool Thin pool volume with chunk size 256.00 KiB can address at most 63.50 TiB of data. Logical volume \"thin_pool\" created. Listing all the logical volumes which displays all the logical volumes\nvinay@kevin ~\u003e sudo lvs -a LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert [lvol0_pmspare] vg_thin ewi------- 1.00g thin_pool vg_thin twi-a-tz-- 5.00g 0.00 1.57 [thin_pool_tdata] vg_thin Twi-ao---- 5.00g [thin_pool_tmeta] vg_thin ewi-ao---- 1.00g Creating 3 logical volumes,while for the second logical volujme volume_2 there is a warning which mentions exceeds the size of thin pool,even though the pool size is 5G,after the creation of the first logical volume volume_1 2G should be remained,since it is thin provisioning, only when data is written blocks are allocated to it,so hence just a warning. Similarly the error comes during the creation of volume_3.\nvinay@kevin ~\u003e sudo lvcreate --thinpool vg_thin/thin_pool --name volume_1 --virtualsize 3G Logical volume \"volume_1\" created. vinay@kevin ~\u003e sudo lvcreate --thinpool vg_thin/thin_pool --name volume_2 --virtualsize 3G WARNING: Sum of all thin volume sizes (6.00 GiB) exceeds the size of thin pool vg_thin/thin_pool (5.00 GiB). WARNING: You have not turned on protection against thin pools running out of space. WARNING: Set activation/thin_pool_autoextend_threshold below 100 to trigger automatic extension of thin pools before they get full. Logical volume \"volume_2\" created. vinay@kevin ~\u003e sudo lvcreate --thinpool vg_thin/thin_pool --name volume_3 --virtualsize 3G WARNING: Sum of all thin volume sizes (9.00 GiB) exceeds the size of thin pool vg_thin/thin_pool (5.00 GiB). WARNING: You have not turned on protection against thin pools running out of space. WARNING: Set activation/thin_pool_autoextend_threshold below 100 to trigger automatic extension of thin pools before they get full. Logical volume \"volume_3\" created. All the logical volumes can be verfied now.\nvinay@kevin ~\u003e sudo lvs -a LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert [lvol0_pmspare] vg_thin ewi------- 1.00g thin_pool vg_thin twi-aotz-- 5.00g 0.00 1.57 [thin_pool_tdata] vg_thin Twi-ao---- 5.00g [thin_pool_tmeta] vg_thin ewi-ao---- 1.00g volume_1 vg_thin Vwi-a-tz-- 3.00g thin_pool 0.00 volume_2 vg_thin Vwi-a-tz-- 3.00g thin_pool 0.00 volume_3 vg_thin Vwi-a-tz-- 3.00g thin_pool 0.00 ","open-----------------1#open                 1":"","open-----------------1-1#open                 1":""},"title":"Logical Volume Manager"},"/docs/nfs/":{"data":{"":"","#":"NFS stands for Network FIle System, is a file system protocol that allows to access files and folders on a remote system,and accessing them like a local storage.The architecture of NFS is client-server architecture,where the files are folders to be accessed are stored on the servers and these file \u0026 folders are accessed by the client machine like a mounted partition.\nWith NFS,its easy to access file,enable special permissions like either read only or read and write,syncing the files and folders across the available clients.\nInstall NFS Server I’m currently on Debian Bookworm, to install the nfs server package just do sudo apt install nfs-kernel-server\n$ cat /etc/issue Debian GNU/Linux 12 \\n \\l $ sudo apt policy nfs-kernel-server nfs-kernel-server: Installed: 1:2.6.2-4 Candidate: 1:2.6.2-4 Version table: *** 1:2.6.2-4 500 500 mirror+file:/etc/apt/mirrors/debian.list bookworm/main amd64 Packages 100 /var/lib/dpkg/status Create a export folder/directory where files and folders are accessed by the clients present on the server, here i have choosed the location /mnt/sharedfolder\n$ sudo mkdir -p /mnt/sharedfolder change the permissions of the folder to 777\nsudo chmod 777 /mnt/sharedfolder\nIt will allow the clients to access the shared folder.\nConfigure Export Directory The configuration file for the NFS server is located at /etc/exports,here can specify directories that are to be shared to clients\n/mnt/sharedfolder 10.22.13.0/24(rw,sync,no_subtree_check) add the above line to /etc/exports, in the form ```directory hostname(options)\nHere /mnt/sharedfolder is the remote folder, 10.22.13.0/24 is the subnet IP where the folder can be accessed across the whole subnet network,this can also be filtered to access from specifc client IP too, and example would be\n/mnt/sharedfolder 10.22.13.101(rw,sync,no_subtree_check) where 10.22.13.101 is the client IP, to which only this IP can access the shared folder,no other IP can access.\nThere are plenty of options to configure the NFS server: ro : directory mounted as read only. rw : directory mounted with read and write permissions. subtree_check – specifies that, in the case of a directory is exported instead of an entire filesystem, the host should verify the location of files and directories on the host filesystem no_subtree_check – specifies that the host should not check the location of the files being accessed within the host filesystem sync – this just ensures that the host keeps any changes uploaded to the shared directory in sync async – ignores synchronization checks in favor of increased speed Exporting the shared directory\nAfter the /etc/exports nfs server is configured,to export the shared directory run the below command and restart nfs-kernel-server\n$ sudo exportfs -a $ sudo systemctl restart nfs-kernel-server Configure the firewall so that the server is open for clients to access the shared content.\n$ sudo ufw allow from 10.22.13.0/24 to any port nfs and again check ufw status\n$ sudo ufw status Status: active To Action From -- ------ ---- 22/tcp ALLOW Anywhere 2049 ALLOW 10.22.13.0/24 22/tcp (v6) ALLOW Anywhere (v6) Configuring Client Once the server and firewall is setup,next thing is to configure the client\nTo configure the client on Debian install the package nfs-common\n$ sudo apt install nfs-common Create a mount point on the client machine for the NFS server’s shared folder\nOn client machine$ sudo mkdir -p /mnt/sharedfolder_client Next step is to mount the remote folder on the client,this can be done in two ways,with the mount command or adding the entry to /etc/fstab\nUsing the mount command On client$ sudo mount 10.22.13.53:/mnt/sharedfolder /mnt/sharedfolder_client where 10.22.13.53 is the local ip of the NFS server,basically mounting /mnt/sharedfolder of the client to /mnt/sharedfolder_client.\nUsing the /etc/fstab way $ cat /etc/fstab # /etc/fstab: static file system information UUID=8f994d1d-8ae8-4dff-aaa5-9aef4574329b / ext4 rw,discard,errors=remount-ro,x-systemd.growfs 0 1 UUID=5F3D-98F1 /boot/efi vfat defaults 0 0 10.22.13.53:/mnt/sharedfolder /mnt/sharedfolder_client nfs4 defaults,user,exec 0 0 where /mnt/sharedfolder_client is the mountpoint on the client,editing any file from the client update’s it on the server,because we have configured to sync across all the mount points,editing any file from the client will update it on the NFS server too."},"title":"NFS-Network File System"},"/docs/rust/":{"data":{"":"","#":"Learning RUST programming language and documenting my learning\nHello World - Rust ! hello_world.rsfn main(){ println!(\"Hello world\") } To compile rust code\n$ rustc hello_world.rs Run the binary\n$ ./hello_world Cargo cargo is rust’s build tool and package manager, to manage dependencies and its versions,basically crates. cargo uses TOML format stands for Tom’s Obvious Minimal language,which is cargo’s configuration format.\nCargo useful commands $ cargo new hello_cargo --vcs=git $ cd hello_cargo on creating a new cargo project the source files are to be present within the src/ directory and also Config.toml file is generated.\ncargo build $cargo build Compiling hello_cargo v0.1.0 (/home/vinay/learn/rust/hello_cargo) Finished dev [unoptimized + debuginfo] target(s) in 0.17s a target/ directory is created\nthe binary is within the target/debug directory\n$ ls target/debug/ build deps examples hello_cargo hello_cargo.d incremental $ ./target/debug/hello_cargo Hello, world! cargo run $ cargo run Finished dev [unoptimized + debuginfo] target(s) in 0.00s Running `target/debug/hello_cargo` Hello, world! instead of two commands of compiling and running the binary, cargo run is a simple command,which compiles and runs the binary\ncargo check compiles the code but does not produce an executable.A\n$ cargo check Checking hello_cargo v0.1.0 (/home/vinay/learn/rust/hello_cargo) Finished dev [unoptimized + debuginfo] target(s) in 0.02s "},"title":"Rust"},"/docs/selfhosting/":{"data":{"":"Self Hosting"},"title":"Self Hosting"},"/docs/selfhosting/nextcloud/":{"data":{"":"","#":"Nextcloud on Debian Nextcloud is a flexible file synchronization and sharing solution.Nextcloud includes Nextcloud server( run on linux) and Nextcloud client.Nextcloud is a Free and Open Source community supported,with all enterprise features. In this doc lets try to install nextcloud server over Nginx and access it over browser client.\nNginx Nginx is Free and Open Source web server which is now also used as reverse proxy,HTTP cache and load balancer.To setup nextcloud we can choose either nginx or apache as webserver. Install and enable nginx service on the server\n$ sudo apt install nginx -y $ sudo systemctl start nginx $ sudo systemctl enable nginx Installation Steps Prerequisites for mannual installation. https://docs.nextcloud.com/server/latest/admin_manual/installation/source_installation.html#prerequisites-for-manual-installation\nInstall php8.0 from deb.sury.org Installing PHP from a third party repository https://deb.sury.org/ which contains the deb packaged version of the latest php and its modules. This repository supports both Ubuntu and Debian.\nif [ \"$(whoami)\" != \"root\" ]; then SUDO=sudo fi ${SUDO} apt-get update ${SUDO} apt-get -y install lsb-release ca-certificates curl ${SUDO} curl -sSLo /usr/share/keyrings/deb.sury.org-php.gpg https://packages.sury.org/php/apt.gpg ${SUDO} sh -c 'echo \"deb [signed-by=/usr/share/keyrings/deb.sury.org-php.gpg] https://packages.sury.org/php/ $(lsb_release -sc) main\" \u003e /etc/apt/sources.list.d/php.list' ${SUDO} apt-get update $ sudo apt policy php8.0 # check for any latest updated php package Install the packages mentionedsudo apt install php8.0-xmlreader php8.0-curl php8.0-gd php8.0-mbstring php8.0-zip php8.0-fpm Database connectors (either choose from MySQL/MariaDB and Postgresql)\nmysql database connector$ sudo apt install mariadb-server php8.0-mysql Caching\nphp modules required for caching$sudo apt install redis php8.0-redis https://docs.nextcloud.com/server/latest/admin_manual/installation/nginx.html\nvim /etc/php/8.0/cli/php.ini update date.timezone = Asia/Kolkata cd /var/www sudo wget https://download.nextcloud.com/server/releases/latest.zip sudo chown www-data:www-data /var/www/nextcloud -R \u003e create database nextcloud_db; \u003e create user nextcloud_user@localhost identified by 'deeproot'; \u003e grant all privileges on nextcloud_db.* to nextcloud_user@localhost identified by 'deeproot'; \u003e flush privileges \u003e exit Nginx Configuration file. paste the following in /etc/nginx/sites-enabled/nextcloud and remove any default files present. and also make a symlink from /etc/nginx/sites-enabled/nextcloud to /etc/nginx/sites-available/nextcloud\nhost nextcloud.vinay.com\nupstream php-handler { #server 127.0.0.1:9000; server unix:/var/run/php/php8.0-fpm.sock; } # Set the `immutable` cache control options only for assets with a cache busting `v` argument map $arg_v $asset_immutable { \"\" \"\"; default \"immutable\"; } server { listen 80; server_name nextcloud.vinay.com; # Path to the root of your installation root /var/www/nextcloud; # Use Mozilla's guidelines for SSL/TLS settings # https://mozilla.github.io/server-side-tls/ssl-config-generator/ #ssl_certificate /etc/ssl/nginx/cloud.example.com.crt; #ssl_certificate_key /etc/ssl/nginx/cloud.example.com.key; # Prevent nginx HTTP Server Detection server_tokens off; # HSTS settings # WARNING: Only add the preload option once you read about # the consequences in https://hstspreload.org/. This option # will add the domain to a hardcoded list that is shipped # in all major browsers and getting removed from this list # could take several months. #add_header Strict-Transport-Security \"max-age=15768000; includeSubDomains; preload\" always; # set max upload size and increase upload timeout: client_max_body_size 512M; client_body_timeout 300s; fastcgi_buffers 64 4K; # Enable gzip but do not remove ETag headers gzip on; gzip_vary on; gzip_comp_level 4; gzip_min_length 256; gzip_proxied expired no-cache no-store private no_last_modified no_etag auth; gzip_types application/atom+xml text/javascript application/javascript application/json application/ld+json application/manifest+json application/rss+xml application/vnd.geo+json application/vnd.ms-fontobject application/wasm application/x-font-ttf application/x-web-app-manifest+json application/xhtml+xml application/xml font/opentype image/bmp image/svg+xml image/x-icon text/cache-manifest text/css text/plain text/vcard text/vnd.rim.location.xloc text/vtt text/x-component text/x-cross-domain-policy; # Pagespeed is not supported by Nextcloud, so if your server is built # with the `ngx_pagespeed` module, uncomment this line to disable it. #pagespeed off; # The settings allows you to optimize the HTTP2 bandwitdth. # See https://blog.cloudflare.com/delivering-http-2-upload-speed-improvements/ # for tunning hints client_body_buffer_size 512k; # HTTP response headers borrowed from Nextcloud `.htaccess` #add_header Referrer-Policy \"no-referrer\" always; #add_header X-Content-Type-Options \"nosniff\" always; #add_header X-Download-Options \"noopen\" always; #add_header X-Frame-Options \"SAMEORIGIN\" always; #add_header X-Permitted-Cross-Domain-Policies \"none\" always; #add_header X-Robots-Tag \"noindex, nofollow\" always; #add_header X-XSS-Protection \"1; mode=block\" always; # Remove X-Powered-By, which is an information leak fastcgi_hide_header X-Powered-By; # Add .mjs as a file extension for javascript # Either include it in the default mime.types list # or include you can include that list explicitly and add the file extension # only for Nextcloud like below: include mime.types; types { text/javascript js mjs; } # Specify how to handle directories -- specifying `/index.php$request_uri` # here as the fallback means that Nginx always exhibits the desired behaviour # when a client requests a path that corresponds to a directory that exists # on the server. In particular, if that directory contains an index.php file, # that file is correctly served; if it doesn't, then the request is passed to # the front-end controller. This consistent behaviour means that we don't need # to specify custom rules for certain paths (e.g. images and other assets, # `/updater`, `/ocm-provider`, `/ocs-provider`), and thus # `try_files $uri $uri/ /index.php$request_uri` # always provides the desired behaviour. index index.php index.html /index.php$request_uri; # Rule borrowed from `.htaccess` to handle Microsoft DAV clients location = / { if ( $http_user_agent ~ ^DavClnt ) { return 302 /remote.php/webdav/$is_args$args; } } location = /robots.txt { allow all; log_not_found off; access_log off; } # Make a regex exception for `/.well-known` so that clients can still # access it despite the existence of the regex rule # `location ~ /(\\.|autotest|...)` which would otherwise handle requests # for `/.well-known`. location ^~ /.well-known { # The rules in this block are an adaptation of the rules # in `.htaccess` that concern `/.well-known`. location = /.well-known/carddav { return 301 /remote.php/dav/; } location = /.well-known/caldav { return 301 /remote.php/dav/; } location /.well-known/acme-challenge { try_files $uri $uri/ =404; } location /.well-known/pki-validation { try_files $uri $uri/ =404; } # Let Nextcloud's API for `/.well-known` URIs handle all other # requests by passing them to the front-end controller. return 301 /index.php$request_uri; } # Rules borrowed from `.htaccess` to hide certain paths from clients location ~ ^/(?:build|tests|config|lib|3rdparty|templates|data)(?:$|/) { return 404; } location ~ ^/(?:\\.|autotest|occ|issue|indie|db_|console) { return 404; } # Ensure this block, which passes PHP files to the PHP process, is above the blocks # which handle static assets (as seen below). If this block is not declared first, # then Nginx will encounter an infinite rewriting loop when it prepends `/index.php` # to the URI, resulting in a HTTP 500 error response. location ~ \\.php(?:$|/) { # Required for legacy support rewrite ^/(?!index|remote|public|cron|core\\/ajax\\/update|status|ocs\\/v[12]|updater\\/.+|oc[ms]-provider\\/.+|.+\\/richdocumentscode\\/proxy) /index.php$request_uri; fastcgi_split_path_info ^(.+?\\.php)(/.*)$; set $path_info $fastcgi_path_info; try_files $fastcgi_script_name =404; include fastcgi_params; fastcgi_pass unix:/var/run/php/php8.0-fpm.sock; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; fastcgi_param PATH_INFO $path_info; fastcgi_param HTTPS off; fastcgi_param modHeadersAvailable true; # Avoid sending the security headers twice fastcgi_param front_controller_active true; # Enable pretty urls #fastcgi_pass php-handler; fastcgi_intercept_errors on; fastcgi_request_buffering off; fastcgi_max_temp_file_size 0; } # Serve static files location ~ \\.(?:css|js|mjs|svg|gif|png|jpg|ico|wasm|tflite|map)$ { try_files $uri /index.php$request_uri; add_header Cache-Control \"public, max-age=15778463, $asset_immutable\"; access_log off; # Optional: Don't log access to assets location ~ \\.wasm$ { default_type application/wasm; } } location ~ \\.woff2?$ { try_files $uri /index.php$request_uri; expires 7d; # Cache-Control policy borrowed from `.htaccess` access_log off; # Optional: Don't log access to assets } # Rule borrowed from `.htaccess` location /remote { return 301 /remote.php$request_uri; } location / { try_files $uri $uri/ /index.php$request_uri; } } OpenLDAP \u0026 NextCloud. To add support for OpenLDAP in nextcloud install ldap php library from deb sury repository.\n$ sudo apt install php8.0-ldap and then later enable LDAP user and group backend on nextcloud Apps"},"title":"NextCloud"},"/wily/":{"data":{"":"WILY word sounds good,an initiative by me to document my everyday learnings to increase my productivity, inspired from Zettelkasten. It is hard to write about the present days learnings,so hence the name WILY, to track Yesterday’s learnings."},"title":"WILY (What I Learnt Yesterday)"},"/wily/dec-2023/20231214/":{"data":{"":" virt-customize Customizing debian generic cloud images using virt-customize $ virt-customize -a debian-12-generic-amd64-20231210-1591.qcow2 \\ --root-password password:debian $ virt-customize -a debian-12-generic-amd64-20231210-1591.qcow2 \\ --append-line '/etc/motd: Welcome to DeepRoot GNU/Linux' $ virt-customize -v -a debian-12-generic-amd64-20231210-1591.qcow2 --install vim $ virt-customize -v -a debian-12-generic-amd64-20231210-1591.qcow2 \\ --upload path-to-localfile:destination-file-path "},"title":"2023-12-14"},"/wily/dec-2023/20231215/":{"data":{"":" Setting this Wily feature and revamping my site. Ansible Semaphore UI - setting up Key Store,Repositories,Inventory and Task Templates Hello World ansible playbook $ cat hello-world-01.yml --- - hosts: all tasks: - name: Print message debug: msg: Hello World $ cat inventory 10.22.13.84 ansible_user=debian Downloading mp3 version of a video from YouTube using yt-dlp\nsudo yt-dlp -f bestaudio -x --audio-format mp3 --audio-quality 0 \"\u003c\u003cYoutube_link\u003e\u003e\""},"title":"2023-12-15"},"/wily/dec-2023/20231218/":{"data":{"":" Setting up a systemd service for openvpn Create a systemd service file in the path /lib/systemd/system/openvpn-vinay.service with the following contents where vinay.ovpn is the openvpn cert file within the location.\nDescription=To access deeproot office infrastructure After=multi-user.target [Service] ExecStart=sudo openvpn /etc/openvpn/vinay.ovpn [Install] WantedBy=multi-user.target "},"title":"2023-12-18"},"/wily/dec-2023/20231219/":{"data":{"":" Signing statements using GPG key\nPut the statement in a document or textfile like file.txt gpg --clearsign file.txt A file called file.txt.asc will be created which is gpg signed statement.\nInstalling iosevka font\nhttps://phd-sid.ethz.ch/debian/fonts-iosevka/\nControlling audio within the terminal\npactl set-sink-volume 0 +10% : to increase the volume by 10%\npactl set-sink-volume 0 -10% : to decrease the volume by 10%"},"title":"2023-12-19"},"/wily/dec-2023/20231221/":{"data":{"":" Minikube\nminikube delete –profile minikube ip gives the ip of minikube\nping command\nping command uses ICMP (Internet Control Message Protocol), and not TCP/UDP hence cannot ping a particular host’s port.sends an ICMP echo request to the target host and waits for ICMP echo reply.The time parameter defines the total time taken to send an ICMP request to the target and the reply back to the source target,hence the name Round Trip Time(RTT), hencethe latency\ndig: Domain Information Groper\ncollects data about Domain Name Servers like DNS records\ndig +short blog.vinay.im\nwhere blog.vinay.im is the target’s domain name\ndig blog.vinay.im\nblog.vinay.im.\t10792\tIN\tCNAME\tvinay-keshava.gitlab.io. vinay-keshava.gitlab.io. 292\tIN\tA\t35.185.44.232 Using Rootless Docker\nhttps://thenewstack.io/how-to-run-docker-in-rootless-mode/ "},"title":"2023-12-21"},"/wily/dec-2023/20231222/":{"data":{"":" Updating PATH in linux\n$ export PATH=$PATH:/usr/sbin - adding a path to a directory\nThere’s a no way to remove a directory from path instead reassign existing path to the same variable like $ export PATH=/home/vinay:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games:/usr/sbin\nKubernetes Architecture\nRemove fish greeting\nTo remove the fish greeting, Welcome to fish, the friendly interactive shell, add the following set fish_greeting \"\" to .config/fish/config.fish "},"title":"2023-12-22"},"/wily/dec-2023/20231227/":{"data":{"":" qemu-img info $ qemu-img info debian-12-generic-amd64-20231013-1532.qcow2 image: debian-12-generic-amd64-20231013-1532.qcow2 file format: qcow2 virtual size: 38 GiB (40802189312 bytes) disk size: 366 MiB cluster_size: 65536 Format specific information: compat: 1.1 compression type: zlib lazy refcounts: false refcount bits: 16 corrupt: false extended l2: false Child node '/file': filename: debian-12-generic-amd64-20231013-1532.qcow2 protocol type: file file length: 366 MiB (383517184 bytes) disk size: 366 MiB qemu-img info displays general information related to the qcow2 image,like virtual size,disk size etc - To remove the fish greeting, Welcome to fish, the friendly interactive shell, add the following ```set fish_greeting \"\"``` to ```.config/fish/config.fish``` "},"title":"2023-12-27"},"/wily/jan-2024/20240102/":{"data":{"":" LVM – Logical Volume Management.\nConcepts of Physical Volumes,Volume Groups,Logical Volumes.\nsudo lvmdiskscan\nCreating physical volume using physical drives\nsudo pvcreate /dev/sda /dev/sdb\nCreating Volume groups sudo vgcreate /dev/sda /dev/sdb\nCreating Logical Volumes within the volume groups\nsudo lvcreate -L 10G -n projects LVMVolGroup sudo lvcreate -L 5G -n www LVMVolGroup sudo lvcreate -L 20G -n db LVMVolGroup Golang\nPackage import,multiple package import Exported names starting with capital letters. Functions: function definition,function parameters,shortening function parameters,return types, named return types, "},"title":"2024-01-02"},"/wily/jan-2024/20240103/":{"data":{"":" LVM\nFormatting and Mounting a logical volume sudo mkdir -p /mnt/{backup,college-data} sudo mount /dev/VolGrpLvm/backup /mnt/backup/ sudo mount /dev/VolGrpLvm/college-data /mnt/college-data/ Renaming a logical Volume sudo lvrename /dev/VolGrpLvm/college-data /dev/VolGrpLvm/college Extending a logical Volume sudo lvextend -L+5G /dev/VolGrpLvm/backup ``` ```sudo lvextend -L25G /dev/VolGrpLvm/backup Shrinking a logical volume sudo lvreduce -L20G /dev/VolGrpLvm/backup Removing an logical volume sudo lvremove /dev/VolGrpLvm/backup LVM Stripping sudo lvcreate -L 10G -i2 -I64 -n backup1 VolGrpLvm LVM Mirroring sudo lvcreate -L 5G -m1 -n mirrorLV VolGrpLvm ThinPool and Thin provisioning sudo lvcreate --thinpool vg_thin/thin_pool --name volume_1 --virtualsize 3G Golang\nVariables Short Description variables Types Type conversion and Type inference Constants "},"title":"2024-01-03"},"/wily/jan-2024/20240104/":{"data":{"":" Network File System(NFS)\nHere is the link to the document Installing NFS server and setting directory permissions to 777 Configuring Export directory by editing the file /etc/exports Options to configure the NFS server,either readonly or read write, sync or async,subtree check. Exporting the shared directory using exportfs command Configuring firewall ufw to allow clients to access the shared folder. Configuring client using nfs-common package Creating mountpoints on the client side to access the shared folder. Mounting the folder using mount command or adding the entry to /etc/fstab "},"title":"2023-01-04"}}