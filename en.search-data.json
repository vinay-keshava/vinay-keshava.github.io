{"/about/":{"data":{"":" Hello, I‚Äôm Vinay a FOSS enthusiast and a undergraduate, currently Hack‚Äôing at Deeproot GNU/Linux.\nI‚Äôm a Debian Maintainer,maintaining \u0026 working on packages of GitLab and its components on Debian.\nPlease feel free to hit me up if you want to get in contact or want to know about me. I go by the handle vinay-keshava across the web.\nEmail/XMPP: vinaykeshava [AT] disroot.org"},"title":"About"},"/blog/":{"data":{"":" Debian Maintainer Now!! Contributing to Debian !! Software Freedom Camp 2021 git.fosscommunity.in Server Update "},"title":"Blog Post's"},"/blog/automating-debian-installer/":{"data":{"":"The Debian Graphical Installer,when i was introduced to Kali Linux(a Debian based distro),during my initial days of bachelor‚Äôs, the installer was so tricky to install GNU / Linux,thereby losing my data (:\nEven though nowadays, Live systems have Calamares based installer,i feel the Graphical Installer is a bit annoying,so i wanted to automate the debian installer using a preseed configuration file,giving answers to debian installer in a config file making it easier and faster.\nThis is the wiki link for Debian Installer Preseeding https://wiki.debian.org/DebianInstaller/Preseed . Preseeding is like a set of answers to debian-installer(d-i) questions.Preseeding can be done in 3 ways\n1.Adding the preseed file to installer‚Äôs initrd.gz\n2.Over webserver via DHCP\n3.Loading the preseed file from a webserver over the boot options.\nThis blog post explains automating the debian installer by loading the preseed file from a webserver over the boot.\nWhen Graphical Installer boot menu appears after booting through the Debian iso,select the Help entry from the menu. After selecting the Help entry from boot menu,a boot: prompt is displayed below, enter you webserver url of the preseed file, in my case the preseed file was on my server with ip http://144.24.135.168/preseed.cfg/, and give boot: auto url=http://144.24.135.168/preseed.cfg and the auto command launchs the automated debian installer. The default preseed file for new release will be updated here https://wiki.debian.org/DebianInstaller/Preseed#Default_preseed_files Answers like setting username and password for Account setup,Network Configuration,Mirror Settings,Partitioning disks,setting normal user as root user Locales,Keyboard layout,Package Selection and many more\nAll the features in the Debian installer can be answered with the preseed file. My Preseed filed-i mirror/http/hostname string http.us.debian.org d-i mirror/http/directory string /debian d-i mirror/http/proxy string d-i passwd/root-login boolean false d-i passwd/user-fullname string Vinay Keshava d-i passwd/username string vinay d-i passwd/user-password password vinay d-i passwd/user-password-again password vinay d-i clock-setup/ntp boolean true d-i partman-auto/init_automatically_partition select biggest_free In the above preseed file i‚Äôve set the debian mirrors [ line 1-3 ]with http.us.debian.org and the directory for the mirror is /debian,Account setup with password[ line 4-8 ], [ line 9 ] for ntp server to sync time with and [ line 10 ] for automatically partitioning the disk with biggest free space disk partition.\nThis is sample preseed file with few options and it can be customized accordingly.\n:wq "},"title":" Automating the Debian Installer"},"/blog/contributing-to-debian/":{"data":{"debian#Debian":"DebianDebian is a GNU/Linux distribution completely inclinded towards Free Software philosophy, maintained by the community.\nBefore talking about how i started contributing to debian, i would like to talk about the camp organized by FSCI It is an online free mentorship programme organized by Free Software Community of India ,introducing people to Free Software.Ravish introduced me to 2021 FSCI‚Äôs camp, and there i got introduced to Debian Packaging through Debian Developers and Debian Maintainers.\nDuring the project phase of the camp, i choosed to work on Debian Packaging and System Administration(here is my Project Proposal)","debian-packages-and-my-story-#Debian Packages and my Story !!":"Debian has roughly over 51,000 packages, these packages are installable through apt, just like ‚Äúsudo apt install nano‚Äù. I always wanted to know how ‚Äúsudo apt install nano‚Äù works !.\nDuring the project phase of the camp Praveen my mentor of the project,a Debian Developer himself suggested to get started by packaging node packages(dependencies of Gitlab). A big Thanks to praveen for teaching packaging from scratch, also answering my useless questions and also sponsoring my packages to debian. Initially i found it very difficult to understand it,but the community was so welcoming, they were helping and assisting me by clearing all my doubts through matrix.\nI took a lot of time to learn,tried to spend more time in learning during hectic schedule of college and also i gave up hope many times and restarted it. So initial task was to setup the Debian Unstable environment and rebuilding the existing simple node-pretty-ms package, and then tried a simple package update and then went to continue packaging few node modules.\nI currently maintain around two node modules as of today, looking forward to maintain more packages in debian. All the communication happens mainly through mailing list or irc of respective teams.","further-development#Further Development":"Looking forward to contribute and hangout with the awesome debian community and learn more.\n:wq "},"title":"Contributing to Debian"},"/blog/debconf23/":{"data":{"":"Its almost been more than a month since DebConf23 happened,and this post was in draft for very long time because i just wanted to write the best post of all my post, and finally writing about the experience of attending a FOSS conference/conference for the first time.I had graduated in early May'23, so was not sure whether i could attend DebConf.I had joined Deeproot GNU/Linux,just before DebConf as an Intern. I was excited for this because i meeting my Debian and Free Software Community of India friends for the first time in 2 years,i hadn‚Äôt met anyone physically,was conversing with them online.\nI became a Debian Maintainer in early'2023 March ,special thanks to Praveen my GURU,for advocating my Debian Maintainer process,who taught me Debian Packaging from scratch,answering my stupid questions and Nilesh for signing my keys. I have written a separate blog post about my experience of becoming a DM.\nAhh so this is Ravish [Left] and me. Ravish is my college super senior,we were part of FOSS club called Edwin‚Äôs Lab in our college,he‚Äôs the one who introduced me to GNU/Linux. Forever indebted to ravish its because of him i‚Äôm working at DeeprootLinux,Thanks man.\nIt was my first time flying,I,Abhas - Founder of Deeproot Linux,Ravish boarded a cab to the Bangalore Airport, and we reached around 8:00pm,the architecture of KIAL was just amazing,i was astonished, we had huge baggage to carry for the Mostly Harmless Stall at the airport,so we had rigourous security checks at the airport. We boarded the flight on 9th September, DebConf was about to start from 10th September [ I missed DebCamp ]\nIt was a surreal experience of flying for the first time,it was amazing feel.We also had our dinner (Veg Roll) on the flight. Had the best view of city during the night time,watching‚Äôem from higher altitude was just so satisfying for eyes. We reached Kochi Airport around 11:15pm and boarded a cab to Four Points Sheraton Hotel. We reached Infopark Kochi around 12:30am and checked in to our hotels.I had applied for Accomodation and Food Bursary and it was approved :) So my room was at Four Points Sheraton Kochi,6th floor, also i was wondering who my roomate was,the earlier day i had receieved a mail that Kurian Benoy was my roommate, i was curious to meet him.\nThe next morning was DebConf Opening Ceremony,so had to sleep because it was already 3:00am i was exploring my hotel room.\nWoke up around 8:00 am and freshened up and headed to FrontDesk for Registration,we got our name with GPG key printed on our ID‚Äôs,also got the SwagBag,with some cool stickers and swags by Debian. After the registration i met kurian benoy, my roommate for a week.\nStickers part of Debian Swag I and ravish were waiting at the HackLab for the opening ceremony,in mean time we met urbec,part of Video Team,had some good conversation too.\nDEBCONF-23 starts with opening ceremony at Anamudi(These were the hall names,other hall names were Kuthiran,Ponmudi) the DebConf organizing team were on the stage giving a Welcome Note, and then after welcoming ceremony i went to attend talks which we interesting. The talk schedule was not very tight, because we used to gather more at the eating place to meet new people from diverse countries,having some really good conversations.\nI met praveen,shruti,anupa,ravi,sahil,abhijith,nilesh,bilal,suman,kelvin,pushkar,utkarsh,joostvb,Israel Galadima‚Ä¶ and lot more people whom i wanted to meet.\nI also met Pushkar from canonical, who used to stay at Bengaluru in the same locality and that was coincidence,meeting him was great too. First day ended good.\nA picture with Pirate Praveen and Ravi. Abhas's talk on Home automation with his amazing LED pant :) Cheese and wine party, the party is simple to bring good stuff from other countries like cheese and wine, People from all over the world bought different stuff to the cheese and wine party,we got the chance to taste from Korean wafers and red wine.\nOn 13th Sep there‚Äôs a Day trip,but i hadn‚Äôt registered early, only for Bird Sanctuary the registration was open,just the day before day trip edited the wiki and added my name. A Day trip to Thattekad Bird Sanctuary On the way to Thattekad i met /su/bin/ siby, on the bus. Thattekad Bird Sanctuary is around 50km from the kochi,so we left around 7:00 am\nWe reached around 9:00 and had snacks and started walking towards the bird sanctuary. It started with a walk around the bird sanctuary spotting for birds around,during the trek i was with Praveen,Bady,Kannan and Kelvin. Spotting birds was difficult because it wasn‚Äôt the actual season for migrating birds,so we could spot only few. Kelvin was explaining how he started to contribute to Open Street Map.\nOn our way back to the bus it started raining heavily and we were drenched completely, The cool debian umbrella with Debian symbol on it,helped us to get back to the bus.After a hot tea and snacks we started back to kochi.\nDebian and Clouds :)\nThe place were i stayed the most Mostly Harmless Stall (But not Harmless) with Abhas,Akshay explaining people about Liberated Hardware,and why it is important in life to use Liberated Hardware.Enjoyed Sahil‚Äôs touch typing and testing keyboards,i couldn‚Äôt take a picture with Sahil,he also volunteers at FSCI managing instances,he taught me git.fosscommunity.in update generating keys etc he‚Äôs also a Debian Developer,part of DebConf organizing committe too, also met saswata from Unmukti Tech.\nIt was an Amazing conference,it was my first Conference/FOSS conference enjoyed it,got to meet new people,the ecosystem of the Hacklab to hack around,seeing the community bonding even ravish wanted to contribute by packaging so taught him packaging at hacklab during free time,Also i learnt about OpenStreetMap,and now i map in and around Bangalore in my free time,a good hobby that i‚Äôm interested.Enjoyed ravi‚Äôs humourous jokes :) throughout DebConf\nThe only disappointing thing at DebConf was the demise of Abraham Raji during a Day Trip,Debian project mourns the death of abraham, i hadn‚Äôt personally met him,but conversed online about fsci camp,an inspiring soul\nAbraham Lives Onnn!"},"title":"DebConf 23,Kochi India"},"/blog/debian-maintainer/":{"data":{"":"I am excited to share with you all that I have recently become a Debian maintainer!! Thanks to amazing debian community.\nIt all started with Software Freedom Camp, ravish my college super senior (we were a part of college linux club) introduced me to software freedom camp organized by FSCI, since then i was a noob hopping between various distro‚Äôs from kali linux to other debian based distros to arch ! I had previously written my experience of attending software freedom camp here.\nI started with packaging node modules initially without any knowledge of javascript/nodejs, before packaging new module i tried to upgrade few node packages to new upstream,it was difficult at first understanding the packaging process. node-prosemirror-view was the first node module i packaged, cut to 20'23, i maintain few ruby and golang packages most of them which are gitlab dependencies, here is the list of packages i maintain.Special thanks to praveen for his mentoring, who is my package sponsorer.\nOver the past six months, I have been packaging Ruby gems and GitLab dependencies. For this gitlab update, I took on the challenge of building GitLab 15.8.4 and its major components, including Gitlay and GitLab-shell.\nThanks to Praveen and Bilal for their help and support during gitlab package upgrade to 15.8.4.\nThe first package as DM uploaded was ruby-et-orbi.\nWe are also preparing GitLab for bookworm, the next release of Debian."},"title":"Debian Maintainer Now !!!!"},"/blog/dont-grow-up-old/":{"data":{"":"Don‚Äôt grow up old, everyone wants to become an adult soon, enjoy life ,stay independent,take more responsibilites etc etc.\nBut in this process, you miss out a lot of things,the excitement to grow old faster kills you, and you will only realize this when you look behind and regret saying, i should have done this at that point of time in my life, but you cannot do it now,and now do nothing but,regretting.\nDon‚Äôt let the kid inside you miss out the fun,enjoy every moment in life to the fullest,enjoy by living the present moment. Do what you‚Äôre supposed to do at that point of time in your life. What ever is supposed to happen,happens at the right time,irrespective of what and how many times you think about it."},"title":"Dont Grow Up Old!"},"/blog/git-fosscommunity-in-update/":{"data":{"":"Ahh, my first blog post. Good Beginnings (:\nExcited!!\nThis blog post is dedicated to sharing my experience with updating the FSCI‚Äôs GitLab instance git.fosscommunity.in update.\nFSCI runs a free instance of GitLab Community Edition at git.fosscommunity.in for collaborative software development.\nFSCI also hosts and maintains a lot of services for the community, you can check out the services here, these services are managed by volunteers.\nAfter joining Software Freedom Camp 2021 Diversity Edition( Online mentorship programme organized by Free Software Community of India(FSCI) ) as a learner and I met a bunch of people who discuss about Free/Libre/Open Source Software and educate people about why it is important to use free software in our life maintaining freedom and privacy in this era of technology. Along with Ravish and Sahilister we all updated it from GitLab v14.4.2 to Gitlab v14.4.4 it was a Security update, it took a lot of my time to update and upgrade the instance.\nAll thanks to Ravish and Sahilister for helping and teaching me."},"title":"git.fosscommunity.in Server Update"},"/blog/i-should-write-more/":{"data":{"":"2023 is about to end in another few months,I feel ,i should write more now!. I just love writing now,I feel i should write more to express my thoughts,ideas,its been since few months i started to write more docs,and i just simply love it.\nI feel like it helps me document stuff,check how my learning evolved over time and its progress.\nAt first when i started to create my portfolio i was reluctant to write much,barely one or two articles per year,i was not confident about my grammer too,now i really dont care about it,i just write my raw thoughts.There‚Äôs some level of satisfaction of writing,i encourage others also to write more.\nPeople who read my blog might provide feedback too,correct if any mistakes. I also encourage other people to write, if they are too shy they can try anonymous blog.\n:wq "},"title":"I Should Write more!"},"/blog/kumara-parvatha/":{"data":{"":"","#":"Awakening Kumara Parvatha üòç ,the highest peak in Pushpagiri Wildlife sanctuary,the best and worst trekking we had ever experienced.It all started with my school friends who were planning for a long trip after graduating from engineering (Most of them are Engineers,few are doctors),the last time i went to a long trip with my school friends was a visit to Waynad,Kerala (10th School Trip).After completing my intermediate,i migrated to moodbidri for my bachelor‚Äôs degree and all my friends pursued their engineering in bangalore,this was the reason it took more time for me to go for a trip with them, during engineering i rarely used to come home,maybe 6 months once so it was difficult to plan for a long trip with them.\nSo I,dharnish,rohan,chandan started hunting for places to plan for the trip,and after a lot of discussions and budget restrictions we decided ‚ÄúA Trek To Kumara Parvatha‚Äù on Jan 5th,2024 should be good enough, after great grand new year.\nWe booked our train tickets one month before,so that we aren‚Äôt cancelling the trip this time, after so many cancellations at the last minute from my side too :) . We also had booked our tents at Battru Mane for one night stay on Jan 6th Saturday.\nI would suggest this trek to kumara parvatha,if one wants to experience the value of a sip of water and rice grain. The only fear we had was,are we capable and fit enough to trek, because kumara parvatha had the level of difficulty from moderate to difficult,which has total trek distance of approx 24KM,which has to be covered in two days according to our plan and a stay at Battru Mane for one night.\nA day before our train, we had to shop clothes and a lot of snacks to survive while trekking and few medicines for emergency purpose. With all set for trek, we all were excited for the trek\nThat's us from left Me, Dharnish, Chandan and Rohan We boarded our train on Jan 5th,2024 9:00pm at Majestic,Bengaluru and it would reach Subhramanya Road around 6:00am the next day, during the train journey we had some good conversations about school memories, cherishing the moments we did in school, talks about Reddy Sir, school friends and a lot of things during the train journey.We were speaking till midnight and then realized we had to sleep soon, so that we can take rest to start afresh to trek. We reached Subhramanya Road Railway Station around 5:45am and had to board a KSRTC bus to reach Kukke Subhramanya Temple which was around 10-12km from the railway station.\nThe picture is the holy river called Kumaradhara river, piligrims take a dip in this holy river and then head to the darshan for Kukke Subhramanya. We took a holy dip at kumaradhara river,even though it was cold, we were shivering after taking the bath.It was cold af. After a holy bath in the Kumaradhara River near Kukke Subhramanya Temple, we started heading to Temple for the darshan. [A picture of ourselves infront of the temple,from left Rohann,Mee,Dharnishaa,Chandann, we look cool right?,i just love this picture, School friends are \u003c3 ] After the darshan and we had our breakfast at a hotel nearby,we had to eat to our stomach full because the next point where we get food during the trek was Battru Mane which was 6km from the trek starting point.Later we realised we bought a lot of baggage which would make us tiring to trek along with carrying the bagge,so we wasted our time deciding and segregating where to put our baggages so that it is safe for atleast 2 days.We then finally found a place at the KSRTC bus stop since it was a paid service,we trusted it üòú.By the time we segregated and deposited our baggage at the KSRTC counter it was afternoon. I just hydrated myself with some juice, and then we started heading to the trek start point and Forest Office.It is around 2km walk from the temple to the trek start point.\nTrek Start Point - Forest Office Roughly around 2km walk from the temple,we reached the Forest Office and Trek Starting Point.\nA good initiative taken by the Forest office was to not dispose any plastics on the way to the trek.At the start of the trek point all the bags are checked thoroughly and the number of plastics are counted with chocolate wrappers counted too.We had a lot of plastics because it was mostly eatables, the total count of plastics was 90 + 4 90 numbers of plastics and 4 water bottles for each of us and if any plastic piece is left on the hill during the trek the forest office informed us that they would charge a Rs.50 per plastic,if any plastic is missed out we would go bankrupt üò¢ , so we were careful about not littering the plastics anywhere. The excitement was very high at the first while walking along the trails,clicking pictures.\nWe found a group of 2 people who were trekking to KP, and the coincidence was even they were from Bangalore,and they were kannadigas.We started trekking along with them,making funny jokes with them,we were comparing our trekking speed with recent version of engines like BS4 , BS5 üòâ, they were few years elder to us.Whenever they were taking rest we use to tease them to upgrade their BS enginesüòÑ. Their baggage was very less compared to ours,they only had a small bag and a water bottle.\nWe started to feel tired, at first the JOSH was high,but then we were taking frequent breaks while trekking,We started feeling thirsty, our bottles were empty after a few hours of trekking, we had bought a TANG packet to stay hydrated while trekking. Legs started aching, it was very humid, with all these the only motivation for boys is girlsüòÑ, there was girl gang who was trekking along with us. Since it was the only way to trek to the top of the hill and get down from the hill, we were asking people who were coming down,how much time it takes to reach Battru Mane,few people were scaring us saying there‚Äôs a lot to trek more to reach battru mane,while few were motivating, but we didn‚Äôt know whom to believe. It was scorching heat and had to bear until we found the path to the water falls,near Bheemana Bande. Empty Bottles,thirsty throat,hungry stomach with birdy butterflies, this was our situation after a trekking for 2Kms\nBheemana Bande | Bheema Rock Bheemana Bande translates to Bheema‚Äôs Rock. Bheemana Bande,a beautiful place with simple view with a small stream of water, a much needed place to rest, soaking our feet in the cold water to feel the relaxation. We had our lunch at bheema‚Äôs rock bought by rohan,we were more hungry so we started eating few sneakers by carefully peeling the wrapper of the chocolate and not littering it out.I think we were more careful about the plastic wrappers than our lives at that point of time. After having our lunch, we took rest for a few minutes and we wanted to drink water,since it was the only water resource until we reach Battru Mane which is like 3 to 4 KM from the Bheema‚Äôs rock. So i and chandan went to the top of the hill hunting for the fresh water.After taking a long rest we decided to leave and reach Battru mane before sunset, so that we aren‚Äôt stuck in dark\nBattru Mane We left Bheema‚Äôs rock at around 2:30 pm,After a long rest we started trekking back again, the trails had more elevation had to put longer steps,making us more tired and take frequent rests.For every 15 to 20 minutes we were taking rest for a period of 10mins Legs started aching badly,we were taking more breaths per second.The trails had more elevation,it wasn‚Äôt flat,may be with an angle of 30 degrees.Number of steps become more. We badly needed water, our throats were dried up.We were saving the snacks for the 2nd day trek because there‚Äôs no food resources after battru mane,we were planning to leave battru mane early morning so that we could complete the trek by next day evening. We had no more energy left out, rohan was badly tired taking more breaks. Everyone were tired even to quit and go back,we have to cover back the distance back,instead it was better to continue to battru mane, only option left out. After 3 hours of trekking, we reached battru mane at around 5:40.\n[Thats chandan and me resting inside the ‚ÄúPatched‚Äù Tent]\nWe finally reached battru mane at around 5:40pm,there‚Äôs little internal satisfaction. We were looking for the person called vasanth,with whom we booked our tents to stay tonight.As soon as we got our tents we rushed into it,to take rest.After little rest we went to meet battru to order our dinner, each plate costs around Rs.150\nWe also ordered food for the next day.There‚Äôs no list or menu the only thing we get is Rice and Sambar.Just like how we trekked from the base,the rice bag is carried on shoulders and then bought to battru mane.\nBattru Mane is the only place where you get food,and a proper flat surface to tent. There were many people like us who had come to trekking and there were like around 50+ tents. There wasn‚Äôt any phone signals too inform home that we have reached.\nWe thought of taking a nap before having dinner.I and chandan were in one tent,rohan and dharnish in the other.It was cloudy by then,since it was summer we didnt expect that it would rain.. It was a one person tent looking at the size,but they fooled us and said two persons can stay,with no other option left and all other tents booked,we adjusted.\nNow the cinema starts‚Ä¶..\nEveryone were tired trekking after a 6km trek,so we fell asleep soon. I suddenly woke up to the sounds of thunderstorms,thats when i realised its raining heavily. It was lighting and thunderstorm‚Äôing heavily,but chandan was sleeping peacefully :) At around 8:00pm tents started leaking, water was all over.We never experienced such a horrible night ever in our lives. The tents were patched with tape,water started flowing inside but for time being we could sit inside.After a few minutes thunderstorms and rains increased, the tents were floating, we had water below the tents, we had the fear of getting washed away along with the tent. I shouted loudly to dharnish saying hope there isn‚Äôt any landslide (Dharnish \u0026 Rohan were in the tent next to us).Even their tents were leaking.Our bags are wet,we are wet, without having any other option for ourselves, we stayed within the tent. Few people who were standing near the pole experienced a slight lightning strike. We were hungry on one side,raining on the other side,at 9:30pm finally i and rohan decided to check for the availability of the dinner at battru mane,its clumsy everywhere there was no place to stand even at battru mane,it was fully occupied with people just like us whose tents were leaking.\nWe couldn‚Äôt find the person with whom we booked our tents so that atleast we could complain that the tents are leaking. I and rohan took our bags along with us and went out,so that our bags wont get wet.After a little while dharnish and chandan joined us to check for the availability of the food. Its 10:30pm and its still raining, butterflies in the stomach,tiredness after a long trek.After a few minutes it stopped raining. As soon as the rains stopped there was a long queue for the food. People all around Battru Mane,standing in the queue for food while drizzling,for a minute it gave me AIET Hostel vibes while holding the plate and standing in the line. While we were standing in the line there were a group of people with torch lights coming down the hill while it was raining.\nBy the time we ate food it became 11:20pm, and the rain had stopped so we thought we could back to our tents and take rest atleast by sitting and floating within the tent. But then here comes the another twist,one of our tents were occupied by other people, we tried re-checking whether if it was our tent,the next tent was the one where rohan and dharnish stayed, and rohan‚Äôs bottle was there lying, when we said them that it was our tent,kindly recheck with vasanth, they replied arrogantly that since you have the issue, you go and ask vasanth,i dont know where the hell was vasanth, there was no charge in our phone neither there was any light due power disconnection due to rains. They said that they had been to the peak and had booked this tent afternoon,they were the one who were returning from the peak while we were stading in the queue. Arguments went on for a while, we neither had energy to talk ,and then it started raining heavily, the tent next to rohan and dharnish‚Äôs was empty so we just bombarded into it.It was already 12:30am by that time,the tent which we bombarded was good enough so I,chandan,dharnish went inside,rohan said it would adjust to the previous one.\nIts 1:00 am we badly needed sleep,we were thinking of quitting and going back to the base morning after the breakfast,thinkging about the trails will be more slippery making it difficult to trek.In a one person tent we three slept,me horizontally,dharnish and chandan vertically.It was difficult to sleep there wasn‚Äôt any sufficient space to stretch our legs too.\nKallu Mantapa \u0026\u0026 Sesha Parvatha After a worst nightmare we got up around 4:30am because people were leaving battru mane and heading towards peak.We thought of quitting even at that point of time,but dharnish motivated us saying ‚Äúlets go to the peak atleast till Kallu Mantapa and if we fail lets take rest for a while and return from kallu mantapa,there was no use taking so many risks and trekking 6km ‚Äú.We decided to continue the trek,left battru mane around 4:45 heading towards forest office to pay the registration entry fee and Rs.500 as security fee.A little time was wasted while waiting to register. Torch lights on, trails wasn‚Äôt that slippery through the grasslands, there wasn‚Äôt any leaches too.Started heading towards Kallu Mantapa with phone torch lights on. After a 2KM trek there was another forest office security check at another base, where our bags were checked, and also confirmed that our registration was also done.After one and half hour of trek the sun was rising.\nSticks in our hands,helping us to trek.\n‚ÄúPeak innu eshtu doora idiyo gothilla‚Äù,‚ÄúPeak beda enu beda vapas hogona‚Äù, were some of the common dialogues by everyone. No proper food,legs were aching, we were trekking for 10minutes,rest for 10 minutes i was the first person to get hit wicket.I couldn‚Äôt trek i badly needed some food,so had a pack of Britannia Cakes,so i was okayish after having the cakes,also after having snickers,kept the wrappers inside the bag.We were taking care of the wrappers like gold :)\nWe reached the view point around 7:40am, took few pictures of ourselves and then started trekking to Kallu Mantapa thinking that it would become late. Pictures from View point: It was the best view ever,if given a chance we could have camped there. We skipped Kallu Mantapa, it was visible for us, but we lost the energy to go and come back from Kallu Mantapa so we thought of visiting while trekking down.So the next target for us Sesha Parvatha.\nAfter many moments of Peak Banthu, Peak Banthu,we finally reached Sesha Parvatha at 8:50am, we took a lot of rest,ate snacks to our stomach full at the peak of Sesha Parvatha by enjoying the view. When we initially reached Sesha Parvatha we assumed it was Kumara Parvatha,but later when other people informed us we got to know that we are the peak of sesha parvatha.\nSilence in the video was because had no energy to talk,after a long trek. EXHAUSEDTED‚Ä¶.\nThick Forest SP -\u003e KP When we left battru mane, we had to thought to quit after Kallu Mantapa but we reached till Sesha Parvatha,but then we were hungry more to trek so we decided to trek till Kumara Parvatha Peak which is 2Km from Sesha parvatha and this phase of the trek is the most difficult part. We started motivating ourselves and gave a try. This thick dense forest shaped like a V between two the mountains Sesha Parvatha \u0026 Kumara Parvatha.Initially we have to get down from Sesha parvatha from one side and climb to Kumara Parvatha on the other side.\n[ Sesha parvatha to Kumara Parvatha through the thick forest,rohan checking his shoe (: ] This thick forest on the way to Kumara Parvatha is the best 1km trek with amazing weather and view. You get to experience the nature‚Äôs beauty with your eyes, this part of the trek was only the interesting and satisfying part of the trek.Its just amazing even though its a hard trail.\nHere comes the next interesting and exciting part, this portion of climbing the hill rock was my favourite.I was excited for this.Our bottles were empty, so just filled water by the river stream before climbing the hill rock. Even though the water was not clean enough to drink, we had to drink water to make ourselves stay hydrated with TANG.\nA girl motivating chandan to climb the hill was another highlight of the trek [Update: We found the girl‚Äôs picture from Incredible Karnataka Instagram Post :) ]\nKumara Parvatha Andddddddddddddddddddddddddddddddd Finallyyyyyyyyyyyyy there we go We reach KUMARAAANNA PARVATHA‚Ä¶.\nWe reached the peak around 10:40am.\nTo be frank the peak wasn‚Äôt that exiciting for the risk we had taken, there was just a board named ‚ÄúPushpagiri Peak‚Äù surrounded by rocks also a temple within the vicinity of the peak.\nWe half emptied our snacks,took blessings from temple. We left Pushpagiri Peak around 11:45 am. The real challenge now is to trek down back,the distance we covered in one and half days, has to be covered in half day. We set ourselves a target to reach the base before sunset.\nTrek Down Episode 1,this was our very first Vlog,we had planned to make a series of videos,but due to time constraints we recorded only few videos,but i enjoy whenever i see this video(PS: It‚Äôs Pushpagiri Peak and Kumara Parvatha Peak sorry for the mistake in the video)\n[Episode 2 the last one we had no energy to speak nor to record videos,so just decided to sum up everything into one.]\nWe returned back to Battru Mane around 2:00pm,we had our hot lunch and left battru mane around 3:00pm, we have 3 hours of time to trek down to the base, which we had covered in 5 hours while climbing.\nThere‚Äôs no much interesting thing to write about trekking down because the only fear was whether we would reach the base before sunset. I dont remember anything while getting down because we were hurrying ourselves,tiring ourselves to walk more,take less rests while trekking down.\nThe only interesting part was getting to know the instagram ID of a trek lead girl of Incredible Karnataka :)\nWe reached the forest entry trek point around 6:45pm.No plastics were lost so we didn‚Äôt have to pay any money.Had our dinner at Kukke again,Here comes another struggle ‚ÄúTransport‚Äù to return back to bangalore. Since it was a sunday there was huge crowd and demand for bangalore buses,after searching for all possibilites we decided to board a KSRTC.\nThere was a bus scheduled at 8:30pm,it didn‚Äôt arrive on time so i was speaking to my friends Priya and other friends on a video call, and then suddenly chandan calls and asks us to board the bus,i and rohan started running towards the bus just to find there were no seats for me.Trekking for 24Km and no seat to sit was the hardest part.The good conductor offered me a seat next to him,seeing my struggles with my friends.I‚Äôm thankful to this man for offering the seat. It was an express bus,\nWe reached Majestic,Bangalore around 3:30 and reached our houses at 4:30am .Slept for 4 hours and went back to work,while all my other friends took a leave.\nWhen i said my roomie Sathwik,that i had been to kumara parvatha successfully, his reaction was ‚ÄúFinally You Made it üòÅ ‚Äú,we did plan for kumara parvatha when we were in engineering but failed successfully üòù.I was that excited to trek to kumara parvatha.\nFinally a trip with school friends come to an end,with great memories and a bright smile on our faces for the best and worst trekking we had ever experienced. So this is us and our story of ‚ÄúA Trek to Kumara Parvatha on Jan 6th,2024‚Äù.\n[I hate uploading these videos to Youtube,still searching for a better alternative,this has been in draft for more than two months, so wanted to get rid of this from draft,once i get a server will learn \u0026 stream them,until then keep \u003c3‚Äôing FOSS ]\nSee you until next time,Byeeee."},"title":"Kumara Parvatha"},"/blog/new-domains/":{"data":{"":"So finally i bought two new domains,one for myself and another one for my dad.After days of hunting for the most creative domains and its availability,i have registered winay dot in from gandi.net inspired from Vishal Arya,i always wanted to buy a domain for myself,had been hunting for the creative one since college, and finally i registered one. i have also bought another domain for my dad smpdiesel dot in,which is a diesel generator service based company.I was able to convince my dad to use GNU/Linux, he now uses Debian 12 on this PC, and its super speed with low specs.In coming days i will configure the DNS to this site, and self host few applications for my personal use."},"title":"New Domains"},"/blog/software-freedom-camp-2021/":{"data":{"experience-of-running-snikket-server#Experience of Running Snikket Server":"Back to writing after a 2-month long Semester End Exam !!!!.\nEveryone uses messaging platforms like WhatsApp, Facebook, Signal, Telegram, and various other applications to communicate with people, in this blog post I would like to introduce to XMPP Protocol( Extensible Messaging and Presence Protocol), XMPP is an open, decentralized universal messaging standard for instant messaging, voice/video calls. Many Applications or Clients are built using the XMPP protocol due to its open nature. Platforms like WhatsApp, Telegram, Signal impose vendor lock-in wherein the user using the product or service cannot transit to the competitor‚Äôs product/service. To overcome vendor lock-in issues and privacy issues one of the minimal, simple best solutions is to set up a Snikket server of your own, where you can own your data.\nWhat is SnikketSnikket is a simple, customized messaging platform that is different from other messaging apps like Whatsapp, Telegram. Snikket is a decentralized messaging platform which means anyone can host their snikket server on their cloud, it allows everyone to host their server. Snikket is free software, a privacy-friendly messaging platform based on XMPP protocol, it can be self-hosted by anyone. Snikket provides an android application client to connect to any XMPP servers and using a snikket account you choose any XMPP clients if you want to connect using android applications like monocles chat, blabber, Snikket app other desktop clients recommended are dino-im and gajim.\nExperience of Running Snikket ServerSnikket is my first self-hosted service, before talking about the experience of running the snikket server I would like to talk about Software Freedom camp 2021 ,the camp is organized by the Free Software Community of India. As a part of the camp initially, learners were made to understand the philosophy and intention behind free software. Later during the project phase, learners were allowed to choose certain available topics proposed by the mentor. After joining the sfcamp as a learner, I choose to learn system administration and Debian packaging, under system administration one of the deliverables was to set up a Snikket server of my own.\nTo run any snikket server basic requirements are a domain name and a VPS (Virtual Private Server )to run your snikket server. I had signed up for the Github Student Developer pack through the pack got the free domain from name.com and I choose Amazon Web Services Free Tier as my VPS.\nSnikket is all about the DNS Docker Daemons Snikket also has an option of creating circles, limiting users to that circle only, although any user can talk to any individual by providing an XMPP or Snikket username. Snikket uses an invite-based procedure for account creation on the server. Only the admin can have the authority to create an invite link. Snikket also supports audio and video calls of great speed, these are some of the features of the snikket application. I have been using Snikket and invited most of my friends to my Snikket server. Initially, it took time to make them understand how it is completely different from other messaging platforms. Later educated them about how decentralization, vendor lock-in works and then introduced them to Snikket and other XMPP-based clients.\nThe learning while setting up the snikket server was got introduced to Docker Container, Domain Name System( DNS ), how server logs are checked, and debugging the errors.","guide-to-setup-snikket-server#Guide to Setup Snikket Server":"Here is the quickstart guide to setup the snikket server , this is the official guide by Snikket to setup the snikket server . The detailed documentation is here. Snikket requires few ports to be open for communication refer this which clearly mentions the firewall rules and ports required. Snikket Source code here.\nThanks to Ravish and Sahil for helping to set up the Snikket server.\nNext Goals - Reverse Proxy by Nginx . Bye for now .\n:wq ","what-is-snikket#What is Snikket":""},"title":"Software Freedom Camp 2021 Snikket"},"/captures/":{"data":{"":"Coming Soon."},"title":"My Captures"},"/docs/":{"data":{"":"I try to hack around a lot of stuff,but lazy to document, but trying to document ‚Äôem all"},"title":"Documentation"},"/docs/debian/":{"data":{"":"Tutorials,configs and hacks related to Debian Packaging."},"title":"Debian Packaging"},"/docs/epm/":{"data":{"":"","#":"EPM is a ESP Package Manager used to package software easily,either by creating debs or rpms or tar.gz which makes easy to distribute software. Software distribution is the most difficult task in today‚Äôs world, and packaging software for each distribution makes it tedious,every distribution has their own set of rules and development tools to package software.\nEPM makes it easy to ship and package software for every distribtion.\nTo get started with EPM here is the documentation link.\nYou can install epm on Debian by just\n$ sudo apt install epm Or can build from source too.\nPackaging using EPM An example demo to package prometheus to generate a deb and tar.gz using EPM.\nStep 1: Download the tarball prometheus-2.48.0.linux-amd64.tar.gz\nStep2: Extract to the new folder\nStep 3: Create a new file in the extracted folder called prometheus.list with the following contents and here is the FHS to package\nls -l prometheus-2.48.0.linux-amd64$ ls -l prometheus-2.48.0.linux-amd64 total 171576 -rw-r--r-- 1 debian debian 11357 Nov 16 05:01 LICENSE -rw-r--r-- 1 debian debian 3773 Nov 16 05:01 NOTICE drwxr-xr-x 2 debian debian 4096 Nov 16 05:01 console_libraries drwxr-xr-x 2 debian debian 4096 Nov 16 05:01 consoles drwxr-xr-x 2 root root 4096 Nov 28 06:30 linux-6.1-x86_64 -rwxr-xr-x 1 debian debian 90226488 Nov 28 06:29 prometheus -rw-r--r-- 1 debian debian 424 Nov 27 10:19 prometheus-systemd-service -rw-r--r-- 1 debian debian 734 Nov 28 06:28 prometheus.list -rw-r--r-- 1 debian debian 934 Nov 16 05:01 prometheus.yml -rwxr-xr-x 1 debian debian 85422008 Nov 28 06:29 promtool prometheus.list%product Prometheus %copyright Promethues[Expat], All Rights Reserved. %vendor %license LICENSE %description Prometheus %version 2.48.0 %literal(control) \u003c\u003cEOF Section: misc Priority: important EOF f 755 root sys /usr/local/bin/prometheus prometheus f 755 root sys /usr/local/bin/promtool promtool d 755 root sys /etc/prometheus/consoles consoles d 755 root sys /etc/prometheus/console_libraries console_libraries f 644 root sys /etc/prometheus/prometheus.yml prometheus.yml f 644 root sys /lib/systemd/system/prometheus.service prometheus-systemd-service %postinstall sudo systemctl daemon-reload %postinstall sudo systemctl enable prometheus %postinstall echo Installation completed prometheus running on port 9090 Terminologies %product describes the name of the package.\n%copyright describes the license of the package.\n%vendor describes the organization name.\n%license attaches the file called LICENSE of the prometheus package.\n%description description about the package.\n%literal literal data, debian packages have control file to provide metadata about each package,similarly this token can be used to produce similar metadata.\n%postinstall \u0026 %preinstall to execute any scripts after and before installing the package respectively.\nHere,comes the actual part files,directories and symlinks\nTo put files/directories in FHS follow the below example syntax\ntype mode owner group destination source options f 755 root sys /usr/local/bin/prometheus prometheus Here\n-\u003e type describes whether its a file(f), or directory(d) or symbolic link (l) or configuration file(c)\n-\u003e mode describes about the file permission in unix style also mentioning the user and the group level access\n-\u003e destination \u0026 source specifies which file or directory to be put,here /usr/local/bin/prometheus is the destination and the binary prometheus in the current directory is the source\nBelow is the prometheus systemd service file example to enable systemd for prometheus and hence we use %postinstall to reload the systemd daemon and setup the systemd service.\nprometheus systemd service file $ cat prometheus-systemd-service [Unit] Description=Prometheus Time Series Collection and Processing Server Wants=network-online.target After=network-online.target [Service] ExecStart=/usr/local/bin/prometheus --config.file /etc/prometheus/prometheus.yml --storage.tsdb.path /var/lib/prometheus/ \\ --web.console.templates=/etc/prometheus/consoles \\ --web.console.libraries=/etc/prometheus/console_libraries [Install] WantedBy=multi-user.target Building the package $ sudo epm -f deb prometheus Will look for prometheus.list we had configured above and tries to build the package.\nThe -f option is to specify the distribution format here, giving it as deb to build a deb.\nIf the command runs successfully it creates and directory within the current directory called linux-6.1-x86_64 the built package deb is present within this directory.\nRunning without the -f option builds a tarball as show below.\nwithin the extraced directory$ sudo epm prometheus $ ls linux-6.1-x86_64/ prometheus-2.48.0-linux-6.1-x86_64.tar.gz $ sudo epm -f deb prometheus $ ls linux-6.1-x86_64/ prometheus-2.48.0-linux-6.1-x86_64.deb prometheus-2.48.0-linux-6.1-x86_64.tar.gz Drawbacks EPM does not support alphanumeric characters and special characters like underscore for the package name making it difficult and reducing reading enhancibility. "},"title":"EPM (ESP Package Manager)"},"/docs/golang/":{"data":{"":"Golang Learning."},"title":"Golang Learning"},"/docs/golang/introduction/":{"data":{"":"","basics#Basics":"Packages Programs start running with package main package main import \"fmt\" func main(){ fmt.Println(\"Hello World\") } Multiple package import paths. package main import ( \"fmt\" \"math/rand\" ) func main(){ fmt.Println(\"Fav number:\", rand.Intn(10)) } Exported Names Exported names start with capital letter,just like Pi in math package. package main import ( \"fmt\" \"math\" ) func main(){ fmt.Println(math.Pi) } Functions Functions can take zero or more arguments, variable type comes after variable name. package main import \"fmt\" func multiply(x int,y int) int { return x*y } func main(){ fmt.Println(multiply(4,2)) } Shortening function parameters,for better readability. func multiply(x,y int) int { return x*y } Return multiple results in a function definition func addsub(x,y int) (int,int){ return x+y,x-y) } func main(){ fmt.Println(addsub(20,20)) } Named return values. func addsub(x,y int) (add,sub int) { add = x+y sub = x-y return } Multiple Returns func swap(x,y string) (string,string){ return y,x } func addsub(x,y int) (int,int){ return x+y,x-y } func main(){ fmt.Println(swap(\"hello\",\"world\") fmt.Pritln(addsub(10,20)) } Variables package main import \"fmt\" var hello bool var i int=0 func main(){ var b,c int= 20,30 fmt.Println(i,hello,b,c) } Short variable description k:=3\nTypes Basic Types Integers - Signed (int,int8,int16,int32,int64) Unsigned (uint,uint8,uint16,uint32,uint64) Floats - float32,float64 Complex Numbers - float32,float64 Byte Rune String Rune Boolean Composite Types Collections/Aggregation - Arrays,Structs Reference Types - slices, maps,channels, pointers,functionos Interface package main import ( \"fmt\" \"math/cmplx\" ) var ( hello bool = false name string = \"vinay\" age int = 22 z complex128 = cmplx.Sqrt(-5+2i) ) func main(){ fmt.Printf(\"Type: %T Value: %v\\n\",hello,hello) fmt.Printf(\"Type: %T Value: %v\",name,name) fmt.Printf(\"Type: %T Value: %v\",age,age) fmt.Printf(\"Type: %T Values: %v\",z,z) } //observe the printf not the usual Println Type conversion and type inference package main import \"fmt\" import \"math\" // The expression T(v) converts the value v to the type T. func main(){ // Type conversion var x,y int =3,5 var f float64 = math.Sqrt(float64(x*x + y*y)) var z uint = uint(f) fmt.Println(x,y,z) fmt.Printf(\"Type: %T Value: %v\\n\",x,x) fmt.Printf(\"Type: %T Value: %v\\n\",z,z) fmt.Printf(\"Type: %T Value: %v\\n\",f,f) // Type Inference - the variable's type is inferred without from the value // on the right side i:=22 fmt.Printf(\"Type: %T Values: %v\",i,i) } Constants package main import \"fmt\" func main(){ const Pi = 3.14 // never use short description for constants i.e := fmt.Println(Pi) } "},"title":"Introduction to Golang"},"/docs/hacks/":{"data":{"":"If things are uncategorized,it goes to Hacks :)"},"title":"Hacks"},"/docs/hacks/conventional-commit/":{"data":{"":"","#":"Conventional Commits Defining a standard format for commit changes,which can be processed by automated tools to produce documentation.\n\u003ctype\u003e[(optional \u003cscope\u003e)]: \u003cdescription\u003e [optional \u003cbody\u003e] [optional \u003cfooter\u003e] type\nbuild: build system and dependencies change: changes to the implementation of existing feature chore: ci: continous integration or continous delivery scripts deprecate: deprecate existing featuresA docs: adds,updates,revises documentation related to applcation feat: new feature fix: commit to fix defect in the application perf: increase performance of algorithm,without fundamental changes in existing feature refactor: refactor existing code,does not change existing features remove: remove a feature revert: revert one or more commits security: resolves security issue. style: reformats the style of source code test: automated tests of the product/application Description very short summary of the intent,or title for the body\nBody additional details in the commit,which can include multiple paragraphs to describe the change.\nFooter Close,Closes,Closed,Fix,Fixes,Fixed,Resolves\nAutomated Version Numbering fix: increase the patch number according to semver.org feat: reset patch version and increase minor version, 1.2.4 changes to 1.3.0 patch number is reset. BREAKING CHANGE: presence of BREAKING CHANGE header increases Major version\ngit log --oneline - prints out the subject in one line\ngit shortlog - prints one line subject and user\nSubject lines should be capitalized\nReferences https://www.conventionalcommits.org/en/v1.0.0/ https://cbea.ms/git-commit/ "},"title":"Conventional Commit"},"/docs/hacks/customize-qcow2-disk-image/":{"data":{"":"Tired of Debian Installer ):\nOn Proxmox VE i had to go through the Debian Installer if i want to spin up a new VM,taking a lot of time and effort.\nDownload the .qcow2 image from cloud.debian.org https://cloud.debian.org/images/cloud/bookworm/20230910-1499/debian-12-genericcloud-amd64-20230910-1499.qcow2 ,this is a generic cloud image which can be easily imported onto proxmox.\nReset the root password on the disk image $ virt-customize -a debian-10-genericcloud-amd64.qcow2 --root-password password:debian\nBy default the .qcow2 doesn‚Äôt have any root password,so the disk image has be customized using virt-customize to add root password.\nIncrease size of .qcow2 disk image. By default the size of Debian Generic Cloud is 2GB, using qemu-img we can resize the disk image. qemu-img resize image.qcow2 +SIZE Import the disk image on Proxmox VE. Copy the image to /var/lib/vz/template/qemu/. Create a VM on Proxmox VE without any media (do not attach any physical media) and delete any existing disk on proxmox.\nqm importdisk 114 /var/lib/vz/template/qemu/debian-12-genericcloud-amd64-20230910-1499.qcow2 amogha -format qcow2 Execute the above qm importdisk on the proxmox server where 114is the VM id where in your case will be different. Refreshing the Proxmox GUI on the browser,attach the unused Hard Disk under Hardware, also add a cloudInit drive and set IP address to dhcp to automatically assign IP address for both IPv4 and IPv6.\nUnder Options update the boot order and check whether the hard disk which was added to be checklisted and prioritize it to first.\nAnother alternative way is to use Preseed file at boot which automates debian installer,haven‚Äôt tried that yet.\nCreating a new VM Creating a vm using command line on proxmox without using using the WEB-UI\n#!/bin/bash function newqemu_vm { qm create $vmid --name $name --memory $ram --net0 virtio,bridge=vmbr0 qm importdisk $vmid /var/lib/vz/template/qemu/debian-12-genericcloud-amd64-20230910-1499.qcow2 amogha -format qcow2 sleep 5 qm set $vmid --scsihw virtio-scsi-pci --scsi0 amogha:vm-$vmid-disk-0 qm set $vmid --ide2 amogha:cloudinit --boot c --bootdisk scsi0 --serial0 socket --vga serial0 qm set $vmid --ipconfig0 ip=dhcp qm resize $vmid scsi0 +\"$size\"G qm set $vmid --sshkey ~/.ssh/id_rsa.pub qm start $vmid } echo \"HostName of the VM:\" read name echo \"Enter new VMID:\" read vmid echo \"Enter number of CPU cores:\" read cpucores echo \"Ram:\" read ram echo \"Enter Total Storage of the VM: [Example: +11G ]\" read size newqemu_vm :wq #for now"},"title":"Customize .qcow2 image"},"/docs/hacks/mapping-of-physical-usb-ports-to-device-names/":{"data":{"":"","how-to-map-physical-usb-ports-to-device-names-on-gnulinux#How to Map Physical USB ports to Device Names on GNU/Linux":"lsusb command$ lsusb Bus 002 Device 004: ID 04b3:3025 IBM Corp. NetVista Full Width Keyboard Bus 002 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub Bus 003 Device 123: ID 0951:1666 Kingston Technology DataTraveler 100 G3/G4/SE9 G2/50 Bus 003 Device 002: ID 2109:0815 VIA Labs, Inc. USB3.0 Hub $ lsusb -t /: Bus 06.Port 1: Dev 1, Class=root_hub, Driver=xhci_hcd/2p, 10000M |__ Port 2: Dev 2, If 0, Class=Hub, Driver=hub/7p, 5000M /: Bus 05.Port 1: Dev 1, Class=root_hub, Driver=ehci-pci/3p, 480M |__ Port 1: Dev 2, If 0, Class=Hub, Driver=hub/8p, 480M /: Bus 04.Port 1: Dev 1, Class=root_hub, Driver=xhci_hcd/2p, 480M /: Bus 03.Port 1: Dev 1, Class=root_hub, Driver=xhci_hcd/4p, 5000M |__ Port 4: Dev 2, If 0, Class=Hub, Driver=hub/4p, 5000M |__ Port 2: Dev 123, If 0, Class=Mass Storage, Driver=usb-storage, 5000M /: Bus 02.Port 1: Dev 1, Class=root_hub, Driver=ehci-pci/3p, 480M |__ Port 1: Dev 2, If 0, Class=Hub, Driver=hub/6p, 480M |__ Port 3: Dev 4, If 0, Class=Human Interface Device, Driver=usbhid, 1.5M /: Bus 01.Port 1: Dev 1, Class=root_hub, Driver=xhci_hcd/4p, 480M |__ Port 4: Dev 2, If 0, Class=Hub, Driver=hub/4p, 480M ‚Äúlsusb‚Äù is a utility of ‚Äúusbutils‚Äù in GNU/Linux to display information about the USB Buses and the USB‚Äôs attached to the buses.The output of the command displays the VendorID:ProductID and to which bus it is attached,the ‚ÄúKingston Technology DataTraveler‚Äù bearing the VendorID:ProductID (0951:1666) attached to bus 003, the lsusb command with option ‚Äú-t‚Äù provides a tree like output in a hierarchial structure.\n‚Äúlsblk‚Äù is a tree-like structure to identify devices and their partitions,and also displays device name (/dev/sd* if its a hard disk,/dev/nvme0n1 in case of SSD),size of the drive/partition, whether it is a disk/partition and the device‚Äôs mountpoints,here the /dev/sda* is the hard disk and sda1/2/5 are the partitions of the hard disk and /dev/sdb is the Kingston USB drive connected.\n$ lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTS sda 8:0 0 119.2G 0 disk ‚îú‚îÄsda1 8:1 0 118.3G 0 part / ‚îú‚îÄsda2 8:2 0 1K 0 part ‚îî‚îÄsda5 8:5 0 976M 0 part [SWAP] sdb 8:16 1 28.9G 0 disk sr0 11:0 1 1024M 0 rom Suppose if there are multiple USB sticks attached to mutiple physical USB ports how to know which device names is mapped to which USB port ?\nIf there are multiple USB‚Äôs attached how do we get to know USB drive‚Äôs device file and to which port that USB is connected ?\nThe answer is by /dev/disk/* Everything in GNU/Linux is either a file or a directory,so even the disk are represented as files in GNU/Linux.\n$ ls -ltrh /dev/disk/ total 0 drwxr-xr-x 2 root root 100 Aug 28 12:28 by-partuuid drwxr-xr-x 2 root root 100 Aug 29 09:49 by-uuid drwxr-xr-x 2 root root 260 Aug 29 09:49 by-path drwxr-xr-x 2 root root 60 Aug 29 09:49 by-label drwxr-xr-x 2 root root 160 Aug 29 09:49 by-id drwxr-xr-x 2 root root 260 Aug 29 09:49 by-diskseq The USB disks can be identified by the Partition UUID, UUID of the disk, by path, by label of the disk and also by disk sequence.\nBy UUID(Universally Unique Identifier) by uuid$ cat /etc/fstab UUID=3341b336-0c26-4079-b3aa-faca8e2dd8b6 / ext4 errors=remount-ro 0 1 UUID=53b53d97-b5e4-43fe-b560-2a01f119b6cf none swap sw 0 0 /dev/sr0 /media/cdrom0 udf,iso9660 user,noauto 0 0 $ ls -ltrh /dev/disk/by-uuid/ total 0 lrwxrwxrwx 1 root root 10 Aug 22 10:40 3341b336-0c26-4079-b3aa-faca8e2dd8b6 -\u003e ../../sda1 lrwxrwxrwx 1 root root 10 Aug 22 10:40 53b53d97-b5e4-43fe-b560-2a01f119b6cf -\u003e ../../sda5 lrwxrwxrwx 1 root root 9 Aug 29 09:49 2010-10-06-11-43-04-00 -\u003e ../../sdb The device /dev/disk/by-uuid/3341b336-0c26-4079-b3aa-faca8e2dd8b6 is simply a symbolic link to actual an device,the reason being this is device name may change depending whether disk is attached or not,whereas these links will point to the same drive,so henceforth safer to use.\nBy-Label by-label$ ls -ltrh /dev/disk/by-label/ total 0 lrwxrwxrwx 1 root root 9 Aug 29 09:49 VINAY-USB -\u003e ../../sdb Labels are easy, it avoids confusion in identifying disk, instead of remembering /dev/sda device file names.\nBy-Path by-path$ ls -ltrh /dev/disk/by-path/ total 0 lrwxrwxrwx 1 root root 9 Aug 22 10:40 pci-0000:00:1f.2-ata-2.0 -\u003e ../../sda lrwxrwxrwx 1 root root 9 Aug 22 10:40 pci-0000:00:1f.2-ata-2 -\u003e ../../sda lrwxrwxrwx 1 root root 10 Aug 22 10:40 pci-0000:00:1f.2-ata-2-part2 -\u003e ../../sda2 lrwxrwxrwx 1 root root 10 Aug 22 10:40 pci-0000:00:1f.2-ata-2.0-part2 -\u003e ../../sda2 lrwxrwxrwx 1 root root 10 Aug 22 10:40 pci-0000:00:1f.2-ata-2-part1 -\u003e ../../sda1 lrwxrwxrwx 1 root root 10 Aug 22 10:40 pci-0000:00:1f.2-ata-2.0-part1 -\u003e ../../sda1 lrwxrwxrwx 1 root root 10 Aug 22 10:40 pci-0000:00:1f.2-ata-2-part5 -\u003e ../../sda5 lrwxrwxrwx 1 root root 10 Aug 22 10:40 pci-0000:00:1f.2-ata-2.0-part5 -\u003e ../../sda5 lrwxrwxrwx 1 root root 9 Aug 22 10:40 pci-0000:00:1f.2-ata-3.0 -\u003e ../../sr0 lrwxrwxrwx 1 root root 9 Aug 22 10:40 pci-0000:00:1f.2-ata-3 -\u003e ../../sr0 lrwxrwxrwx 1 root root 9 Aug 29 09:49 pci-0000:00:14.0-usb-0:4.2:1.0-scsi-0:0:0:0 -\u003e ../../sdb Here /dev/sdb is the USB device attached and ‚Äúpci-0000:00:14.0-usb-0:4.2:1.0-scsi-0:0:0:0‚Äù file which represents the USB device describes that the USB device is connected from PCI bus to SCSI adapter.‚Äúby-path‚Äù is the pci path of the disk device. this device file name is created depending on the shortest physical path to the device. ‚Äú/dev/sda‚Äù the first SCSI drive on the first SCSI bus,/dev/sdb is the second SCSI drive and /dev/sdc is the third SCSI drive and so on.\n:wq "},"title":"Mapping of Physical USB ports to Device Name on GNU/Linux"},"/docs/interception-vimproved/":{"data":{"":"","#":"Setting up Interception Vimproved on Debian Bookworm I started learning vim few months ago and wanted to try vim key bindings like shortcuts on my laptop after trying a mechanical hackable keyboard.\nInterception Vimproved is a plugin for interception-tools which combines both caps2esc and space on hold work as special fn key. This blog post shows how to setup interception-vimproved using interception-tools on Debian Bookworm.\nStep 1: Dependencies Installing Dependencies to build interception-vimproved on Debian Bookworm GNU/Linux\nsudo apt install interception-tools meson libyaml-cpp-dev cmake interception-tools is a small set of tools for input events of devices,that can be used to customize the behaviour of input keyboard mappings.\nThe advantage of interception-tools operates at lower level compared to xmodmap by using libevdev and libudev.\nStep 2: Clone \u0026 Build Clone interception-vimproved repository and build\n$ git clone \"https://github.com/maricn/interception-vimproved\" $ cd interception-vimproved $ sudo make install Clone the git repository and change the directory, and then launch a make install command to build.\nStep 3: Configuration Create a new file called udevmon.yaml in /etc/interception and paste the following contents into the file /etc/interception/udevmon.yaml\n- JOB: \"interception -g $DEVNODE | interception-vimproved /etc/interception-vimproved/config.yaml | uinput -d $DEVNODE\" DEVICE: NAME: \".*((k|K)(eyboard|EYBOARD)).*\" udevmon.yaml is like a job specification for udevmon,specifying that it matches with (k|K)(eyboard|EYBOARD)) input device.\n‚ÑπÔ∏è I haven‚Äôt tested this for an External Keyboard Input device,but works fine for the built-in keyboard of the laptop. Step 4: Reload udevmon Reload udevmon using systemctl\n$ sudo systemctl restart udevmon Hack around the config To change any keybindings or to add new mappings the config file is present in config.yaml located in /etc/interception-vimproved/ when a sudo make install is launched the config file is copied to /etc/interception-vimproved/config.yaml.\nmy config.yaml has the below shortcuts\n/etc/interception-vimproved/config.yaml- intercept: KEY_CAPSLOCK ontap: KEY_ESC onhold: KEY_LEFTCTRL - intercept: KEY_ENTER # not necessary: ontap: KEY_ENTER is inferred if left empty onhold: KEY_RIGHTCTRL # this is a layer. hold space (onhold) contains several remappings - intercept: KEY_SPACE onhold: # special chars - from: KEY_E to: KEY_ESC # alternative syntax - {from: KEY_D, to: KEY_DELETE} - {from: KEY_B, to: KEY_BACKSPACE} # vim home row - {from: KEY_H, to: KEY_LEFT} - {from: KEY_J, to: KEY_DOWN} - {from: KEY_K, to: KEY_UP} - {from: KEY_L, to: KEY_RIGHT} # vim above home row - {from: KEY_Y, to: KEY_HOME} - {from: KEY_U, to: KEY_PAGEDOWN} - {from: KEY_I, to: KEY_PAGEUP} - {from: KEY_O, to: KEY_END} # number row, to F keys - {from: KEY_1, to: KEY_F1} - {from: KEY_2, to: KEY_F2} - {from: KEY_3, to: KEY_F3} - {from: KEY_4, to: KEY_F4} - {from: KEY_5, to: KEY_F5} - {from: KEY_6, to: KEY_F6} - {from: KEY_7, to: KEY_F7} - {from: KEY_8, to: KEY_F8} - {from: KEY_9, to: KEY_F9} - {from: KEY_0, to: KEY_F10} - {from: KEY_MINUS, to: KEY_F11} - {from: KEY_EQUAL, to: KEY_F12} # xf86 audio - {from: KEY_M, to: KEY_MUTE} - {from: KEY_COMMA, to: KEY_VOLUMEDOWN} - {from: KEY_DOT, to: KEY_VOLUMEUP} # mouse navigation - {from: BTN_LEFT, to: BTN_BACK} - {from: BTN_RIGHT, to: BTN_FORWARD} Interception-tools is packaged on debian,interception-vimproved is not, that is the reason we are building the source of interception-vimproved,hopefully i‚Äôll try packaging it !.\nArch has interception-tools already packaged here is the link\n:wq #until next time "},"title":"Interception Vimproved"},"/docs/java/":{"data":{"":"Java Learnings Spring Framework, Java builds and much more stufff‚Ä¶"},"title":"Java"},"/docs/java/ant/":{"data":{"":"Apache Ant, is Java based make tool, which process according to the build commands given in build.xml. Ant is mainly used for Java applications, which can be used to run,compile and package java software. Configuration for the build is done in build.xml file. Software projects looking for build tool and dependency management can use Ant.\nSimple Hello World project enabling Ant build system for the Hello World project. Pre-requisties are to install openjdk and ant build system.\nHelloWorld.java$ cat src/HelloWorld.java public class HelloWorld{ public static void main(String []args){ System.out.println(\"Hello World\"); System.out.println(\"Vinay Keshava\"); } } The conventional way to run the above simple HelloWorld.java is using javac and java.\n$ javac HelloWorld.java $ java HelloWorld Hello World Vinay Keshava In order to simplify the processing of building and running the java code, we use build systems like Apache Ant,Maven and Gradle. Here lets create a simple build.xml file for the above HelloWorld.java using Ant build system.\n$ tree . ‚îú‚îÄ‚îÄ build.xml ‚îî‚îÄ‚îÄ src ‚îî‚îÄ‚îÄ HelloWorld.java 1 directory, 2 files Create a project where the source within the src directory and build.xml within the root directory having the contents.\nbuild.xml\u003cproject\u003e \u003ctarget name=\"clean\"\u003e \u003cdelete dir=\"build\"/\u003e \u003c/target\u003e \u003ctarget name=\"compile\"\u003e \u003cmkdir dir=\"build/classes\"/\u003e \u003cjavac srcdir=\"src\" destdir=\"build/classes\"/\u003e \u003c/target\u003e \u003ctarget name=\"jar\"\u003e \u003cmkdir dir=\"build/jar\"/\u003e \u003cjar destfile=\"build/jar/HelloWorld.jar\" basedir=\"build/classes\"\u003e \u003cmanifest\u003e \u003cattribute name=\"Main-Class\" value=\"HelloWorld\"/\u003e \u003c/manifest\u003e \u003c/jar\u003e \u003c/target\u003e \u003ctarget name=\"run\"\u003e \u003cjava jar=\"build/jar/HelloWorld.jar\" fork=\"true\"/\u003e \u003c/target\u003e \u003c/project\u003e A simple xml file having tags like targets where the operations are defined, here we have three target types compile,jar,run. In compile phase a directory called build/classes is created, and destination directory is set.\nvinay@falcon:/tmp/ant-sample$ ant compile Buildfile: /tmp/ant-sample/build.xml compile: [mkdir] Created dir: /tmp/ant-sample/build/classes [javac] /tmp/ant-sample/build.xml:9: warning: 'includeantruntime' was not set, defaulting to build.sysclasspath=last; set to false for repeatable builds [javac] Compiling 1 source file to /tmp/ant-sample/build/classes BUILD SUCCESSFUL Total time: 0 seconds vinay@falcon:/tmp/ant-sample$ ant jar Buildfile: /tmp/ant-sample/build.xml jar: [mkdir] Created dir: /tmp/ant-sample/build/jar [jar] Building jar: /tmp/ant-sample/build/jar/HelloWorld.jar BUILD SUCCESSFUL Total time: 0 seconds vinay@falcon:/tmp/ant-sample$ ant run Buildfile: /tmp/ant-sample/build.xml run: [java] Hello World [java] Vinay Keshava BUILD SUCCESSFUL Total time: 0 seconds All the above three commands can be run simultaneously, ant compile jar run where the code is compiled,packaged and run.\nCompile : a directory build/classes is created, source directory is set with javac command tag.\nJar : creating a directory build/jar,where the jar is stored.\nRun : running the HelloWorld.jar file."},"title":"Ant"},"/docs/java/java17/":{"data":{"":"","foreign-function-and-memory-api-in-java#Foreign Function and Memory API in java":" Foreign Function Interface and Memory API in java provide mechanisms to interact with libraries of other languages such as C or C++. This allows developers to leverage existing native libraries or access low level system libraries. For example a native library written in C with .so or .a files and accessing these over java is possible over foreign function interface. ","instanceof-pattern-matching#InstanceOf Pattern Matching":"","local-variable-type-inference#Local Variable Type Inference":" Type inference refers to the automatic detection of the datatype of a variable, done generally at the compile time. The traditional way of creating an object was:\nClass_name object_name = new Class_name(arguments); This is how things have been since the inception of java. If the type of object is clearly mentioned on the right side of the expression, mentioning the same thing before the name of the variable makes it redundant. Therefore the need to eliminate the redundancy and make variable declaration shorter.\nInitialization is mandatory on the right hand side of var. var order = ‚Äúfirst‚Äù;\nhere the right hand side of the assignment operator is String,so there‚Äôs need to declare the variable order as String on the left hand side, type inference comes into picture here. To make code readability easier, can declare local variables as non-null initializers with the ‚Äúvar‚Äù identifier.\nLocal variable type inference can be used in the traditional for loop can be for initialization.","record-classes#Record Classes":"Sealed Classes \u0026 Interfaces Limiting the extensibility of classes and interfaces, which means that can specify which other classes or interfaces are permitted to extend or implement them. Sealed Classespublic sealed class Shape permits Circle, Square {} public non-sealed class Square extends Shape{} public non-sealed class Circle extends Shape {} Sealed keywords to the class and specify which classes are permitted to inherit it by using the ‚Äúpermits keyword to the class\nShape is the Parent class which we specify to permit which classes can inherit,here the child classes are Square and Circle\n-Child classes of sealed class should be either sealed, non-sealed or final, here\npublic sealed class Shape permits Circle,Square{ public void printName() { System.out.println(\"Default\"); }} public non-sealed class Circle extends Shape { public void printName() { System.out.println(\"Circle\"); }} public non-sealed class Square extends Shape{ public void printName() { System.out.println(\"Square\"); }} Switch Statements Java.lang.Object is now supported in switch case with simplified return statement without having to use the return statement again.Below is the demo code for the demonstration which shows the traditional way of switch case which only supports int,byte,short. We can also make use of the switch case functionality over objects package java17features; public class SwitchExamples { // traditional Switch statement public String traditionalSwitch(int dayNum) { String day; switch (dayNum) { case 1: day = \"Monday\"; break; case 2: day = \"Tuesday\"; break; default: throw new IllegalArgumentException(\"Unexpected value: \" + dayNum); } return day; } public String simpleSwitch(String dayNum) { return switch (dayNum) { case \"Monday\" -\u003e \"Week day\"; case \"Tuesday\" -\u003e \"Week day\"; case \"Wednesday\" -\u003e \"Week day\"; case \"Thursday\" -\u003e \"Week day\"; case \"Friday\" -\u003e \"Week day\"; // multiple case values in single case label statements. case \"Saturday\", \"Sunday\" -\u003e \"Weekend\"; default -\u003e \"Unknown\"; }; } public Object getLength(Object obj) { return switch (obj) { case Integer i -\u003e \"It is an integer\"; case String s -\u003e \"It is a string\"; case Shape s -\u003e \"It is a Shape\"; default -\u003e \"It is none of the known data types\"; }; }} InstanceOf Pattern Matching Reducing redundant casting during the creation of objects. From java17 onwards we can do pattern matching without the need to need to do redundant casting for objects which can be done within the if condition Here, String s is tested and casted within the if statement avoiding the redundant casting in traditional way. //tradition way,redundant casting in line 8 void testInstanceOf(Object obj) { if(obj instanceof String) { String s = (String) obj; System.out.println(s.length()); } } // testing the instanceOf object in jdk17 void testInstanceOf2(Object obj) { if(obj instanceof String s) { System.out.println(s.length()); } Switch Expressions Pattern Matching using switch Expressions.Below is the example for switch expression feature in switch statement. public static double getPerimeter(Shape shape) throws IllegalArgumentException { switch (shape) { case Rectangle r: return 2 * r.length() + 2 * r.width(); case Circle c: return 2 * c.radius() * Math.PI; default: throw new IllegalArgumentException(\"Unrecognized shape\"); } } Record Classes Passing immutable data between objects is the most common operation that is done, there‚Äôs a lot of boilerplate code involved like getters, setters. We write classes to simply hold data such as database results, query results. Immutability ensures validity of objects. To accomplish immutability between objects we use ‚Äì\nprivate, final field for each piece of data. Getter for each field Public constructor for each field. Equals,hashCode and toString methods. We can reduce the number of lines using Lombok,since Lombok itself being a community project, relying on it as a dependency and backward compatibility issues within the JDK version can lead to complex problems. Lombok is a third party dependency which relies on community support for feature and development. To overcome this issue we use Records which can hold immutable data classes that require only type and name of fields. We create a record using its fields, the JDK compiler creates getters and setters and methods for Person avoiding the boilerplate code here. The Attributes of Person are accessed by ObjectName.attributename(), unlike get and set methods. Since Records are immutable objects we cannot change or set values to attributes once initialized.\npublic record Person(int id,String firstName,String lastName) {} System.out.println(\"Java 17 features: Records for immutability in Objects\"); Person person= new Person(1, \"Vinay\", \"Keshava\"); Person person1 = new Person(2,\"Mahesh\",\"Kumar\"); System.out.println(person.firstName()); System.out.println(person.lastName()); System.out.println(person.id()); System.out.println(person.equals(person1)); //false : since both are different objects Static variables and methods can be declared within the records. JDK compiler also create a default constructor for the record created.","sealed-classes--interfaces#Sealed Classes \u0026amp; Interfaces":"","strong-encapsulation-of-jdk-internal-apis#Strong Encapsulation of JDK Internal API‚Äôs":" From JDK 9 to 15, code from classpath could still access internal JDK API‚Äôs, applications with this issue were managed with the command line options, ‚Äìillegal-access. From JDK 17 onwards the access to JDK was deactivated, and ‚Äú‚Äîadd-exports‚Äù , ‚Äú‚Äîadd-open‚Äù gives access to internal API‚Äôs. ","switch-expressions#Switch Expressions":"","switch-statements#Switch Statements":"","textblocks#TextBlocks":" Textblock is to provide clarity by way of minimizing the java syntax required to render a string that spans multiple lines. In earlier releases of JDK explicit line terminators, concatenation and delimiters were used to implement multi line strings. // text blocks System.out.println(\"\"\" multi Line string using text blocks textblocks can also be used as method as in println \"\"\"); "},"title":"Java 17 Features"},"/docs/java/java8/":{"data":{"":"","comparable--comparator#Comparable \u0026amp; Comparator":"Date Time API Streams Lambda Expressions Comparable \u0026 Comparator ","date-time-api#Date Time API":"","lambda-expressions#Lambda Expressions":"","optional-class#Optional Class":"","streams#Streams":""},"title":"Java 8"},"/docs/java/lombok/":{"data":{"":"Lombok was created to avoid boilerplate code,Replaces code with java annotations\n- `@AllArgsConstructor`: Generates an all arguments AllArgsConstructor - `@Builder`: Generates class instances using builder API,we can build all the entire POJO using the parameters - `@Data`: is like having implicit @Getter, @Setter, @ToString, @EqualsAndHashCode and @RequiredArgsConstructor - `@Getter`: generates getter methods for the attributes - `@Setter`: generates setter methods for the attributes - `@NoArgsConstructor`: creates a constructor with no arguments - `@RequiredArgsConstructor`: creates a constructor with all final field attributes "},"title":"Lombok"},"/docs/java/springcore/":{"data":{"":"","#":"Spring is a popular framework in Java Enterprise Edition.Spring can be thought of as a framework of frameworks,because it provides support to other frameworks as well such as Hibernate,JPA etc\nSome of the key and core features of spring core are as belows:\nDependency Injection Dependency Injection provides Objects which an object needs.Dependency injection generally means passing a dependent object as a parameter to a method, rather than having the method create the dependent object.Instead of making the objects tightly coupled on other objects, an initiative to make objects loosely coupled.\nConventionally,we create objects using the new operator.\nclass Employee { private int id; private String name; private Address address; } } class Address { private String street; private String city; } } In this case Address class values are only set when the class Employee is instantiated,making it a tight coupling, spring resolves this type of tight coupling with the help of Dependency Injection in two ways, Setter Injection and Constructor Injection.This is achieved in spring by IOC.\nIn spring dependency injection is of two types, XML based and annotaiton based.\nInversion of Control Spring IoC container is the core of spring framework.It creates objects,configures and assemble their dependencies,manage entire life cycle of each object.\nInformation about the object‚Äôs configuration is done by the configuration file(XML),java annotations or java code,these objects are called Beans.\nSpring IoC internally uses Dependency Injection to manage object life cycle.\nSince the control of these objects are not in the hands of developers hence the name,Inversion of Control.\nThere are two types of IoC containers in Spring\nBean Factory Application Context Bean Factory is the basic version of IoC container,while ApplicationContext extends the features of BeanFactory.\nSome of the main features of IoC containers.\nCreating Objects Managing dependencies Application Configuration Managing Objects Constructor Injection \u0026 Setter Injection In constructor injection dependencies are passed as parameter to the class‚Äôs constructor.In this way all the dependencie‚Äôs objects are created during the objection creation,say for example there is a class called Employee with another object Address as its dependency,along with other attributes. The Address class object is created whenever the Employee class object is instantiated.\n@Autowired annotation uses constructor Injection.\nIn Setter Injection dependencies are injected with the help of getters and setters\nAutowiring Autowiring in spring framework is used to automatically inject dependencies.Spring IoC container detects the dependencies mentioned in the cofiguration file and the realtionship between the beans,this is known as autowiring. @Autowired annotation is used,autowiring in spring internally uses constructor injection.\nCommon Annotations @Configuration: Used to declare a class with one or more @Bean methods.These classes are processed by the spring container to generate bean definitions.\n@Bean: Indicates that a method produces a bean to be managed by the Spring container.\n@ComponentScan : is used along with @Configuration annotation to specify the packages that we want to be scanned.If no arguments it scans the current package and all of its sub packages.\n@Component : is a class level annotation,used to denote a class as component.This annotation is used to mark the beans as Spring managed components.\n@Service - Annotated class is a service,specialization of @Component, used for business logic or services in it. @Repository - dealing with CRUD operations,mostly deals with DAO or repositories that deal with databases. @Controller - front controllers,responsible to handle user requests and for returning appropriate responses to user. @Autowired : is used for automatic injection of beans.\nSpring MVC Annotations @Controller or @RestController components use annotation to express request mappings,result input,exception handling and more.\n@RequestMapping : class level or method level annotation in controller,class level annotation maps a specific request path onto a controller,used to handle web requests,\n@PathVariable : handle template variables in request URI mapping.\n@RequestParam : to read form data and bind it automatically to the parameter present in the provided method.\n@RequestBody : RequestBody is mainly used with CRUD operations to read request body.\n@ResponseBody : is used with GET methods to write the response body content.\nSpring Annotations. @SpringBootApplication : Many spring boot developers like their apps to use Auto Configuration,component scan and be able define extra configuration on their application class.\n- @EnableAutoConfiguration: enables spring boot's auto configuration - @ComponentScan : enable component scan on the package where the application is located. - @Configuration : allow to register extra beans @EnableAutoConfiguration : attempts to automatically configure your spring application based on the dependencies.\nSpring Data JPA Annotations @Transactional: class or method level annotation,Propagation Type of the transaction, Isolation Level of the transaction,Timeout for the transaction,Rollback rules for transactions.\n@Id : marks field in model class as primary key.\n@Query: Native SQL queries \u0026 JPQL implementation.\n@Lock : We can configure Lock Mode when we execute a repository query method. Available lock modes are : - READ - WRITE - OPTIMISTIC - OPTIMISTIC_FORCE_INCREMENT - PESSIMISTIC_READ - PESSIMISTIC_WRITE - PESSIMISTIC_FORCE_INCREMENT - NONE"},"title":"Spring Core Framework"},"/docs/ldap/":{"data":{"":"Documenting stuff learning about OpenLDAP with two types of configuration, the traditional slapd.conf and slapd.d way of configuring."},"title":"LDAP"},"/docs/ldap/introduction/":{"data":{"":"","#":"Directory Service ‚ÑπÔ∏è Difference between a folder and a directory Folder is for grouping items. Directory has index. It is for finding specific item,Directory is a filesystem concept. In simple terms think directory like a telephone directory which is in a hierarchial structure. The term directory service refers to the collection of software, hardware, and processes that store information about an enterprise, subscribers, or both, and make that information available to users. A directory service consists of at least one instance of Directory Server and at least one directory client program. Client programs can access names, phone numbers, addresses, and other data stored in the directory service.\nA directory is similar to database,which is attribute-based data;where data is read more often than write.\nDirectory Server provides Global Directory Services which means it provides information to wide variety of applications,rather than using databases with different applications,which is very hard to administrate.Directory server is a single solution to manage the same information ‚ÑπÔ∏è For example, an organization has three different applications running like nextcloud,email and matrix server and all the applications are accessed by same credentials,if separate database schema‚Äôs are used for each application it would be hard to manage,if user requesting a password change in one application maybe not be replicated into another application;this problem is solved single,centralized repository of directory information. LDAP provides a common language that client applications and servers use to communicate with one another. LDAP is a ‚Äúlightweight‚Äù version of the Directory Access Protocol (DAP)\nLDAP vs Database How often does your data change? Directory servers are used for reads,if your data changes often and have many write operations directory service is not a ideal choice,RDBMS would be the ideal choice. Type of Data? If data is defined in Key:Value pair or Attribute:Value pair, Directory service would be the best choice,like user profile. Data in Hierarchial tree like structure If data can be modeled into a tree like structure,accessing the parent and child node in the tree,directory service The read:write ratio in LDAP is of 500:1 so more number of read operations are done than the write/update operations.\nOpenLDAP LDAP stands for Lightweight Directory Access Protocol, for accessing directory services.OpenLDAP is the implementation of the LDAP protocol,is a communications protocol that defines the methods in which a directory service can be accessed. The LDAP information model is based on entries, which is a collection of attributes that has a globally unique Distinguished Name(DN) OpenLDAP is the implementation of the LDAP protocol which belong to User Management and Authentication in tech.\nThe LDAP protocol both authenticates and authorize‚Äôs users to their resources.The protocol authenticates users with a bind operation that allows users to communicate with LDAP directory then authorizes the authenticated user to resources they need if they have access that are defined in rules.Once a user is successfully authenticated, they need to be authorized to access the resource(s) requested. With OpenLDAP, for example, users belong to groups that can be assigned different permissions. If the authenticating user is assigned the correct permissions to access a certain resource, the LDAP protocol will authorize them to it; if not, the protocol will deny access.\nLDAP Data components Directory: an LDAP server\nDIT: the tree of entries stored within a directory server\nAttributes\nData in LDAP system is stored in elements called attributes,like Key Value pair.Data in the attribute must match to the type defined in the attribute‚Äôs initial declaration.\nmail: user@example.com dc:example,dc:com Entries Attributes by themselves are not useful, a group or collection of attributes under a name represents an entry.\ndn: ou=people,dc=example,dc=com objectClass: person sn: Ramesh cn: Varma An example entry displayed in LDIF ( LDAP Data Interchange Format).\n$ cat ldif/user.ldif dn: uid=vinay.m,ou=People,dc=vinay,dc=im objectClass: top objectClass: inetOrgPerson uid: vinay.m cn: vinay sn: m userPassword: test ou: People dn: uid=akshay,ou=People,dc=vinay,dc=im objectClass: top objectClass: inetOrgPerson uid: akshay cn: akshay sn: p userPassword: test ou: People ObjectClass Object class: a collection of required (MUST) and optional (MAY) attributes. Object classes are further subdivided into STRUCTURAL and AUXILIARY classes, and they may inherit from each other.Every entry has a structural Object class which indicates what type of object an entry is and also can have more auxiliary object that have additional characteristics for that entry.\nThe ObjectClass definitions are stored in the schema files.Object class must have an object identifier (OID) Object classes may also list a set of required attribute types (so that any entry with that object class must also include those attributes) and/or a set of optional attribute types (so that any entry with that object class may optionally include those attributes).OID‚Äôs are sequence of numbers separated by periods(.), ‚Äú1.2.840.113556.1.4.473‚Äù\nSchema Schema‚Äôs define the directory, specifying the configuration of the directories including syntax,object classes,attribute types and matching rules.\nReferences https://access.redhat.com/documentation/en-us/red_hat_directory_server/11/html/deployment_guide/introduction_to_directory_services\nhttps://www.zytrax.com/books/ldap\nhttps://tylersguides.com/guides/openldap-how-to-add-a-user/\nhttps://www.zytrax.com/books/ldap/"},"title":"Introduction"},"/docs/ldap/slapd-conf/":{"data":{"":"","#":"slapd - Standalone LDAP Daemon slapd is a LDAP directory server,which stands for Standalone LDAP daemon.Providing simple auth and security layer.\n$ sudo apt install slapd ldapvi ldap-utils ‚ö†Ô∏è when asked for administration password prompt during installation just press Enter,we reconfigure slapd using dpkg-reconfigure after the installation. $sudo dpkg-reconfigure slapd ‚ÑπÔ∏è Reconfiguration:\nOmit initial LDAP server config : No we obviously want to create intial configuration. DNS Domain Name : domain name to build the base DN of LDAP directory in this case we are choosing vinay.im. Organization Name: Type down the organization name( here XYZ Pvt Ltd) Choose an Admin Password of your choice( for tutorial purpose i‚Äôve choosed test) and choose MDB as backend database If asked to purge database when slapd is removed we choose No,will be helpful when we want to switch to a different LDAP server. Choose Yes if you want to backup the current existing database to /var/backups. To have a look at the LDAP database , simple execute slapcat with sudo privileges.\n$ sudo slapcat$ sudo slapcat dn: dc=vinay,dc=im objectClass: top objectClass: dcObject objectClass: organization o: XYZ Pvt Ltd dc: vinay structuralObjectClass: organization entryUUID: 8057316c-ed6e-103d-8b93-b9da23579469 creatorsName: cn=admin,dc=vinay,dc=im createTimestamp: 20230922083350Z modifiersName: cn=admin,dc=vinay,dc=im modifyTimestamp: 20230922083350Z ‚ÑπÔ∏è Config files are present in /etc/ldap directory.\nSchemas can be added within the slap.d directory for server customization.\nDatabase is stored in /var/lib/ldap having two files data.mdb and lock.mdb. $ sudo cp /usr/share/doc/slapd/examples/slapd.conf /etc/ldap/ Copy the example config file slapd.conf to /etc/ldap, and replace DNS domain components dc=example to dc=vinay and dc=com to dc=im everywhere in the config, also update /etc/default/slapd from SLAPD_CONF to SLAPD_CONF=/etc/ldap/slapd.conf and update slapd service by sudo systemctl restart slapd\nIn /etc/ldap/slapd.conf under suffix \"dc=vinay,dc=com\" add the following lines\nrootdn \"cn=admin,dc=vinay,dc=com\" rootpw \"test\" Restart the slapd service again.\n$ sudo systemctl restart slapd ldapsearch ldapsearch anonymous query$ldapsearch -x -b \"dc=vinay,dc=im\" # vinay.im dn: dc=vinay,dc=im objectClass: top objectClass: dcObject objectClass: organization o: XYZ Pvt Ltd dc: vinay # search result search: 2 result: 0 Success # numResponses: 2 ldapsearch authenticating with admin user$ ldapsearch -D cn=admin,dc=vinay,dc=im -w test -b dc=vinay,dc=im # extended LDIF # # LDAPv3 # base \u003cdc=vinay,dc=im\u003e with scope subtree # filter: (objectclass=*) # requesting: ALL # # vinay.im dn: dc=vinay,dc=im objectClass: top objectClass: dcObject objectClass: organization o: XYZ Pvt Ltd dc: vinay # search result search: 2 result: 0 Success # numResponses: 2 # numEntries: 1 -D {dn} / --bindDN {dn} ‚Äî The DN to use to bind to the directory server when performing simple authentication,to use the distinguished binddn name to bind the LDAP directory. -w - this option is used to provide the password on the command line for auth, -W option is used to ask for prompt for typing invisible password without actualling having to type the pass on cli. -b - search base as the starting point for the search instead of default. -x option in ldapsearch is used for simple authentication instead of SASL. The above command search‚Äôs through the ldap directory server with admin distinguished name providing password with the -w option and setting the searchbase to start from the rootdn.\n‚Äì To list all users on ldap\n$ ldapsearch -D \"cn=admin,dc=vinay,dc=com\" -W -b \"dc=vinay,dc=com\" $ slapcat lists all users from the base dn\nAdding OU (Organization Unit) Organizational units (OUs) are used to organize entries within the directory tree and can be used to delegate administrative responsibilities within your organization. It‚Äôs important to keep your directory organized and well-structured from the beginning; otherwise it will quickly become unwieldy and difficult to manage.\nCreate a directory called ldif(LDAP Interchange Format) in /etc/ldap and create a file called people.ldif and paste the following contents.\n$ cat /etc/ldap/ldif/people.ldif dn: ou=People,dc=vinay,dc=com ou: People cn: people sn: people objectClass: top objectClass: inetOrgPerson $ ldapadd -D cn=admin,dc=vinay,dc=im -w test -f /etc/ldap/ldif/people.ldif adding new entry \"ou=People,dc=vinay,dc=im\" now slapcat command shows the OU added within the command output.\nAdd new User Adding new user within the newly created OU(Organizational Unit)\n/etc/ldap/john.ldif# cat john.ldif dn: uid=john,ou=People,dc=vinay,dc=com objectClass: top objectClass: inetOrgPerson uid: john cn: john ou: People sn: abraham mail: john@vinay.com userPassword: john Adding the .ldif file using ldapadd command\n$ sudo ldapadd -D \"cn=admin,dc=vinay,dc=com\" -W -f john.ldif Enter LDAP Password: adding new entry \"uid=john,ou=People,dc=vinay,dc=com\" Read entries within OU as admin Now we have added an OU and a user john to People OU,lets try to ldapsearch the users within the OU as admin\ndisplay users of an OU as admin$ ldapsearch -D \"cn=admin,dc=vinay,dc=com\" -w vinay.com -b \"ou=People,dc=vinay,dc=com\" # extended LDIF # # LDAPv3 # base \u003cou=People,dc=vinay,dc=com\u003e with scope subtree # filter: (objectclass=*) # requesting: ALL # # People, vinay.com dn: ou=People,dc=vinay,dc=com ou: People cn: people sn: people objectClass: top objectClass: inetOrgPerson # john, People, vinay.com dn: uid=john,ou=People,dc=vinay,dc=com objectClass: top objectClass: inetOrgPerson uid: john cn: john ou: People ou: Support sn: abraham mail: john@vinay.com userPassword:: am9obg== Read entries within OU as normal user. $ ldapsearch -D \"uid=john,ou=People,dc=vinay,dc=com\" -w john -b \"ou=People,dc=vinay,dc=com\" # extended LDIF # # LDAPv3 # base \u003cou=People,dc=vinay,dc=com\u003e with scope subtree # filter: (objectclass=*) # requesting: ALL # # People, vinay.com dn: ou=People,dc=vinay,dc=com ou: People cn: people sn: people objectClass: top objectClass: inetOrgPerson # john, People, vinay.com dn: uid=john,ou=People,dc=vinay,dc=com objectClass: top objectClass: inetOrgPerson uid: john cn: john ou: People ou: Support sn: abraham mail: john@vinay.com userPassword:: am9obg== Modifying existing entries Using ldapmodify to update entries. Now to modify an already added record we use ldapmodify and the attributes that are to be modified are put into a separate file,here john-modify.ldif and to demonstrate here an OU Support is added to the existing entry,along with People OU.\njohn-modify.ldif$ cat /etc/ldap/ldif/john-modify.ldif dn: uid=john,ou=People,dc=vinay,dc=com changetype: modify add: ou ou: Support ldapmodify command for john-modify.ldif$ ldapmodify -D \"cn=admin,dc=vinay,dc=com\" -W -f john-modify.ldif Enter LDAP Password: modifying entry \"uid=john,ou=People,dc=vinay,dc=com\" Now running a slapcat command shows the updated OU Support\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 dn: uid=john,ou=People,dc=vinay,dc=com objectClass: top objectClass: inetOrgPerson uid: john cn: john ou: People ou: Support sn: abraham mail: john@vinay.com userPassword:: am9obg== structuralObjectClass: inetOrgPerson entryUUID: 50ea0ea8-f23d-103d-816b-4d9c39504958 creatorsName: cn=admin,dc=vinay,dc=com createTimestamp: 20230928112421Z entryCSN: 20230928120656.291224Z#000000#000#000000 modifiersName: cn=admin,dc=vinay,dc=com modifyTimestamp: 20230928120656Z 2.Using ldapvi to update LDAP entries with a text editor.\nldapvi example$ ldapvi -d --host vinay.im ldapvi is a ldap client using which we can search,modify and delete entries which is easier than ldapmodify instead of adding the updated records in a separate ldif file. ldapvi prompts to open text editor to modify entries,just similar to text editor.\nThe above command will bind anonmously to hostname, here the hostname is vinay.im.After making necessary changes in the entry save from the text editor.\n# ldapvi -d --host nextcloud.vinay.com 3 entries read add: 0, rename: 0, modify: 1, delete: 0 Action? [yYqQvVebB*rsf+?] b --- Login --- Login --- Login Type M-h for help on key bindings. Filter or DN: cn=admin,dc=vinay,dc=im Password: ***** Bound as cn=admin,dc=vinay,dc=im. add: 0, rename: 0, modify: 1, delete: 0 Action? [yYqQvVebB*rsf+?] y Done. after saving and exiting from text editor, an interactive bash prompt [yYqQvVebB*rsf+?]\ny to commit changes.\ne to edit changes.\nv to view changes as LDIF change records.\nb to show login and rebind - we are trying to auth from admin and save the changes to LDAP entries.\n[Reference serverfault] https://serverfault.com/questions/290296/ldapadd-ldapmodify-clarifications-needed-about-these-commands #### Verifying the ```slapd.conf``` Configuration file ```bash $sudo slaptest -v -f /etc/ldap/slapd.conf config file testing succeeded -f : Specifying an alternative configuration file.\n-v : enable verbose mode.\nConventions in OpenLDAP dn - Distinguished Name\nRDN - Relative Distinguished Name\ncn - Common Name\ndc - Domain Component\nmail - Email Address\nou - Organization Unit\nldif - LDAP Data Interchange Format\nldap - Lightweight Directory Access Protocol\nReferences https://access.redhat.com/documentation/en-us/red_hat_directory_server/11/html/deployment_guide/introduction_to_directory_services\nhttps://www.zytrax.com/books/ldap\nhttps://tylersguides.com/guides/openldap-how-to-add-a-user/\nhttps://www.zytrax.com/books/ldap/"},"title":"OpenLDAP (slapd.conf)"},"/docs/ldap/terminology/":{"data":{"":"","#":"Terminology used in LDAP DIT Directory Information Tree root entry {Object}(Also called Objects) objectclass 1 This object class consists of zero or more attributes objectclass 2 This object class consists of zero or more attributes entry {Object} ObjectClass ObjectClass Data is represented as hierarchy of objects,each of which is called entry.The resulting tree structure is called a Directory Information Tree (DIT). The top entry of the tree is called root.\nEach entry in the tree has one parent entry and zero or more child entries.\nEach entry is composed of one or more objectClasses. -\u003e These objectClasses contain zero or more attributes.\nThese attributes have names just like values.\nObjectClasses. Objectclasses is like a container of attributes,where each objectClass has a unique name.There exists a predefined set of ObjectClasses,each of which contains lot of attributes.\nCharacteristics of ObjectClasses:\nobjectClasses defines whether the attribute member should be MUST or MAY be present. objectClass types: STRUCTURAL,AUXILIARY,ABSTRACT, and there should be atleast one STRUCTURAL objectClass with zero or more AUXILIARY objectClasses. objectClass inherits properties and characteristics from its parent objectClass (including its attributes). Attributes. Attributes contains values,which are present within the objectClass,each attribute define the data type. Attributes are mostly defined in key=value pair.\nAttributes can be optional MAY or mandatory MUST defined in that object class.If it is inherited by multiple objectClasses, in one objectClass it can be mandatory in another object class it can be optional, this is defined by the objectClass.\nAttributes can be SINGLE or MUTLI valued.\nsome examples for attributes like cn aliased commonName which is within the objectClass person,organizationalPerson and so on..\nAnother example is dc aliased domainComponent which is present under the objectClass dcObject.\n# Entry Level Hierarchy dn: dc=example,dc=com dc: example description: The best company in the whole world objectClass: dcObject objectClass: organization o: Example, Inc. ## FIRST Level hierarchy - people # this is an ENTRY sequence and is preceded by a BLANK line dn: ou=people, dc=example,dc=com ou: people description: All people in organisation objectClass: organizationalUnit ## SECOND Level hierarchy - people entries # this is an ENTRY sequence and is preceded by a BLANK line dn: cn=Robert Smith,ou=people,dc=example,dc=com objectclass: inetOrgPerson cn: Robert Smith cn: Robert sn: Smith uid: rsmith mail: robert@example.com mail: r.smith@example.com ou: sales DN attribute is the sum of all the RDN (Root Distinguished Name)"},"title":"Terminology"},"/docs/lvm/":{"data":{"":"","#":"LVM is a disk management tool, which is a device mapper for linux kernel,managing storage systems than the traditional partition based one.In LVM instead of creating partitions you create logical volumes, /boot cannot use logical volumes.\nLVM offers features like striping,mirroring,snapshotting.LVM functions by layering abstractions on top of physical storage devices.\nMain components of LVM are\nPhysical Volumes: physical block devices which are set a hard disks,physical volumes are regular storage devices,prefixed with pv.. Volume Groups: LVM combines physical volumes into storage pools known as volume groups,LVM abstracts the function there by making a unified logical devices with one ,prefixed with vg... Logical Volumes: a volume group is sliced into a number of logical volumes.Logical volumes are functionally equivalent to partitions on a physical disks,but with more advanced features. Basic LVM Commands Making Physical Devices as Physical Volumes. lvmdiskscan - returns the number of block devices to which LVM can interact. vinay@kevin ~\u003e sudo lvmdiskscan /dev/sda [ 57.30 GiB] /dev/nvme0n1p1 [ \u003c464.81 GiB] /dev/nvme0n1p5 [ 975.00 MiB] /dev/sdb [ \u003c28.87 GiB] 2 disks 2 partitions 0 LVM physical volume whole disks 0 LVM physical volumes Here we are creating a physical volume for the disks /dev/sda and /dev/sdb.\npvcreate - command that is used to initialize physical disks to physical volumes for LVM, this will write an LVM header to the devices to indicate that they are ready to be added to volume group. vinay@kevin ~\u003e sudo pvcreate /dev/sda /dev/sdb Physical volume \"/dev/sda\" successfully created. Physical volume \"/dev/sdb\" successfully created. pvs - displays information about physical volumes. vinay@kevin ~\u003e sudo pvs PV VG Fmt Attr PSize PFree /dev/sda lvm2 --- 57.30g 57.30g /dev/sdb lvm2 --- \u003c28.87g \u003c28.87g the disks /dev/sda and /dev/sdb is of the size 57G and 28G respectively,hence these can be added to the volume groups.\nAdd Physical Volumes to Volume Group. vgcreate - creates a volume group vinay@kevin ~\u003e sudo vgcreate VolGrpLvm /dev/sda /dev/sdb Volume group \"VolGrpLvm\" successfully created a volume group with the name, VolGrpLvm is created\nvgs - displays information about volume groups vinay@kevin ~\u003e sudo vgs VG #PV #LV #SN Attr VSize VFree VolGrpLvm 2 0 0 wz--n- 86.16g 86.16g Here the two phyical volumes are converted into a pool of storage,making a total of 86G, from this pool of storage,these are sliced to several logical volumes.\nCreating Logical Volumes from the Volume Group Pool. lvcreate - creating a logical volume from the volume group vinay@kevin ~\u003e sudo lvcreate -L 10G -n backup VolGrpLvm Logical volume \"backup\" created. vinay@kevin ~\u003e sudo lvs LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert backup VolGrpLvm -wi-a----- 10.00g lvcreate is used to create a logical volume from the volume group of storage pool, -L option is used to specify the size of the volume and -n option is used to label the logical volume.\nlvs displays information about the logical volume created.\nSimilarly create another logical volume.\nvinay@kevin ~\u003e sudo lvcreate -L 30G -n college-data VolGrpLvm Logical volume \"college-data\" created. vinay@kevin ~\u003e sudo lvs LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert backup VolGrpLvm -wi-a----- 10.00g college-data VolGrpLvm -wi-a----- 30.00g Format and Mount the logical volumes Formatting the logical volumes.\n$ sudo mkfs.ext4 /dev/VolGrpLvm/backup $ sudo mkfs.ext4 /dev/VolGrpLvm/college-data Mounting the logical volume\nvinay@kevin ~\u003e sudo mkdir -p /mnt/{backup,college-data} vinay@kevin ~\u003e sudo mount /dev/VolGrpLvm/backup /mnt/backup/ vinay@kevin ~\u003e sudo mount /dev/VolGrpLvm/college-data /mnt/college-data/ vinay@kevin ~\u003e lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTS sda 8:0 1 57.3G 0 disk ‚îú‚îÄVolGrpLvm-backup 254:0 0 10G 0 lvm /mnt/backup ‚îî‚îÄVolGrpLvm-college--data 254:1 0 30G 0 lvm /mnt/college-data sdb 8:16 1 28.9G 0 disk nvme0n1 259:0 0 465.8G 0 disk ‚îú‚îÄnvme0n1p1 259:1 0 464.8G 0 part / ‚îú‚îÄnvme0n1p2 259:2 0 1K 0 part ‚îî‚îÄnvme0n1p5 259:3 0 975M 0 part [SWAP] Creating mount points in /mnt and mount the volumes onto the mountpoints created.\nOther useful scan and display commands. vinay@kevin ~\u003e sudo pvscan PV /dev/sda VG VolGrpLvm lvm2 [57.30 GiB / 17.30 GiB free] PV /dev/sdb VG VolGrpLvm lvm2 [28.86 GiB / 28.86 GiB free] Total: 2 [86.16 GiB] / in use: 2 [86.16 GiB] / in no VG: 0 [0 ] vinay@kevin ~\u003e sudo lvscan ACTIVE '/dev/VolGrpLvm/backup' [10.00 GiB] inherit ACTIVE '/dev/VolGrpLvm/college-data' [30.00 GiB] inherit vinay@kevin ~\u003e sudo vgscan Found volume group \"VolGrpLvm\" using metadata type lvm2 vinay@kevin ~\u003e s^C vinay@kevin ~\u003e vinay@kevin ~\u003e sudo pvscan PV /dev/sda VG VolGrpLvm lvm2 [57.30 GiB / 17.30 GiB free] PV /dev/sdb VG VolGrpLvm lvm2 [28.86 GiB / 28.86 GiB free] Total: 2 [86.16 GiB] / in use: 2 [86.16 GiB] / in no VG: 0 [0 ] vinay@kevin ~\u003e sudo vgscan Found volume group \"VolGrpLvm\" using metadata type lvm2 vinay@kevin ~\u003e sudo lvscan ACTIVE '/dev/VolGrpLvm/backup' [10.00 GiB] inherit ACTIVE '/dev/VolGrpLvm/college-data' [30.00 GiB] inherit vinay@kevin ~\u003e sudo pvdisplay --- Physical volume --- PV Name /dev/sda VG Name VolGrpLvm PV Size 57.30 GiB / not usable 4.00 MiB Allocatable yes PE Size 4.00 MiB Total PE 14669 Free PE 4429 Allocated PE 10240 PV UUID obDX3S-49P0-0Y2o-Vpr1-zFxV-Tgng-Ov9oEz ‚Äî Physical volume ‚Äî PV Name /dev/sdb VG Name VolGrpLvm PV Size \u003c28.87 GiB / not usable 4.00 MiB Allocatable yes PE Size 4.00 MiB Total PE 7389 Free PE 7389 Allocated PE 0 PV UUID 7KAaVc-1H9V-FSsK-n98X-P9SM-IIAw-s9Myce\nvinay@kevin ~\u003e sudo vgdisplay ‚Äî Volume group ‚Äî VG Name VolGrpLvm System ID Format lvm2 Metadata Areas 2 Metadata Sequence No 3 VG Access read/write VG Status resizable MAX LV 0 Cur LV 2 Open LV 2 Max PV 0 Cur PV 2 Act PV 2 VG Size 86.16 GiB PE Size 4.00 MiB Total PE 22058 Alloc PE / Size 10240 / 40.00 GiB Free PE / Size 11818 / 46.16 GiB VG UUID P1dIv1-Lk34-Oxjo-ZZoE-81ys-3XnL-5WZotd\nvinay@kevin ~\u003e sudo lvdisplay ‚Äî Logical volume ‚Äî LV Path /dev/VolGrpLvm/backup LV Name backup VG Name VolGrpLvm LV UUID CjtnRq-evig-hsY4-avOM-6KVM-a7TT-VeAkDR LV Write Access read/write LV Creation host, time kevin, 2024-01-03 10:41:55 +0530 LV Status available\nopen 1LV Size 10.00 GiB Current LE 2560 Segments 1 Allocation inherit Read ahead sectors auto\ncurrently set to 256 Block device 254:0 ‚Äî Logical volume ‚Äî LV Path /dev/VolGrpLvm/college-data LV Name college-data VG Name VolGrpLvm LV UUID f2zixQ-ayec-zrXb-AV35-JaU0-9jz5-9ZrFtk LV Write Access read/write LV Creation host, time kevin, 2024-01-03 10:45:39 +0530 LV Status available\nopen 1LV Size 30.00 GiB Current LE 7680 Segments 1 Allocation inherit Read ahead sectors auto\ncurrently set to 256 Block device 254:1 \u003cbutton class=‚Äúcode-copy-btn group/copybtn transition-all active:opacity-50 bg-primary-700/5 border border-black/5 text-gray-600 hover:text-gray-900 rounded-md p-1.5 dark:bg-primary-300/10 dark:border-white/10 dark:text-gray-400 dark:hover:text-gray-50‚Äù title=‚ÄúCopy code‚Äù Rename a LV Renaming a logical volume using lvrename\nvinay@kevin ~\u003e sudo lvrename /dev/VolGrpLvm/college-data /dev/VolGrpLvm/college Renamed \"college-data\" to \"college\" in volume group \"VolGrpLvm\" vinay@kevin ~\u003e ls /dev/VolGrpLvm/ backup@ college@ Extending a LV To increase the size of the logical volume,we use lvextend command.\nvinay@kevin ~\u003e sudo lvs LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert backup VolGrpLvm -wi-ao---- 10.00g college VolGrpLvm -wi-ao---- 30.00g vinay@kevin ~\u003e sudo lvextend -L+5G /dev/VolGrpLvm/backup Size of logical volume VolGrpLvm/backup changed from 10.00 GiB (2560 extents) to 15.00 GiB (3840 extents). Logical volume VolGrpLvm/backup successfully resized. To increase the size of the volume by specified size use the + character to mention the increase in size.\nTo set the size of the volume see the below example.\nvinay@kevin ~\u003e sudo lvextend -L25G /dev/VolGrpLvm/backup Size of logical volume VolGrpLvm/backup changed from 15.00 GiB (3840 extents) to 25.00 GiB (6400 extents). Logical volume VolGrpLvm/backup successfully resized. vinay@kevin ~\u003e sudo lvs LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert backup VolGrpLvm -wi-ao---- 25.00g college VolGrpLvm -wi-ao---- 30.00g Shrink a LV Can reduce the size of the volume using lvreduce command.\nvinay@kevin ~\u003e sudo lvs LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert backup VolGrpLvm -wi-ao---- 25.00g college VolGrpLvm -wi-ao---- 30.00g vinay@kevin ~\u003e sudo lvreduce -L20G /dev/VolGrpLvm/backup WARNING: Reducing active and open logical volume to 20.00 GiB. THIS MAY DESTROY YOUR DATA (filesystem etc.) Do you really want to reduce VolGrpLvm/backup? [y/n]: y Size of logical volume VolGrpLvm/backup changed from 25.00 GiB (6400 extents) to 20.00 GiB (5120 extents). Logical volume VolGrpLvm/backup successfully resized. vinay@kevin ~\u003e sudo lvs LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert backup VolGrpLvm -wi-ao---- 20.00g college VolGrpLvm -wi-ao---- 30.00g Here,the size of the volume is reduced to 20G.\nRemove an LV Before removing an LV,umount it first and then use the lvremove to remove the volume group.\nvinay@kevin ~\u003e sudo lvremove /dev/VolGrpLvm/backup Do you really want to remove active logical volume VolGrpLvm/backup? [y/n]: y Logical volume \"backup\" successfully removed. Increase Pool storage To increase the size of the volume group we use the command vgextend to increase the size of the storage pool.\nInitially the size of the volume storage pool was 86G and now it is increased to 115G /dev/sdc is the new phyical volume.\nvinay@kevin ~\u003e sudo pvcreate /dev/sdc Physical volume \"/dev/sdc\" successfully created. vinay@kevin ~\u003e sudo vgs VG #PV #LV #SN Attr VSize VFree VolGrpLvm 2 1 0 wz--n- 86.16g 56.16g vinay@kevin ~\u003e sudo vgextend VolGrpLvm /dev/sdc Volume group \"VolGrpLvm\" successfully extended vinay@kevin ~\u003e sudo vgs VG #PV #LV #SN Attr VSize VFree VolGrpLvm 3 1 0 wz--n- \u003c115.03g \u003c85.03g Striping RAID 0: Striping RAID 0,also known as striped set or striped volume,requires a minimum of two disks, the disks are merged into one single large volume and data is stored evenly the disks.This process is called disk striping and involves splitting data into blocks and writing it simultaneously/sequentially on multiple disks. It doesn‚Äôt support redundancy,fault tolerance and hence data loss.\nData is stored sequentially\nvinay@kevin ~\u003e sudo lvcreate -L 10G -i2 -I64 -n backup1 VolGrpLvm [sudo] password for vinay: WARNING: ext4 signature detected on /dev/VolGrpLvm/backup1 at offset 1080. Wipe it? [y/n]: y Wiping ext4 signature on /dev/VolGrpLvm/backup1. Logical volume \"backup1\" created. Creating a logical volume with the size 10G, the -i argument is used to mention striping and the number next to the option specifies the striping in how many disks, the -I option in the above command is to specify the size of block of 64kB across two physical volumes.\nIf the striping number across the disks is more than the physical volumes,it fails to create a logical volume,with an exeception saying number of stripes exceeds number of physical volumes.\nvinay@kevin ~\u003e sudo lvcreate -L 5G -i4 -I64 -n backup3 VolGrpLvm Number of stripes (4) must not exceed number of physical volumes (3) In this setup only 3 physical volumes are used,which exceeds the stripe number.\nMirroring RAID 1: Disk Mirroring Keeping a copy of the data within the logical volume is called mirroring,for redundancy and to avoid data loss.\nthe -m option with value 1 creates one copy of the data,therefore having a total of two copies of data within the file system,-m2 creates two mirrors,yielding three copies of the file system.\nvinay@kevin ~\u003e sudo lvcreate -L 5G -m1 -n mirrorLV VolGrpLvm Logical volume \"mirrorLV\" created. Thin Volumes Usually LVM normally allocates blocks when you create a volume,thats thick provisioning.LVM thin pools instead allocates blocks when they are written,this is called thin provisioning. Because volumes can be much larger than physically available space.\nTo remove a physical volume from the existing volume group,use vgreduce vinay@kevin ~ [5]\u003e sudo vgreduce VolGrpLvm /dev/sdc Removed \"/dev/sdc\" from volume group \"VolGrpLvm\" Create new physical volumes using physical disks and create a volume group.\nvinay@kevin ~\u003e sudo pvcreate /dev/sdc /dev/sdd Physical volume \"/dev/sdc\" successfully created. Physical volume \"/dev/sdd\" successfully created. vinay@kevin ~\u003e sudo vgcreate vg_thin /dev/sdc /dev/sdd Volume group \"vg_thin\" successfully created Create a thinpool with the size 5G with chunksize 256K where ```vg_thin`` is the volume group name and creating a pool again within the volume group\nvinay@kevin ~\u003e sudo lvcreate --thin --size 5G --chunksize 256K --poolmetadatasize 1G vg_thin/thin_pool Thin pool volume with chunk size 256.00 KiB can address at most 63.50 TiB of data. Logical volume \"thin_pool\" created. Listing all the logical volumes which displays all the logical volumes\nvinay@kevin ~\u003e sudo lvs -a LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert [lvol0_pmspare] vg_thin ewi------- 1.00g thin_pool vg_thin twi-a-tz-- 5.00g 0.00 1.57 [thin_pool_tdata] vg_thin Twi-ao---- 5.00g [thin_pool_tmeta] vg_thin ewi-ao---- 1.00g Creating 3 logical volumes,while for the second logical volujme volume_2 there is a warning which mentions exceeds the size of thin pool,even though the pool size is 5G,after the creation of the first logical volume volume_1 2G should be remained,since it is thin provisioning, only when data is written blocks are allocated to it,so hence just a warning. Similarly the error comes during the creation of volume_3.\nvinay@kevin ~\u003e sudo lvcreate --thinpool vg_thin/thin_pool --name volume_1 --virtualsize 3G Logical volume \"volume_1\" created. vinay@kevin ~\u003e sudo lvcreate --thinpool vg_thin/thin_pool --name volume_2 --virtualsize 3G WARNING: Sum of all thin volume sizes (6.00 GiB) exceeds the size of thin pool vg_thin/thin_pool (5.00 GiB). WARNING: You have not turned on protection against thin pools running out of space. WARNING: Set activation/thin_pool_autoextend_threshold below 100 to trigger automatic extension of thin pools before they get full. Logical volume \"volume_2\" created. vinay@kevin ~\u003e sudo lvcreate --thinpool vg_thin/thin_pool --name volume_3 --virtualsize 3G WARNING: Sum of all thin volume sizes (9.00 GiB) exceeds the size of thin pool vg_thin/thin_pool (5.00 GiB). WARNING: You have not turned on protection against thin pools running out of space. WARNING: Set activation/thin_pool_autoextend_threshold below 100 to trigger automatic extension of thin pools before they get full. Logical volume \"volume_3\" created. All the logical volumes can be verfied now.\nvinay@kevin ~\u003e sudo lvs -a LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert [lvol0_pmspare] vg_thin ewi------- 1.00g thin_pool vg_thin twi-aotz-- 5.00g 0.00 1.57 [thin_pool_tdata] vg_thin Twi-ao---- 5.00g [thin_pool_tmeta] vg_thin ewi-ao---- 1.00g volume_1 vg_thin Vwi-a-tz-- 3.00g thin_pool 0.00 volume_2 vg_thin Vwi-a-tz-- 3.00g thin_pool 0.00 volume_3 vg_thin Vwi-a-tz-- 3.00g thin_pool 0.00 ","open-----------------1#open                 1":"","open-----------------1-1#open                 1":""},"title":"Logical Volume Manager"},"/docs/nfs/":{"data":{"":"","#":"NFS stands for Network FIle System, is a file system protocol that allows to access files and folders on a remote system,and accessing them like a local storage.The architecture of NFS is client-server architecture,where the files are folders to be accessed are stored on the servers and these file \u0026 folders are accessed by the client machine like a mounted partition.\nWith NFS,its easy to access file,enable special permissions like either read only or read and write,syncing the files and folders across the available clients.\nInstall NFS Server I‚Äôm currently on Debian Bookworm, to install the nfs server package just do sudo apt install nfs-kernel-server\n$ cat /etc/issue Debian GNU/Linux 12 \\n \\l $ sudo apt policy nfs-kernel-server nfs-kernel-server: Installed: 1:2.6.2-4 Candidate: 1:2.6.2-4 Version table: *** 1:2.6.2-4 500 500 mirror+file:/etc/apt/mirrors/debian.list bookworm/main amd64 Packages 100 /var/lib/dpkg/status Create a export folder/directory where files and folders are accessed by the clients present on the server, here i have choosed the location /mnt/sharedfolder\n$ sudo mkdir -p /mnt/sharedfolder change the permissions of the folder to 777\nsudo chmod 777 /mnt/sharedfolder\nIt will allow the clients to access the shared folder.\nConfigure Export Directory The configuration file for the NFS server is located at /etc/exports,here can specify directories that are to be shared to clients\n/mnt/sharedfolder 10.22.13.0/24(rw,sync,no_subtree_check) add the above line to /etc/exports, in the form ```directory hostname(options)\nHere /mnt/sharedfolder is the remote folder, 10.22.13.0/24 is the subnet IP where the folder can be accessed across the whole subnet network,this can also be filtered to access from specifc client IP too, and example would be\n/mnt/sharedfolder 10.22.13.101(rw,sync,no_subtree_check) where 10.22.13.101 is the client IP, to which only this IP can access the shared folder,no other IP can access.\nThere are plenty of options to configure the NFS server: ro : directory mounted as read only. rw : directory mounted with read and write permissions. subtree_check ‚Äì specifies that, in the case of a directory is exported instead of an entire filesystem, the host should verify the location of files and directories on the host filesystem no_subtree_check ‚Äì specifies that the host should not check the location of the files being accessed within the host filesystem sync ‚Äì this just ensures that the host keeps any changes uploaded to the shared directory in sync async ‚Äì ignores synchronization checks in favor of increased speed Exporting the shared directory\nAfter the /etc/exports nfs server is configured,to export the shared directory run the below command and restart nfs-kernel-server\n$ sudo exportfs -a $ sudo systemctl restart nfs-kernel-server Configure the firewall so that the server is open for clients to access the shared content.\n$ sudo ufw allow from 10.22.13.0/24 to any port nfs and again check ufw status\n$ sudo ufw status Status: active To Action From -- ------ ---- 22/tcp ALLOW Anywhere 2049 ALLOW 10.22.13.0/24 22/tcp (v6) ALLOW Anywhere (v6) Configuring Client Once the server and firewall is setup,next thing is to configure the client\nTo configure the client on Debian install the package nfs-common\n$ sudo apt install nfs-common Create a mount point on the client machine for the NFS server‚Äôs shared folder\nOn client machine$ sudo mkdir -p /mnt/sharedfolder_client Next step is to mount the remote folder on the client,this can be done in two ways,with the mount command or adding the entry to /etc/fstab\nUsing the mount command On client$ sudo mount 10.22.13.53:/mnt/sharedfolder /mnt/sharedfolder_client where 10.22.13.53 is the local ip of the NFS server,basically mounting /mnt/sharedfolder of the client to /mnt/sharedfolder_client.\nUsing the /etc/fstab way $ cat /etc/fstab # /etc/fstab: static file system information UUID=8f994d1d-8ae8-4dff-aaa5-9aef4574329b / ext4 rw,discard,errors=remount-ro,x-systemd.growfs 0 1 UUID=5F3D-98F1 /boot/efi vfat defaults 0 0 10.22.13.53:/mnt/sharedfolder /mnt/sharedfolder_client nfs4 defaults,user,exec 0 0 where /mnt/sharedfolder_client is the mountpoint on the client,editing any file from the client update‚Äôs it on the server,because we have configured to sync across all the mount points,editing any file from the client will update it on the NFS server too."},"title":"NFS-Network File System"},"/docs/powerdns/":{"data":{"":"https://www.cloudflare.com/learning/dns/what-is-dns/\ndig +trace amogha.labnetwork.in ; \u003c\u003c\u003e\u003e DiG 9.18.19-1~deb12u1-Debian \u003c\u003c\u003e\u003e +trace amogha.labnetwork.in ;; global options: +cmd .\t600\tIN\tNS\tb.root-servers.net. .\t600\tIN\tNS\tm.root-servers.net. .\t600\tIN\tNS\tf.root-servers.net. .\t600\tIN\tNS\ti.root-servers.net. .\t600\tIN\tNS\tl.root-servers.net. .\t600\tIN\tNS\td.root-servers.net. .\t600\tIN\tNS\ta.root-servers.net. .\t600\tIN\tNS\tg.root-servers.net. .\t600\tIN\tNS\te.root-servers.net. .\t600\tIN\tNS\th.root-servers.net. .\t600\tIN\tNS\tc.root-servers.net. .\t600\tIN\tNS\tj.root-servers.net. .\t600\tIN\tNS\tk.root-servers.net. .\t600\tIN\tRRSIG\tNS 8 0 518400 20240130050000 20240117040000 30903 . 3UGfMmYAGBezyUTAir+TH1swje4FUz2dT6OkIbTzpcOHx/AUjndw/SKz y8BCTgaIltIwF0I6SOQYNe4vi22rVsfGGcVO+qTnTERKIUFS7VHP3cNw sCoXHvVASZMuhO2CLofz0YqnrEdmSG9jM2V/HYWEvTzmbPRZC2C+nz8a 8MuW666wyPH1Uum5iUPoz2Fouwfk0cT42mJ1X3I0exXazFkGeJGB7Sfv zP6irEH7WURZcLoDP3rY9DpIGCSsaKTy6bGvf8Muns4lPWSvFw92pFBr XrsKBCSNhr7wrBTOg1UM14P/c4ggUYLP35V4mp/K5RlKOfh3pd8+uoc2 B/nSww== ;; Received 1097 bytes from 127.0.0.1#53(127.0.0.1) in 0 ms in.\t172800\tIN\tNS\tns1.registry.in. in.\t172800\tIN\tNS\tns2.registry.in. in.\t172800\tIN\tNS\tns3.registry.in. in.\t172800\tIN\tNS\tns4.registry.in. in.\t172800\tIN\tNS\tns5.registry.in. in.\t172800\tIN\tNS\tns6.registry.in. in.\t86400\tIN\tDS\t25291 8 2 2945B61339DFA7221AD82D5C6C7E3CE4E9C2523E7754ACC8131D0EF9 4617E2F2 in.\t86400\tIN\tRRSIG\tDS 8 1 86400 20240131050000 20240118040000 30903 . IFHCnVVRWAsLFEfioh6tQ377W9j6X0wMnhLYOf/jpwV165bfE3Eds37N vc2xebHces+WtwfNvMsczo6+qoLMEEQENNc3P5GHF0Tu0VwQ6KIKvbze I0NALAlv+J/r0FSAhNy1PoeR1vS8DLobaAjNCCy3qYGkpyKwlxqgusPC IU8BFCZaeEtz4XBeYNYn9lchY540xCGd7ZEcdI3S/OrTLblZQosJfc4l NyoYngvntdaDDdcuoRf3Usamrk3SUS3QUoOt/Qx3Z1LifU7QKbnnkjgW nGMFRgCqFnWCXjUotoPeQbNjthBL5E5SmWEvvYsNc2DMyUnqp9r/OX+h +zudAA== ;; Received 765 bytes from 199.7.91.13#53(d.root-servers.net) in 248 ms labnetwork.in.\t3600\tIN\tNS\tns6.tinydns.in. labnetwork.in.\t3600\tIN\tNS\tns5.tinydns.in. u7smslveus494o8dr4h483un5spuc1tu.in. 900 IN NSEC3 1 1 0 - U7UB8S485RVUNK2H8F23BU6LRI1GJL00 NS SOA RRSIG DNSKEY NSEC3PARAM CDS CDNSKEY TYPE65534 u7smslveus494o8dr4h483un5spuc1tu.in. 900 IN RRSIG NSEC3 8 2 900 20240130195500 20240116192722 27000 in. wdxZl/4X8UG7iX4fMqIfYCPP8G9flaM7zgUCwrwlkqb7mtzyc7Vzvvyw IGqZgSrOz5VNtOxZd2u0+L+bGzbBhdLcUxPBzcKuIqs6pk1+etkyBIp5 IZbe35F6mkmO2pKrba1YPmLL7H7MYsudvuUcrbWWRg8MGb8sVFzJm49H eQvvK+3LXHV2SSv0ypLx1kKJuFwMQ+6MX02gEV7Uzdi74g== e4tmotrmfrj6v3sii9g2rgv9j3r7i7sq.in. 900 IN NSEC3 1 1 0 - E4U5LD2VI0EOIE3ATE1MFHP5POUKAG26 NS DS RRSIG e4tmotrmfrj6v3sii9g2rgv9j3r7i7sq.in. 900 IN RRSIG NSEC3 8 2 900 20240131185933 20240117185317 27000 in. haKYuAtWZP8zV+xf55vjJbWlIl/ZRVENv720IhDlPSLlPR1E6w0LDiqk E2yo/wKiIbHhmhL0I9cPpGXgBq7Ki8SmhBaU9nYqA2+y+s/u2AlcUF9I AAl2VZDtmLq7ty3dMrrJ2sSygx4SWWnH6hqRi+L8DqzbuwKRXE5PfgAF FI1dzezRn2kq9tJ+WILjtCAKPcccI8wAgHQlZXPUVOQklg== ;; Received 707 bytes from 156.154.101.20#53(ns6.registry.in) in 24 ms amogha.labnetwork.in.\t3600\tIN\tA\t122.166.50.175 ;; Received 65 bytes from 205.147.109.33#53(ns5.tinydns.in) in 40 ms powerdns and systemd resolved both uses port 53 to resolve dns queries. root@powerdns:/etc/powerdns# netstat -tnpl Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:5355 0.0.0.0:* LISTEN 282/systemd-resolve tcp 0 0 127.0.0.53:53 0.0.0.0:* LISTEN 282/systemd-resolve tcp 0 0 10.22.13.150:8082 0.0.0.0:* LISTEN 1633/pdns_recursor tcp 0 0 127.0.0.54:53 0.0.0.0:* LISTEN 282/systemd-resolve tcp 0 0 0.0.0.0:25 0.0.0.0:* LISTEN 698/master tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 419/sshd: /usr/sbin tcp 0 0 127.0.0.1:53 0.0.0.0:* LISTEN 1633/pdns_recursor tcp6 0 0 :::5355 :::* LISTEN 282/systemd-resolve tcp6 0 0 :::25 :::* LISTEN 698/master tcp6 0 0 :::22 :::* LISTEN 419/sshd: /usr/sbin root@powerdns:/etc/powerdns# systemctl stop systemd-resolved root@powerdns:/etc/powerdns# netstat -tnpl Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 10.22.13.150:8082 0.0.0.0:* LISTEN 1633/pdns_recursor tcp 0 0 0.0.0.0:25 0.0.0.0:* LISTEN 698/master tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 419/sshd: /usr/sbin tcp 0 0 127.0.0.1:53 0.0.0.0:* LISTEN 1633/pdns_recursor tcp6 0 0 :::25 :::* LISTEN 698/master tcp6 0 0 :::22 :::* LISTEN 419/sshd: /usr/sbin root@powerdns:/etc/powerdns# ss -anp | grep 53\nhttps://www.howtogeek.com/are-smart-plugs-and-power-points-the-best-smart-home-upgrade/ What the Hell is loopback address like 127.0.0.1"},"title":"PowerDNS"},"/docs/python/":{"data":{"":"##Python Learning","references#References":" learnpython.org "},"title":"Python"},"/docs/python/introduction/":{"data":{"":"","#":"Text Multi line print statement print(\"\"\" Hello World this is amazing \"\"\") Escape Sequences \u003e\u003e\u003e print('hello\\'world') \u003e\u003e\u003e print('hello\\nworld') Strings Strings are indexed,just like array indexing,here string‚Äôs characters can be accessed over index \u003e\u003e\u003e name=\"vinay\" \u003e\u003e\u003e name[0] #get the character at 0 'v' \u003e\u003e\u003e name[0:4] # get characters from 0th index to 4th index of the string 'vina' \u003e\u003e\u003e name[0:8] # total number of characers is 5 it prints every character 'vinay' \u003e\u003e\u003e name[-1] # python gives the flexibility to access string characters in reverse indexing way. 'y' \u003e\u003e\u003e name[-1:0] '' \u003e\u003e\u003e name[:-1] # can specify a range [:-1] in this range, it prints till the last element,but not the last element 'vina' \u003e\u003e\u003e name[:] 'vinay' \u003e\u003e\u003e name[-6:] 'vinay' Python strings are immutable and therefore cannot change the characters neither can assign new value to particular index.\n\u003e\u003e\u003e name[3]='v' Traceback (most recent call last): File \"\u003cstdin\u003e\", line 1, in \u003cmodule\u003e TypeError: 'str' object does not support item assignment len() returns the total length of the string.\nVariables and Types myint=7 print(myint) myfloat=7.0 myfloat2=float(myint) print(myfloat,myfloat2) #strings name=\"Vinay Keshava\" name1='kevin' print(name,name1) # Regarding strings it is that double quotes makes it easy to add apostrophe in given strings. #Assignments can be done on more than one variable \"simultaneously\" on the same line like this #variable assignment,below is the example for swapping of two variables. a,b=20,30 print(a,b) b,a = a,b print(a,b) Lists Lists is a compound data types,where values are separted by commas,here values can be of different types. Unlike strings which are immutable,lists are mutable type,where it is possible to change value of a particular location.\n\u003e\u003e\u003e marks = [90,92,100,4,87] \u003e\u003e\u003e marks [90, 92, 100, 4, 87] \u003e\u003e\u003e marks [0] 90 \u003e\u003e\u003e marks [-1] 87 \u003e\u003e\u003e marks [:} File \"\u003cstdin\u003e\", line 1 marks [:} ^ SyntaxError: closing parenthesis '}' does not match opening parenthesis '[' \u003e\u003e\u003e marks [:] [90, 92, 100, 4, 87] \u003e\u003e\u003e marks[-1:] [87] \u003e\u003e\u003e marks + [10,20,30] #concatenation [90, 92, 100, 4, 87, 10, 20, 30] \u003e\u003e\u003e marks [90, 92, 100, 4, 87] \u003e\u003e\u003e marks[3]= 76 \u003e\u003e\u003e marks [90, 92, 100, 76, 87] \u003e\u003e\u003e marks.append(40) \u003e\u003e\u003e marks [90, 92, 100, 76, 87, 40] ‚Äìslicing‚Äì\n\u003e\u003e\u003e letters = ['a','b','c','d','e','f'] \u003e\u003e\u003e letters ['a', 'b', 'c', 'd', 'e', 'f'] \u003e\u003e\u003e #replace some values \u003e\u003e\u003e letters[1:4]=['B','C','D'] \u003e\u003e\u003e letters ['a', 'B', 'C', 'D', 'e', 'f'] \u003e\u003e\u003e #can also remove the same values during slicing \u003e\u003e\u003e letters[1:4]=[] \u003e\u003e\u003e letters ['a', 'e', 'f'] \u003e\u003e\u003e len(letters) 3 \u003e\u003e\u003e #it is possible to nest lists \u003e\u003e\u003e letters ['a', 'e', 'f'] \u003e\u003e\u003e marks [90, 92, 100, 76, 87, 40] \u003e\u003e\u003e letters = [letters,marks] \u003e\u003e\u003e letters [['a', 'e', 'f'], [90, 92, 100, 76, 87, 40]] \u003e\u003e\u003e letters[0][2] 'f' \u003e\u003e\u003e "},"title":"Python Basics"},"/docs/ruby/":{"data":{"":"Ruby Learning\nReferences\nBig Binary The Odin Project"},"title":"Ruby"},"/docs/ruby/introduction/":{"data":{"":"","#":"Data Types A literal is any notation that lets you represent a fixed value in source code. For instance, all of the following are literals in Ruby: Data types like strings,integer literals, array literals,hash literals,symbol literal and nil.\n'Hello, world!' # string literal 375 # integer literal 3.141528 # float literal true # boolean literal { 'a' =\u003e 1, 'b' =\u003e 2 } # hash literal [ 1, 2, 3 ] # array literal :sym # symbol literal nil # nil literal nil means nothing in ruby\nType Conversion Type conversion means converting from one data type to another is called type conversion,here 13 which is a integer is being converted into a float using to_f which converts the integer ot 13.0,similarly for the string,converting 13 to string using to_s.\nirb(main):001:0\u003e 13.to_f =\u003e 13.0 irb(main):002:0\u003e 13.to_f =\u003e 13.0 irb(main):003:0\u003e 13.to_s =\u003e \"13\" irb(main):004:0\u003e String Interpolation Often in input output statements,string interpolation is used for variable placeholders within the puts statements.\nirb(main):013:0\u003e #String interpolation =\u003e nil irb(main):014:0\u003e name= \"vinay\" =\u003e \"vinay\" irb(main):015:0\u003e puts \"hello, #{name}\" hello, vinay =\u003e nil In the above example the variable name is used in the puts statement.\nStrings Strings are group of characters,there are lot of inbuilt function for string operations few of them are, .capitalize capitalizes the first alphabet of the string,empty? returns a boolean whether the string is empty or not,length returns the length of the string,split function splits the characters in the string based on the separator.\nirb(main):016:0\u003e \"Vinay\".capitalize =\u003e \"Vinay\" irb(main):017:0\u003e \"vinay\".capitalize =\u003e \"Vinay\" irb(main):018:0\u003e \"hello\".empty? =\u003e false irb(main):019:0\u003e \"vinay\".length =\u003e 5 irb(main):020:0\u003e \"hello world\".split =\u003e [\"hello\", \"world\"] irb(main):021:0\u003e \"hello world\".split(\"\") =\u003e [\"h\", \"e\", \"l\", \"l\", \"o\", \" \", \"w\", \"o\", \"r\", \"l\", \"d\"] Basic Data Structures Arrays and Hashes. Array Literals and Hash literals are important data structures,to handle large continous data. Array is a collection of data of the same type,that are accessed by index,whereas Hash are stored in a key:value pair,where the value is accessed by mentioning the key.\nirb(main):022:0\u003e #Basic data strctures arrays and hashes =\u003e nil irb(main):023:0\u003e [1,4,5,67,8] =\u003e [1, 4, 5, 67, 8] irb(main):024:0\u003e #hashes =\u003e nil irb(main):025:0\u003e {:dog =\u003e \"barks\"} =\u003e {:dog=\u003e\"barks\"} irb(main):026:0\u003e Symbols Symbol is a text that begins with a colon(:symbol) while strings are enclosed within the double quotes.Strings are mutable objects,while symbols are immutable objects,since strings are mutable and their value can be changed,it can cause bugs, there at that time where object‚Äôs value shouldn‚Äôt be changed,at that time symbols can be used.\nirb(main):021:0\u003e \"a string\".object_id =\u003e 237820 irb(main):022:0\u003e \"a string\".object_id =\u003e 239900 irb(main):023:0\u003e \"a string\".object_id =\u003e 241980 irb(main):024:0\u003e :a_symbol.object_id =\u003e 2332828 irb(main):025:0\u003e :a_symbol.object_id =\u003e 2332828 irb(main):026:0\u003e :a_symbol.object_id =\u003e 2332828 For every new string created there is a different object_id created,making it different objects,where as in symbols,it points to the same object id.A\nVariables Variable names are reusable,you can assign a new value to a variable at any point.To name variables in ruby follow snake_case and not CamelCase\nage=20 Variables as references,variable is effectively a reference or a pointer to that address in memory.\ndesired_location= \"Bengaluru\" referenced_location= desired_location reference_location.upcase! here since the referenced_location is a pointer to desired_location changing the referenced_location will also reflect on the actual variable.\ngets and chomp irb(main):034:0\u003e name = gets Bob =\u003e \"Bob\\n\" irb(main):035:0\u003e name = gets.chomp Bob =\u003e \"Bob\" irb(main):036:0\u003e \"hello \"+ name =\u003e \"hello Bob\" irb(main):037:0\u003e Variable Scope variable‚Äôs scope determines where in a program the particular variable is accessible,\nname=\"Vinay Keshava\" def print_full_name(first_name,last_name) name = first_name+ ' ' + last_name puts name end print_full_name 'Mahesh', 'Kumar' print_full_name 'Suresh', 'Kumar' puts name Output of the above program.\n$ ruby variable_examples.rb Mahesh Kumar Suresh Kumar Vinay Keshava Variable blocks total=0 [1,2,4].each { |number| total += number} puts total a=5 3.times do |n| a=3 end puts a Types of Variable\nConstants Global Variablesruby Class Variables Instance Variables Local Variables Constants\nCapitalizing every letter in variable‚Äôs name.Constants are used for storing data that never needs to change.\nMY_CONSTANT = 'I am available throughout your app.' Global Variables Accessible throughout the entire app,overriding all scope boundaries. $var = 'I am also available throughout your app.' Class Variables Class Variables are declared by starting the variable name with two @ signs,these variables are accessible by instances of the class and by the class itself.\n@@instances = 0 Instance Variables Instances variables are declared by starting the variable with one @ sign,these variables are available throughout the current instance of the parent class. @var = \"I'm available throughout the current instance of this class\" Local Variable Most common variables you will come across and obey all scope boundary rules.\nvar = 'Hello world' Input \u0026 Output gets:returns the user input,difference bw puts \u0026 print is puts appends a new line at the end of the string while print does not.\nirb(main):001:0\u003e puts \"hello world\" hello world =\u003e nil irb(main):002:0\u003e print \"hello world\" hello world=\u003e nil irb(main):003:0\u003e gets hello world =\u003e \"hello world\\n\" irb(main):004:0\u003e gets.chomp hello world =\u003e \"hello world\" irb(main):005:0\u003e name =gets.chomp hell world =\u003e \"hell world\" irb(main):006:0\u003e name =\u003e \"hell world\" since gets appends an new line escape character at the end of the line,to avoid this we use chomp.\nConditional Logic Conditional statements,similar to in other programming languages,case statements just like switch checks for condition against a set of values defined,where in the example below,is demonstrated using the grade variable with the help of case and when keywords.\nif true==false print \"This is not printing\" elsif true== true print \"True is true hence false is false\\n\" end if 1\u003c2 \u0026\u0026 5\u003c6 print \"This is printing because 1 is smaller than 2\\n\" end #case statements grade = 'F' pass_fail = case grade when 'A' then \"Hell yeah distinction\" when 'B' then \"Ahh first class yes yes\" else \"You shall not pass in life\" end puts pass_fail percentage = 50.00 pass_fail_percentage = case percentage when 70.00 puts \"Above 70.00 you dumbshit\" total=percentage*100 when 80.00 puts \"80.00 ahh yes yes\" total=percentage*100 else puts \"You shall not pass go graze donkeysss man\" end # unless statements - unless statement works in the opposite way to if statement,it only processes the code if it evaluates to false,unless can be added with else too. age = 19 unless age \u003c18 puts \"get a job\" else puts \" Careful now\" end # Ternary Operator response = age \u003c 18? \"You still have time to become 19\": \"You're a grown up kid\" puts response unless statement works in the opposite way of if statement,it processes the block of code only if it evaluates to false.\nLoops Loops are used to repeat a set of statements.Types of loops are loop,for,while. until loop opposite to while loop,which evaluates as long as the condition is false not like while loop which only evaluates when the expression evaluate to true.\ni=0 #this type of ruby's loop is infinite until you stop it. loop do puts \"i is #{i}\" i+=1 break if i==10 end #while loop i=0 puts \"while loop\" while i\u003c10 do puts \"i is #{i}\" i+=1 end #using while loop with gets while gets.chomp !=\"yes\" do puts \"Are we there yet?\" end #until loop i=0 until i\u003e=10 do puts \"i is #{i}\" i +=1 end # forloops for i in 0..5 puts \"#{i} zombie coming\" end #times loop 5.times do puts \"hello world\" end #upto and downto loops 5.upto(10) { |num| print \"#{num}\" } puts \" \" 10.downto(5) { |num| print \"#{num}\" } #iterators names = [\"vinay\",\"keshava\",\"hello\",\"world\"] names.each { |name| puts name } Block is some lines of code that is ready to be executed,when working with blocks they are two styles,single line and multi line. In single line block we use {} curly braces,while in multi line style we use the do and end keywords.\n##block names = [\"vinay\",\"keshava\",\"hello\",\"world\"] names.each { |name| puts name } names.each do |name| puts \"#{name}\" end Arrays Arrays are a collection of data of the same type,that are referenced by an index.Array.new is another way to create an array apart from the traditional way of creating it. Array elements are accessed by an index. some of the important methods used in arrays are first, which returns the value at the first index,and last function returns the value at the last index.\nnum_array=[1,3,4,5,76] str_array = [\"vinay\",\"hello\",\"world\",\"keshava\"] #Creating an array using .new Array.new Array.new(3) #creates a new array with size 3 a1 = Array.new(4,7) #creates a new array with size 3,with all the values in these indexes is \"7\" puts a1 Array.new(4,true) #first and last array methods - to access the first and last value of the array. puts str_array.first puts str_array.last puts str_array.first(3) # adding a element to the array. num_array=[1,2] print num_array puts \"\" num_array.push(3,4) print num_array puts \"\" num_array \u003c\u003c 5 # shovel operator which adds 5 to the array. print num_array # deleting an element from the array. num_array.pop # delete 5 puts num_array Shift/Unshift and Push/Pop\n.unshift and .push is used to add an element to an array, while `.unshift‚Äô adds element to beginning of the array,while ‚Äò.push‚Äô adds the element to the end.\n.shift and .pop is used to remove an element from the array,and the removed element is returned,.shiftremoves an element from the beginning while, .pop removes the element from the end.\n#shift unshift and push and pop =\u003e [1, 1, 3, 4, 5] irb(main):005:0\u003e num_array =\u003e [1, 1, 3, 4, 5] irb(main):006:0\u003e num_array.shift =\u003e 1 irb(main):007:0\u003e num_array =\u003e [1, 3, 4, 5] irb(main):008:0\u003e num_array.push(10) =\u003e [1, 3, 4, 5, 10] irb(main):010:0\u003e num_array.unshift =\u003e [1, 3, 4, 5, 10] irb(main):011:0\u003e num_array.unshift(1) =\u003e [1, 1, 3, 4, 5, 10] irb(main):012:0\u003e num_array.shift =\u003e 1 irb(main):013:0\u003e num_array =\u003e [1, 3, 4, 5, 10] irb(main):014:0\u003e num_array.shift =\u003e 1 irb(main):015:0\u003e num_array =\u003e [3, 4, 5, 10] irb(main):016:0\u003e num_array.shift =\u003e 3 irb(main):017:0\u003e num_array =\u003e [4, 5, 10] irb(main):018:0\u003e Basic array methods\nnum_array.methods in the irb will display all the array methods available.\nHashes One of the drawback of Array‚Äôs is,it holds data of the same type and the way of accessing the elements in the array is time consuming due to indexing of elements from 0. Hash is like a key:value pair,where to access the value,we use the key which can be of different data types,can be string,array,integer etc.\nAnother style of creating an hash similar to array using .new like Hash.new.\nTo access the values in the hash we use the fetch option along with key.\nStings are not prefferred to use as keys in the hash due to their mutable nature,hence symbols are used due to their immutable nature.\nirb(main):004:0\u003e hash_with_different_types = { \"name\"=\u003e \"vinay\", \"degrees\"=\u003e[\"MBA\",\"MTECH\",\"MS\"],12=\u003e\"twelve\" } =\u003e {\"name\"=\u003e\"vinay\", \"degrees\"=\u003e[\"MBA\", \"MTECH\", \"MS\"], 12=\u003e\"twelve\"} irb(main):005:0\u003e #creating a hash with Hash.new =\u003e nil irb(main):006:0\u003e new_hash=Hash.new =\u003e {} irb(main):007:0\u003e new_hash[10=\u003e\"ten\"] =\u003e nil irb(main):008:0\u003e new_hash =\u003e {} irb(main):009:0\u003e new_hash={10=\u003e\"ten\"} =\u003e {10=\u003e\"ten\"} irb(main):010:0\u003e #accessing hash values =\u003e nil irb(main):011:0\u003e new_hash[10] =\u003e \"ten\" irb(main):012:0\u003e new_hash.fetch(10) =\u003e \"ten\" irb(main):013:0\u003e #adding and changing data =\u003e nil irb(main):014:0\u003e my_hash_example[8]=\"eighttttee\" =\u003e \"eighttttee\" irb(main):015:0\u003e my_hash_example =\u003e {10=\u003e\"ten\", 8=\u003e\"eighttttee\", 7=\u003e\"seven\"} irb(main):016:0\u003e my_hash_example[9]=\"ninie\" =\u003e \"ninie\" irb(main):017:0\u003e my_hash_example =\u003e {10=\u003e\"ten\", 8=\u003e\"eighttttee\", 7=\u003e\"seven\", 9=\u003e\"ninie\"} irb(main):018:0\u003e #deleting a hash data element =\u003e nil irb(main):019:0\u003e my_hash_example.delete(10) =\u003e \"ten\" irb(main):020:0\u003e my_hash_example =\u003e {8=\u003e\"eighttttee\", 7=\u003e\"seven\", 9=\u003e\"ninie\"} irb(main):021:0\u003e #methods in hashes =\u003e nil irb(main):022:0\u003e my_hash_example.keys =\u003e [8, 7, 9] irb(main):024:0\u003e my_hash_example.values =\u003e [\"eighttttee\", \"seven\", \"ninie\"] irb(main):027:0\u003e #merging two hashes =\u003e nil irb(main):028:0\u003e my_hash_example.merge(hash_with_different_types) =\u003e {8=\u003e\"eighttttee\", 7=\u003e\"seven\", 9=\u003e\"ninie\", \"name\"=\u003e\"vinay\", \"degrees\"=\u003e[\"MBA\", \"MTECH\", \"MS\"], 12=\u003e\"twelve\"} irb(main):029:0\u003e new_merged_hash=my_hash_example.merge(hash_with_different_types) =\u003e {8=\u003e\"eighttttee\", 7=\u003e\"seven\", 9=\u003e\"ninie\", \"name\"=\u003e\"vinay\", \"degrees\"=\u003e[\"MBA\", \"MTECH\", \"MS\"], 12=\u003e\"twelve\"} irb(main):030:0\u003e new_merged_hash =\u003e {8=\u003e\"eighttttee\", 7=\u003e\"seven\", 9=\u003e\"ninie\", \"name\"=\u003e\"vinay\", \"degrees\"=\u003e[\"MBA\", \"MTECH\", \"MS\"], 12=\u003e\"twelve\"} irb(main):031:0\u003e Symbols\nThe first style is rocket style of declaring hashes,while the second style is symbols syntax\nirb(main):031:0\u003e #symbols as hashes =\u003e nil irb(main):032:1* american_cars = { irb(main):033:1* :chevrolet =\u003e \"Corvette\", irb(main):034:1* :fort =\u003e \"Mustang\", irb(main):035:1* :ferrari =\u003e \"1\" irb(main):036:0\u003e } =\u003e {:chevrolet=\u003e\"Corvette\", :fort=\u003e\"Mustang\", :ferrari=\u003e\"1\"} irb(main):037:0\u003e american_cars =\u003e {:chevrolet=\u003e\"Corvette\", :fort=\u003e\"Mustang\", :ferrari=\u003e\"1\"} irb(main):038:1* japnese_cars = { irb(main):039:1* honda: \"Accord\", irb(main):040:1* toyota: \"Corolla\", irb(main):041:1* nissan: \"Altime\" irb(main):042:0\u003e } =\u003e {:honda=\u003e\"Accord\", :toyota=\u003e\"Corolla\", :nissan=\u003e\"Altime\"} Methods Methods are useful, when you want to repeatedly want to execute a set of statements based on condition,then comes methods into picture.\ndef hello_world_method puts \"hello world\" end hello_world_method def add_two_numbers(a,b) puts a+b #puts a-b Error: Undefined method end add_two_numbers(10,20) add_two_numbers(\"hello\",\"world\") #method with return type and argument def hello_world_with_argument(name) return name+\" Hello World\" end puts hello_world_with_argument(\"vinay\") #default parameters def method_with_default_parameters(name=\"Vinay\") \"Hello\" + name end puts method_with_default_parameters puts method_with_default_parameters(\"Mahesh\") #predicate methods- which return a boolean puts 5.even? puts 6.even? Advanced Arrays puts \"Remove all duplicates\" array1 = [1,1,1,1,2] print array1.uniq puts \"\\nRemoving All Nil Elements\" array1=[1,2,4,5,nil,\"John\"] array2=array1.compact #compact removes all the nil elements. print array1.to_s print array2.to_s puts \"Remove Odd numbers\" array=[10,34,44,32,21,9,3,8] even_array= array.reject do |item| item.odd? end puts even_array puts \"Joining Arrays\" #using concat numbers1= [1,2,4,5] numbers2= [5,6] all_numbers = numbers1+ numbers2 print all_numbers # Destructuring Array.- Instead of manually assigning values using indexes, we can use this option of destructuring arrays. puts \"\\nDestructuring Array\" destructuring_array = [89,90,\"Hello\",\"world\"] mark1,mark2,string1,string2 = destructuring_array puts mark1 puts mark2 puts string2 # Destructuring using greedy variables- adding a star before a variable name makes the variable greedy and that takes all the remaining values mark1,*other_values= destructuring_array puts \"Destructuring array using greedy variable\" puts mark1 print other_values puts \"\\nVariables are greedy,but ruby is damn smart\" mark1, *other_variables, string2= destructuring_array puts mark1 print other_variables print string2 puts \"\\n Creating an array using %w\" w_array = %w{one two three four} print w_array puts \"\\n Quicker way to create array of strings\" array_of_strings= %w[hello world blue green red yellow] print array_of_strings puts \"\\n Quicker way to create array of symbols using %i\" array_of_symbols = %i[symbol1 symbol2 symbol3] print array_of_symbols Comments # single line comments =begin hello world this is a multi line comment in ruby =end Debugging with pry-byebug gem \u003e ruby advanced_arrays.rb Remove all duplicates [1, 2] Removing All Nil Elements [1, 2, 4, 5, nil, \"John\"][1, 2, 4, 5, \"John\"]Remove Odd numbers 10 34 44 32 8 Joining Arrays [1, 2, 4, 5, 5, 6] Destructuring Array From: /home/vinay/Documents/learn/ruby/ruby-exercises/advanced_arrays/advanced_arrays.rb:34 : 29: # Destructuring Array.- Instead of manually assigning values using indexes, we can use this option of destructuring arrays. 30: puts \"\\nDestructuring Array\" 31: destructuring_array = [89,90,\"Hello\",\"world\"] 32: mark1,mark2,string1,string2 = destructuring_array 33: binding.pry =\u003e 34: puts mark1 35: puts mark2 36: puts string2 37: 38: # Destructuring using greedy variables- adding a star before a variable name makes the variable greedy and that takes all the remaining values 39: mark1,*other_values= destructuring_array [1] pry(main)\u003e mark1 =\u003e 89 [2] pry(main)\u003e mark2 =\u003e 90 [3] pry(main)\u003e string1 =\u003e \"Hello\" [4] pry(main)\u003e Enumerable Methods puts \"Select enumerable methods\" friends = ['Sharon','Vinay','Suresh','Mahesh'] print friends.select { |friend| friend!= 'Vinay'} puts \"\\n\\nEach enumerable methods\" friends.each { |friend| puts \"hello\"+ friend} puts \"each_with_index method- returns two block elements,the value and the index of the value\" friends.each_with_index { |fruit, index| print fruit if index.even? } puts \"\\n the map method,instead of creating two separate arrays or creating a new array to put the same data,we can use the map\" friends.each { |friend| friend.upcase } # the above just converts but doesn't saves to the original array,instead creating a new array will be like duplicating data friends.map { |friend| friend.upcase} print friends puts \"\\nreduce method- takes an array or hash and reduces it to single object\" my_numbers = [10,20,40,90] print my_numbers.reduce { |sum, number| sum+number } puts \"\\n Bang methods end with an exclamation and often modify the object they are called on\" #just like friends in the above example if we want to modify the original object we use bang method,we use the above map method to modify the original array friends.map! { |friend| friend.upcase } print friends puts \"\\n Return values of enumerables - it is not a good practice to use bang methods and modify original objects,instead return the enumerables and assign it to a new object\" invited_friends = friends.select { |friend| friend!='VINAY' } print invited_friends Predicate Enumerable Methods #include? predicate enumerable method numbers = [5,7,7,8] print numbers.include?(8) #any method returns true if any elements in array or hash matches the condition within the block;otherwise return false print numbers.any? { |num| num\u003e10 } print numbers.any? { |num| num\u003c10 } #all? method returns true if all the elements in your array or hash matches the condition puts \"\\nall? predicate enumerable method\" print numbers.all? {|num| num\u003e1} # none? method returns true only if the condition in the block matches with none of the elements in array/hash,otherwise it returns false. print numbers.none? { |num| num\u003e20} #saying there are no numbers greater than 20 "},"title":"Introduction to Ruby"},"/docs/rust/":{"data":{"":"","#":"Learning RUST programming language and documenting my learning\nHello World - Rust ! hello_world.rsfn main(){ println!(\"Hello world\") } To compile rust code\n$ rustc hello_world.rs Run the binary\n$ ./hello_world Cargo cargo is rust‚Äôs build tool and package manager, to manage dependencies and its versions,basically crates. cargo uses TOML format stands for Tom‚Äôs Obvious Minimal language,which is cargo‚Äôs configuration format.\nCargo useful commands $ cargo new hello_cargo --vcs=git $ cd hello_cargo on creating a new cargo project the source files are to be present within the src/ directory and also Config.toml file is generated.\ncargo build $cargo build Compiling hello_cargo v0.1.0 (/home/vinay/learn/rust/hello_cargo) Finished dev [unoptimized + debuginfo] target(s) in 0.17s a target/ directory is created\nthe binary is within the target/debug directory\n$ ls target/debug/ build deps examples hello_cargo hello_cargo.d incremental $ ./target/debug/hello_cargo Hello, world! cargo run $ cargo run Finished dev [unoptimized + debuginfo] target(s) in 0.00s Running `target/debug/hello_cargo` Hello, world! instead of two commands of compiling and running the binary, cargo run is a simple command,which compiles and runs the binary\ncargo check compiles the code but does not produce an executable.A\n$ cargo check Checking hello_cargo v0.1.0 (/home/vinay/learn/rust/hello_cargo) Finished dev [unoptimized + debuginfo] target(s) in 0.02s "},"title":"Rust"},"/docs/selfhosting/":{"data":{"":"Self Hosting"},"title":"Self Hosting"},"/docs/selfhosting/nextcloud/":{"data":{"":"","#":"Nextcloud on Debian Nextcloud is a flexible file synchronization and sharing solution.Nextcloud includes Nextcloud server( run on linux) and Nextcloud client.Nextcloud is a Free and Open Source community supported,with all enterprise features. In this doc lets try to install nextcloud server over Nginx and access it over browser client.\nNginx Nginx is Free and Open Source web server which is now also used as reverse proxy,HTTP cache and load balancer.To setup nextcloud we can choose either nginx or apache as webserver. Install and enable nginx service on the server\n$ sudo apt install nginx -y $ sudo systemctl start nginx $ sudo systemctl enable nginx Installation Steps Prerequisites for mannual installation. https://docs.nextcloud.com/server/latest/admin_manual/installation/source_installation.html#prerequisites-for-manual-installation\nInstall php8.0 from deb.sury.org Installing PHP from a third party repository https://deb.sury.org/ which contains the deb packaged version of the latest php and its modules. This repository supports both Ubuntu and Debian.\nif [ \"$(whoami)\" != \"root\" ]; then SUDO=sudo fi ${SUDO} apt-get update ${SUDO} apt-get -y install lsb-release ca-certificates curl ${SUDO} curl -sSLo /usr/share/keyrings/deb.sury.org-php.gpg https://packages.sury.org/php/apt.gpg ${SUDO} sh -c 'echo \"deb [signed-by=/usr/share/keyrings/deb.sury.org-php.gpg] https://packages.sury.org/php/ $(lsb_release -sc) main\" \u003e /etc/apt/sources.list.d/php.list' ${SUDO} apt-get update $ sudo apt policy php8.0 # check for any latest updated php package Install the packages mentionedsudo apt install php8.0-xmlreader php8.0-curl php8.0-gd php8.0-mbstring php8.0-zip php8.0-fpm Database connectors (either choose from MySQL/MariaDB and Postgresql)\nmysql database connector$ sudo apt install mariadb-server php8.0-mysql Caching\nphp modules required for caching$sudo apt install redis php8.0-redis https://docs.nextcloud.com/server/latest/admin_manual/installation/nginx.html\nvim /etc/php/8.0/cli/php.ini update date.timezone = Asia/Kolkata cd /var/www sudo wget https://download.nextcloud.com/server/releases/latest.zip sudo chown www-data:www-data /var/www/nextcloud -R \u003e create database nextcloud_db; \u003e create user nextcloud_user@localhost identified by 'deeproot'; \u003e grant all privileges on nextcloud_db.* to nextcloud_user@localhost identified by 'deeproot'; \u003e flush privileges \u003e exit Nginx Configuration file. paste the following in /etc/nginx/sites-enabled/nextcloud and remove any default files present. and also make a symlink from /etc/nginx/sites-enabled/nextcloud to /etc/nginx/sites-available/nextcloud\nhost nextcloud.vinay.com\nupstream php-handler { #server 127.0.0.1:9000; server unix:/var/run/php/php8.0-fpm.sock; } # Set the `immutable` cache control options only for assets with a cache busting `v` argument map $arg_v $asset_immutable { \"\" \"\"; default \"immutable\"; } server { listen 80; server_name nextcloud.vinay.com; # Path to the root of your installation root /var/www/nextcloud; # Use Mozilla's guidelines for SSL/TLS settings # https://mozilla.github.io/server-side-tls/ssl-config-generator/ #ssl_certificate /etc/ssl/nginx/cloud.example.com.crt; #ssl_certificate_key /etc/ssl/nginx/cloud.example.com.key; # Prevent nginx HTTP Server Detection server_tokens off; # HSTS settings # WARNING: Only add the preload option once you read about # the consequences in https://hstspreload.org/. This option # will add the domain to a hardcoded list that is shipped # in all major browsers and getting removed from this list # could take several months. #add_header Strict-Transport-Security \"max-age=15768000; includeSubDomains; preload\" always; # set max upload size and increase upload timeout: client_max_body_size 512M; client_body_timeout 300s; fastcgi_buffers 64 4K; # Enable gzip but do not remove ETag headers gzip on; gzip_vary on; gzip_comp_level 4; gzip_min_length 256; gzip_proxied expired no-cache no-store private no_last_modified no_etag auth; gzip_types application/atom+xml text/javascript application/javascript application/json application/ld+json application/manifest+json application/rss+xml application/vnd.geo+json application/vnd.ms-fontobject application/wasm application/x-font-ttf application/x-web-app-manifest+json application/xhtml+xml application/xml font/opentype image/bmp image/svg+xml image/x-icon text/cache-manifest text/css text/plain text/vcard text/vnd.rim.location.xloc text/vtt text/x-component text/x-cross-domain-policy; # Pagespeed is not supported by Nextcloud, so if your server is built # with the `ngx_pagespeed` module, uncomment this line to disable it. #pagespeed off; # The settings allows you to optimize the HTTP2 bandwitdth. # See https://blog.cloudflare.com/delivering-http-2-upload-speed-improvements/ # for tunning hints client_body_buffer_size 512k; # HTTP response headers borrowed from Nextcloud `.htaccess` #add_header Referrer-Policy \"no-referrer\" always; #add_header X-Content-Type-Options \"nosniff\" always; #add_header X-Download-Options \"noopen\" always; #add_header X-Frame-Options \"SAMEORIGIN\" always; #add_header X-Permitted-Cross-Domain-Policies \"none\" always; #add_header X-Robots-Tag \"noindex, nofollow\" always; #add_header X-XSS-Protection \"1; mode=block\" always; # Remove X-Powered-By, which is an information leak fastcgi_hide_header X-Powered-By; # Add .mjs as a file extension for javascript # Either include it in the default mime.types list # or include you can include that list explicitly and add the file extension # only for Nextcloud like below: include mime.types; types { text/javascript js mjs; } # Specify how to handle directories -- specifying `/index.php$request_uri` # here as the fallback means that Nginx always exhibits the desired behaviour # when a client requests a path that corresponds to a directory that exists # on the server. In particular, if that directory contains an index.php file, # that file is correctly served; if it doesn't, then the request is passed to # the front-end controller. This consistent behaviour means that we don't need # to specify custom rules for certain paths (e.g. images and other assets, # `/updater`, `/ocm-provider`, `/ocs-provider`), and thus # `try_files $uri $uri/ /index.php$request_uri` # always provides the desired behaviour. index index.php index.html /index.php$request_uri; # Rule borrowed from `.htaccess` to handle Microsoft DAV clients location = / { if ( $http_user_agent ~ ^DavClnt ) { return 302 /remote.php/webdav/$is_args$args; } } location = /robots.txt { allow all; log_not_found off; access_log off; } # Make a regex exception for `/.well-known` so that clients can still # access it despite the existence of the regex rule # `location ~ /(\\.|autotest|...)` which would otherwise handle requests # for `/.well-known`. location ^~ /.well-known { # The rules in this block are an adaptation of the rules # in `.htaccess` that concern `/.well-known`. location = /.well-known/carddav { return 301 /remote.php/dav/; } location = /.well-known/caldav { return 301 /remote.php/dav/; } location /.well-known/acme-challenge { try_files $uri $uri/ =404; } location /.well-known/pki-validation { try_files $uri $uri/ =404; } # Let Nextcloud's API for `/.well-known` URIs handle all other # requests by passing them to the front-end controller. return 301 /index.php$request_uri; } # Rules borrowed from `.htaccess` to hide certain paths from clients location ~ ^/(?:build|tests|config|lib|3rdparty|templates|data)(?:$|/) { return 404; } location ~ ^/(?:\\.|autotest|occ|issue|indie|db_|console) { return 404; } # Ensure this block, which passes PHP files to the PHP process, is above the blocks # which handle static assets (as seen below). If this block is not declared first, # then Nginx will encounter an infinite rewriting loop when it prepends `/index.php` # to the URI, resulting in a HTTP 500 error response. location ~ \\.php(?:$|/) { # Required for legacy support rewrite ^/(?!index|remote|public|cron|core\\/ajax\\/update|status|ocs\\/v[12]|updater\\/.+|oc[ms]-provider\\/.+|.+\\/richdocumentscode\\/proxy) /index.php$request_uri; fastcgi_split_path_info ^(.+?\\.php)(/.*)$; set $path_info $fastcgi_path_info; try_files $fastcgi_script_name =404; include fastcgi_params; fastcgi_pass unix:/var/run/php/php8.0-fpm.sock; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; fastcgi_param PATH_INFO $path_info; fastcgi_param HTTPS off; fastcgi_param modHeadersAvailable true; # Avoid sending the security headers twice fastcgi_param front_controller_active true; # Enable pretty urls #fastcgi_pass php-handler; fastcgi_intercept_errors on; fastcgi_request_buffering off; fastcgi_max_temp_file_size 0; } # Serve static files location ~ \\.(?:css|js|mjs|svg|gif|png|jpg|ico|wasm|tflite|map)$ { try_files $uri /index.php$request_uri; add_header Cache-Control \"public, max-age=15778463, $asset_immutable\"; access_log off; # Optional: Don't log access to assets location ~ \\.wasm$ { default_type application/wasm; } } location ~ \\.woff2?$ { try_files $uri /index.php$request_uri; expires 7d; # Cache-Control policy borrowed from `.htaccess` access_log off; # Optional: Don't log access to assets } # Rule borrowed from `.htaccess` location /remote { return 301 /remote.php$request_uri; } location / { try_files $uri $uri/ /index.php$request_uri; } } OpenLDAP \u0026 NextCloud. To add support for OpenLDAP in nextcloud install ldap php library from deb sury repository.\n$ sudo apt install php8.0-ldap and then later enable LDAP user and group backend on nextcloud Apps"},"title":"NextCloud"},"/wily/":{"data":{"":"WILY word sounds good,an initiative by me to document my everyday learnings to increase my productivity, inspired from Zettelkasten. It is hard to write about the present days learnings,so hence the name WILY, to track Yesterday‚Äôs learnings."},"title":"WILY (What I Learnt Yesterday)"},"/wily/2023/dec-2023/20231214/":{"data":{"":" virt-customize Customizing debian generic cloud images using virt-customize $ virt-customize -a debian-12-generic-amd64-20231210-1591.qcow2 \\ --root-password password:debian $ virt-customize -a debian-12-generic-amd64-20231210-1591.qcow2 \\ --append-line '/etc/motd: Welcome to DeepRoot GNU/Linux' $ virt-customize -v -a debian-12-generic-amd64-20231210-1591.qcow2 --install vim $ virt-customize -v -a debian-12-generic-amd64-20231210-1591.qcow2 \\ --upload path-to-localfile:destination-file-path "},"title":"2023-12-14"},"/wily/2023/dec-2023/20231215/":{"data":{"":" Setting this Wily feature and revamping my site. Ansible Semaphore UI - setting up Key Store,Repositories,Inventory and Task Templates Hello World ansible playbook $ cat hello-world-01.yml --- - hosts: all tasks: - name: Print message debug: msg: Hello World $ cat inventory 10.22.13.84 ansible_user=debian Downloading mp3 version of a video from YouTube using yt-dlp\nsudo yt-dlp -f bestaudio -x --audio-format mp3 --audio-quality 0 \"\u003c\u003cYoutube_link\u003e\u003e\""},"title":"2023-12-15"},"/wily/2023/dec-2023/20231218/":{"data":{"":" Setting up a systemd service for openvpn Create a systemd service file in the path /lib/systemd/system/openvpn-vinay.service with the following contents where vinay.ovpn is the openvpn cert file within the location.\nDescription=To access deeproot office infrastructure After=multi-user.target [Service] ExecStart=sudo openvpn /etc/openvpn/vinay.ovpn [Install] WantedBy=multi-user.target "},"title":"2023-12-18"},"/wily/2023/dec-2023/20231219/":{"data":{"":" Signing statements using GPG key\nPut the statement in a document or textfile like file.txt gpg --clearsign file.txt A file called file.txt.asc will be created which is gpg signed statement.\nInstalling iosevka font\nhttps://phd-sid.ethz.ch/debian/fonts-iosevka/\nControlling audio within the terminal\npactl set-sink-volume 0 +10% : to increase the volume by 10%\npactl set-sink-volume 0 -10% : to decrease the volume by 10%"},"title":"2023-12-19"},"/wily/2023/dec-2023/20231221/":{"data":{"":" Minikube\nminikube delete ‚Äìprofile minikube ip gives the ip of minikube\nping command\nping command uses ICMP (Internet Control Message Protocol), and not TCP/UDP hence cannot ping a particular host‚Äôs port.sends an ICMP echo request to the target host and waits for ICMP echo reply.The time parameter defines the total time taken to send an ICMP request to the target and the reply back to the source target,hence the name Round Trip Time(RTT), hencethe latency\ndig: Domain Information Groper\ncollects data about Domain Name Servers like DNS records\ndig +short blog.vinay.im\nwhere blog.vinay.im is the target‚Äôs domain name\ndig blog.vinay.im\nblog.vinay.im.\t10792\tIN\tCNAME\tvinay-keshava.gitlab.io. vinay-keshava.gitlab.io. 292\tIN\tA\t35.185.44.232 Using Rootless Docker\nhttps://thenewstack.io/how-to-run-docker-in-rootless-mode/ "},"title":"2023-12-21"},"/wily/2023/dec-2023/20231222/":{"data":{"":" Updating PATH in linux\n$ export PATH=$PATH:/usr/sbin - adding a path to a directory\nThere‚Äôs a no way to remove a directory from path instead reassign existing path to the same variable like $ export PATH=/home/vinay:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games:/usr/sbin\nKubernetes Architecture\nRemove fish greeting\nTo remove the fish greeting, Welcome to fish, the friendly interactive shell, add the following set fish_greeting \"\" to .config/fish/config.fish "},"title":"2023-12-22"},"/wily/2023/dec-2023/20231227/":{"data":{"":" qemu-img info $ qemu-img info debian-12-generic-amd64-20231013-1532.qcow2 image: debian-12-generic-amd64-20231013-1532.qcow2 file format: qcow2 virtual size: 38 GiB (40802189312 bytes) disk size: 366 MiB cluster_size: 65536 Format specific information: compat: 1.1 compression type: zlib lazy refcounts: false refcount bits: 16 corrupt: false extended l2: false Child node '/file': filename: debian-12-generic-amd64-20231013-1532.qcow2 protocol type: file file length: 366 MiB (383517184 bytes) disk size: 366 MiB qemu-img info displays general information related to the qcow2 image,like virtual size,disk size etc - To remove the fish greeting, Welcome to fish, the friendly interactive shell, add the following ```set fish_greeting \"\"``` to ```.config/fish/config.fish``` "},"title":"2023-12-27"},"/wily/2024/feb-2024/20240212/":{"data":{"":" Ant : Java based make tool\nCreating a simple ant build system for HelloWorld project. Understanding of build.xml Build commands of ant like ant compile, ant jar, ant run Java 17 features\nJEP: Pseudo Random Generator JEP: Switch Expressions JEP: Records - for creating immutable object without the use of lombok JEP: Usage of Objects in switch statement. JEP: Updated instanceof method to avoid redundant casting JEP: Local Variable Type Inference JEP: Sealed Classes using sealed and permits keyword, to restrict the implementation and extension of classes and interfaces in java (JEP) - JDK Enhanced Proposal."},"title":"2024-02-12"},"/wily/2024/feb-2024/20240214/":{"data":{"":" Termux Learnings\ninstalling packages in termux pkg install git pkg update for package updates. pkg upgrade for package upgrades. pkg edit-sources command to edit sources.list alike files,to change the default mirror "},"title":"2024-02-14"},"/wily/2024/feb-2024/20240215/":{"data":{"":"","#":"Java 17 Features Link to the Java 17 docs\nSealed Classes \u0026 Interfaces Switch Statements InstanceOf Pattern Matching Switch Expressions Record Classes TextBlocks Strong Encapsulation of JDK Internal API‚Äôs Local Variable Type Inference "},"title":"2024-02-15"},"/wily/2024/feb-2024/20240218/":{"data":{"":" Nginx To list files in nginx web server use autoindex on within the server block "},"title":"2024-02-18"},"/wily/2024/feb-2024/20240219/":{"data":{"":" Conventional Commits Defining a standard format for commit changes,which can be processed by automated tools to produce documentation.\n\u003ctype\u003e[(optional \u003cscope\u003e)]: \u003cdescription\u003e [optional \u003cbody\u003e] [optional \u003cfooter\u003e] Link to docs\nDescriptive git commit messages.\ngit commit -m \"Tittle\" -m \"Description\" , a descriptive git commit can be written by using the option -m twice"},"title":"2024-02-19"},"/wily/2024/feb-2024/20240220/":{"data":{"":" Project Lombok Link to the docs common annotations used in lombok avoiding boilerplate code with lombok annotations @Getter,@Setter,@RequiredArgsConstructor,@Builder,@Data,@AllArgsConstructor,@NoArgsConstructor "},"title":"2024-02-19"},"/wily/2024/feb-2024/20240226/":{"data":{"":" FFMPEG ffmpeg is a suite of libraries and programs to handle video,audio \u0026 other multimedia files and streams.\nJoining multiple videos using ffmpeg$ ffmpeg -f concat -safe 0 -i joinvideo.txt -c copy episode2.mp4 vinay@falcon:~/Documents/blog$ cat ../KumaraParvathaVideo/joinvideo.txt file kp-peak-rest.mp4 file thick-forest.mp4 file rohan_vlog.mp4 Rotating a video by a certain degree using ffmpeg\nffmpeg -i inputfile.mp4 -vf \"transpose=1\" outputfile.mp4 "},"title":"2024-02-26"},"/wily/2024/jan-2024/20240102/":{"data":{"":" LVM ‚Äì Logical Volume Management.\nConcepts of Physical Volumes,Volume Groups,Logical Volumes.\nsudo lvmdiskscan\nCreating physical volume using physical drives\nsudo pvcreate /dev/sda /dev/sdb\nCreating Volume groups sudo vgcreate /dev/sda /dev/sdb\nCreating Logical Volumes within the volume groups\nsudo lvcreate -L 10G -n projects LVMVolGroup sudo lvcreate -L 5G -n www LVMVolGroup sudo lvcreate -L 20G -n db LVMVolGroup Golang\nPackage import,multiple package import Exported names starting with capital letters. Functions: function definition,function parameters,shortening function parameters,return types, named return types, "},"title":"2024-01-02"},"/wily/2024/jan-2024/20240103/":{"data":{"":" LVM\nFormatting and Mounting a logical volume sudo mkdir -p /mnt/{backup,college-data} sudo mount /dev/VolGrpLvm/backup /mnt/backup/ sudo mount /dev/VolGrpLvm/college-data /mnt/college-data/ Renaming a logical Volume sudo lvrename /dev/VolGrpLvm/college-data /dev/VolGrpLvm/college Extending a logical Volume sudo lvextend -L+5G /dev/VolGrpLvm/backup ``` ```sudo lvextend -L25G /dev/VolGrpLvm/backup Shrinking a logical volume sudo lvreduce -L20G /dev/VolGrpLvm/backup Removing an logical volume sudo lvremove /dev/VolGrpLvm/backup LVM Stripping sudo lvcreate -L 10G -i2 -I64 -n backup1 VolGrpLvm LVM Mirroring sudo lvcreate -L 5G -m1 -n mirrorLV VolGrpLvm ThinPool and Thin provisioning sudo lvcreate --thinpool vg_thin/thin_pool --name volume_1 --virtualsize 3G Golang\nVariables Short Description variables Types Type conversion and Type inference Constants "},"title":"2024-01-03"},"/wily/2024/jan-2024/20240104/":{"data":{"":" Network File System(NFS)\nHere is the link to the document Installing NFS server and setting directory permissions to 777 Configuring Export directory by editing the file /etc/exports Options to configure the NFS server,either readonly or read write, sync or async,subtree check. Exporting the shared directory using exportfs command Configuring firewall ufw to allow clients to access the shared folder. Configuring client using nfs-common package Creating mountpoints on the client side to access the shared folder. Mounting the folder using mount command or adding the entry to /etc/fstab "},"title":"2024-01-04"},"/wily/2024/jan-2024/20240109/":{"data":{"":" Ruby Learning\nData Types Type Conversion String Interpolation Strings Basic Data Structures and Hashes Symbols Variables Input Output Solved exercises of Odin Project for the String Exercices \u0026 Basic Data Types"},"title":"2024-01-09"},"/wily/2024/jan-2024/20240110/":{"data":{"":" Ruby Learning Cont.\nConditional Logic, if,elsif,else,unless,case statements and ternary operator. Loops -loop,while,for,until loops and upto and downto loops,times and iterators. Blocks - single line blocks and multi line blocks Arrays Array.new, .first \u0026 .last functions , push \u0026 pop of elements, shift and unshift of elements. Hashes Hash.new,Accessing values from key, adding and updating values, merging two hashes and hashes with symbols Methods Solved exercises of Odin Project for the Arrays, Hashes,Methods"},"title":"2024-01-10"},"/wily/2024/jan-2024/20240118/":{"data":{"":" Guake load preferences from config file guake --restore-preferences ~/Downloads/guake_prefs Python Introduction learing Text - multi line print statement,escape sequences,strings and len() of strings Variables and Types Lists "},"title":"2024-01-18"},"/wily/debian/foss-activities-dec-2023/":{"data":{"":"","debian-activities#Debian Activities":" javamorph\nAdded compilation support for JDK 21 with the help of Vladimir Petko. #Bug 1052620 Link to MR, MR accepted and bug closed. Thanks to package maintainer tony mancill for sponsoring package. ruby-validates-hostname\nNew Upstream 1.0.13-1 Routine Update Required for gitlab 16.4 ruby-gpgme\nNew Upstream 2.0.23-1 Routine Update Required for gitlab 16.4 ruby-lockbox\nNew Upstream 1.3.0-1 Routine Update Required for gitlab 16.4 ruby-gitlab-experiment\nruby-gitlab-experiment to experimental New Upstream version 0.8.0-1 Required for gitlab 16.4 ruby-tanuki-emoji\nNew Upstream version 0.7.0-1 Required for gitlab 16.4 epm\nUpdated d/watch patch for epm,epm upstream maintainer has been changed to github.com/jimjag/epm Bug #1051502 ruby-loofah\nNew upstream version 2.21.4 Required for GitLab 16.6.x ruby-apollo-upload-server\nNew upstream version 2.1.5 Required for Gitlab 16.6.x ruby-po-to-json\nNew upstream version 2.0.0 Required for Gitlab 16.6.x Refreshed Patches. "},"title":"Foss activities - Dec 2023"},"/wily/debian/foss-activities-nov-2023/":{"data":{"":"","debian-activities#Debian Activities":" javamorph\nAdded compilation support for JDK 21 with the help of Vladimir Petko. Link to MR ruby-pry-byebug\nMy first QA upload to Debian Closing the bug #1054747 Link to MR New Upstream release 3.10.1 Abhijith pointed out this bug to me, to prevent ruby-octokit from being removed from the archive. Thanks to Miguel Landaeta for sponsoring this package upload."},"title":"Foss activities - Nov 2023"},"/wily/debian/foss-activities-oct-2023/":{"data":{"":"Post DebConf Month","debian-activities#Debian Activities":" ruby-aws-sdk-core\nNew upstream release 3.178.0 rofi\nMy first NMU( Non Maintainer Upload) to debian\nSponsorer: Abhijith PA,also thanks to karthik for mentioning to update rofi,because it was no longer maintained also fixed the bug https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1043483 for d/watch\nNew Upstream version 1.7.5\nd/watch update closes bug\nRefreshing Patch to fix man pages\nFixing Build Depends on obsolute package\nruby-aws-sigv4\nNew Upstream release 1.6.1 ruby-aws-sdk-s3\nNew Upstream release 1.130.0 ","open-street-map#Open Street Map":"My edits on open street Map for October in and around Bangalore and Pavagada. https://www.openstreetmap.org/user/vinay-keshava/history\n:wq "},"title":"Foss activities - Oct 2023"}}